<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant confidence="0.000804" no="0">
<title confidence="0.965761">
Guided Parsing of Range Concatenation Languages
</title>
<author confidence="0.959702">
Fran¸cois Barth´elemy, Pierre Boullier, Philippe Deschamp and ´Eric de la Clergerie
</author>
<affiliation confidence="0.774562">
INRIA-Rocquencourt
</affiliation>
<address confidence="0.3928145">
Domaine de Voluceau
B.P. 105
78153 Le Chesnay Cedex, France
Francois.Barthelemy Pierre.Boullier
</address>
<email confidence="0.641436">
Philippe.Deschamp Eric.De La Clergerie @inria.fr
</email>
<sectionHeader confidence="0.986483" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999974916666666">The theoretical study of the range concatenation grammar [RCG] formalism has revealed many attractive properties which may be used in NLP. In particular, range concatenation languages [RCL] can be parsed in polynomial time and many classical grammatical formalisms can be translated into equivalent RCGs without increasing their worst-case parsing time complexity. For example, after translation into an equivalent RCG, any tree adjoining grammar can be parsed in time. In this paper, we study a parsing technique whose purpose is to improve the practical efficiency of RCL parsers. The non-deterministic parsing choices of the main parser for a language are directed by a guide which uses the shared derivation forest output by a prior RCL parser for a suitable superset of . The results of a practical evaluation of this method on a wide coverage English grammar are given.</bodyText>
<sectionHeader confidence="0.999337" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99981743902439">Usually, during a nondeterministic process, when a nondeterministic choice occurs, one explores all possible ways, either in parallel or one after the other, using a backtracking mechanism. In both cases, the nondeterministic process may be assisted by another process to which it asks its way. This assistant may be either a guide or an oracle. An oracle always indicates all the good ways that will eventually lead to success, and those good ways only, while a guide will indicate all the good ways but may also indicate some wrong ways. In other words, an oracle is a perfect guide (Kay, 2000), and the worst guide indicates all possible ways. Given two problems and and their respective solutions and , if they are such that , any algorithm which solves is a candidate guide for nondeterministic algorithms solving . Obviously, supplementary conditions have to be fulfilled for to be a guide. The first one deals with relative efficiency: it assumes that problem can be solved more efficiently than problem . Of course, parsers are privileged candidates to be guided. In this paper we apply this technique to the parsing of a subset of RCLs that are the languages defined by RCGs. The syntactic formalism of RCGs is powerful while staying computationally tractable. Indeed, the positive version of RCGs [PRCGs] defines positive RCLs [PRCLs] that exactly cover the class PTIME of languages recognizable in deterministic polynomial time. For example, any mildly context-sensitive language is a PRCL. In Section 2, we present the definitions of PRCGs and PRCLs. Then, in Section 3, we design an algorithm which transforms any PRCL into another PRCL ,such that the (theoretical) parse time for is less than or equal to the parse time for : the parser for will be guided by the parser for . Last, in Section 4, we relate some experiments with a wide coverage tree-adjoining grammar [TAG] for English.</bodyText>
<sectionHeader confidence="0.9763945" genericHeader="method">
2 Positive Range Concatenation
Grammars
</sectionHeader>
<bodyText confidence="0.993550993827161">This section only presents the basics of RCGs, more details can be found in (Boullier, 2000b). A positive range concatenation grammar [PRCG] is a 5-tuple where is a finite set of nonterminal symbols (also called predicate names), and are finite, disjoint sets of terminal symbols and variable symbols respectively, is the start predicate name, and is a finite set of clauses where and each of is a predicate of the form where is its arity, , and each of , , is an argument. Each occurrence of a predicate in the LHS (resp. RHS) of a clause is a predicate definition (resp. call). Clauses which define predicate name are called -clauses. Each predicate name has a fixed arity whose value is arity . By definition arity . The arity of an -clause is arity , and the arity of a grammar (we have a -PRCG) is the maximum arity of its clauses. The size of a clause is the integer arity and the size of is . For a given string , a pair of integers s.t. is called a range, and is denoted : is its lower bound, is its upper bound and is its size. For a given , the set of all ranges is noted . In fact, denotes the occurrence of the string in . Two ranges and can be concatenated iff the two bounds and are equal, the result is the range . Variable occurrences or more generally strings in can be instantiated to ranges. However, an occurrence of the terminal can be instantiated to the range iff . That is, in a clause, several occurrences of the same terminal may well be instantiated to different ranges while several occurrences of the same variable can only be instantiated to the same range. Of course, the concatenation on strings matches the concatenation on ranges. We say that is an instantiation of the predicate iff and each symbol (terminal or variable) of , is instantiated to a range in s.t. is instantiated to . If, in a clause, all predicates are instantiated, we have an instantiated clause. A binary relation derive, denoted , is defined on strings of instantiated predicates. If is a string of instantiated predicates and if is the LHS of some instantiated clause , then we have . , the PRCL defined by a PRCG , is the set of all its sentences. For a given sentence , as in the context-free [CF] case, a single complete derivation can be represented by a parse tree and the (unbounded) set of complete derivations by a finite structure, the parse forest. All possible derivation strategies (i.e., top-down, bottom-up,...) are encompassed within both parse trees and parse forests. A clause is: combinatorial if at least one argument of its RHS predicates does not consist of a single variable; bottom-up erasing (resp. top-down erasing) if there is at least one variable occurring in its RHS (resp. LHS) which does not appear in its LHS (resp. RHS); erasing if there exists a variable appearing only in its LHS or only in its RHS; linear if none of its variables occurs twice in its LHS or twice in its RHS; simple if it is non-combinatorial, nonerasing and linear. These definitions extend naturally from clause to set of clauses (i.e., grammar). In this paper we will not consider negative RCGs, since the guide construction algorithm An input string ,is a sentence iff the empty string (of instantiated predicates) can be derived from , the instantiation of the start predicate on the whole source text. Such a sequence of instantiated predicates is called a complete derivation. presented is Section 3 is not valid for this class. Thus, in the sequel, we shall assume that RCGs are PRCGs. In (Boullier, 2000b) is presented a parsing algorithm which, for any RCG and any input string of length , produces a parse forest in time. The exponent , called degree of , is the maximum number of free (independent) bounds in a clause. For a non-bottom-uperasing RCG, is less than or equal to the maximum value, for all clauses, of the sum where, for a clause , is its arity and is the number of (different) variables in its LHS predicate. . Let be the initial PRCG and let be the generated 1-PRCG. Informally, to each -ary predicate name we shall associate unary predicate names , each corresponding to one argument of . We define and , ,and the set of clauses is generated in the way described below. We say that two strings and , on some alphabet, share a common substring, and we write , iff either , or or both are empty or, if and , we have . For any clause in , such that , we generate the set of clauses in the following way. The clause has the form where the RHS is constructed from the ’s as follows. A predicate call is in iff the arguments and share a common substring (i.e., we have ). As an example, the following set of clauses, in which , and are variables and and are terminal symbols, defines the 3-copy language which is not a CF language [CFL] and even lies beyond the formal power of TAGs. This PRCG is transformed by the above algorithm into a 1-PRCG whose clause set is It is not difficult to show that . This transformation algorithm works for any PRCG. Moreover, if we restrict ourselves to the class of PRCGs that are non-combinatorial and non-bottom-up-erasing, it is easy to check that the constructed 1-PRCG is also non-combinatorial and non-bottom-up-erasing. It has been shown in (Boullier, 2000a) that non-combinatorial and nonbottom-up-erasing 1-RCLs can be parsed in cubic time after a simple grammatical transformation. In order to reach this cubic parse time, we assume in the sequel that any RCG at hand is a noncombinatorial and non-bottom-up-erasing PRCG. However, even if this cubic time transformation is not performed, we can show that the (theoretical) throughput of the parser for cannot be less than the throughput of the parser for . In other words, if we consider the parsers for and and if we recall the end of Section 2, it is easy to show that the degrees, say and , of their polynomial parse times are such that . The equality is reached iff the maximum value in is produced by a unary clause which is kept unchanged by our transformation algorithm. The starting RCG is called the initial grammar and it defines the initial language . The corresponding 1-PRCG constructed by our transformation algorithm is called the guiding grammar and its language is the guiding language.</bodyText>
<sectionHeader confidence="0.406156" genericHeader="method">
3 PRCG to 1-PRCG Transformation
Algorithm
</sectionHeader>
<bodyText confidence="0.998806470588236">The purpose of this section is to present a transformation algorithm which takes as input any PRCG and generates as output a 1-PRCG , such that If the algorithm to reach a cubic parse time is applied to the guiding grammar , we get an equivalent -guiding grammar (it also defines ). The various RCL parsers associated with these grammars are respectively called initial parser, guiding parser and -guiding parser. The output of a ( -) guiding parser is called a ( -) guiding structure. The term guide is used for the process which, with the help of a guiding structure, answers ‘yes’ or ‘no’ to any question asked by the guided process. In our case, the guided processes are the RCL parsers for called guided parser and -guided parser.</bodyText>
<sectionHeader confidence="0.762721" genericHeader="evaluation">
4 Parsing with a Guide
</sectionHeader>
<bodyText confidence="0.999871670212766">Parsing with a guide proceeds as follows. The guided process is split in two phases. First, the source text is parsed by the guiding parser which builds the guiding structure. Of course, if the source text is parsed by the -guiding parser, the -guiding structure is then translated into a guiding structure, as if the source text had been parsed by the guiding parser. Second, the guided parser proper is launched, asking the guide to help (some of) its nondeterministic choices. Our current implementation of RCL parsers is like a (cached) recursive descent parser in which the nonterminal calls are replaced by instantiated predicate calls. Assume that, at some place in an RCL parser, is an instantiated predicate call. In a corresponding guided parser, this call can be guarded by a call to a guide, with , and as parameters, that will check that both and are instantiated predicates in the guiding structure. Of course, various actions in a guided parser can be guarded by guide calls, but the guide can only answer questions that, in some sense, have been registered into the guiding structure. The guiding structure may thus contain more or less complete information, leading to several guide levels. For example, one of the simplest levels one may think of, is to only register in the guiding structure the (numbers of the) clauses of the guiding grammar for which at least one instantiation occurs in their parse forest. In such a case, during the second phase, when the guided parser tries to instantiate some clause of , it can call the guide to know whether or not can be valid. The guide will answer ‘yes’ iff the guiding structure contains the set of clauses in generated from by the transformation algorithm. At the opposite, we can register in the guiding structure the full parse forest output by the guiding parser. This parse forest is, for a given sentence, the set of all instantiated clauses of the guiding grammar that are used in all complete derivations. During the second phase, when the guided parser has instantiated some clause of the initial grammar, it builds the set of the corresponding instantiations of all clauses in and asks the guide to check that this set is a subset of the guiding structure. During our experiment, several guide levels have been considered, however, the results in Section 5 are reported with a restricted guiding structure which only contains the set of all (valid) clause numbers and for each clause the set of its LHS instantiated predicates. The goal of a guided parser is to speed up a parsing process. However, it is clear that the theoretical parse time complexity is not improved by this technique and even that some practical parse time will get worse. For example, this is the case for the above 3-copy language. In that case, it is not difficult to check that the guiding language is , and that the guide will always answer ‘yes’ to any question asked by the guided parser. Thus the time taken by the guiding parser and by the guide itself is simply wasted. Of course, a guide that always answer ‘yes’ is not a good one and we should note that this case may happen, even when the guiding language is not . Thus, from a practical point of view the question is simply “will the time spent in the guiding parser and in the guide be at least recouped by the guided parser?” Clearly, in the general case, no definite answer can be brought to such a question, since the total parse time may depend not only on the input grammar, the (quality of) the guiding grammar (e.g., is not a too “large” superset of ), the guide level, but also it may depend on the parsed sentence itself. Thus, in our opinion, only the results of practical experiments may globally decide if using a guided parser is worthwhile . Another potential problem may come from the size of the guiding grammar itself. In particular, experiments with regular approximation of CFLs related in (Nederhof, 2000) show that most reported methods are not practical for large CF grammars, because of the high costs of obtaining the minimal DFSA. In our case, it can easily be shown that the increase in size of the guiding grammars is bounded by a constant factor and thus seems a priori acceptable from a practical point of view. The next section depicts the practical experiments we have performed to validate our approach.</bodyText>
<sectionHeader confidence="0.9898555" genericHeader="evaluation and result">
5 Experiments with an English
Grammar
</sectionHeader>
<bodyText confidence="0.999678821428571">In order to compare a (normal) RCL parser and its guided versions, we looked for an existing widecoverage grammar. We chose the grammar for English designed for the XTAG system (XTAG, 1995), because it both is freely available and seems rather mature. Of course, that grammar uses the TAG formalism.1 Thus, we first had to transform that English TAG into an equivalent RCG. To perform this task, we implemented the algorithm described in (Boullier, 1998) (see also (Boullier, 1999)), which allows to transform any TAG into an equivalent simple PRCG.2 However, Boullier’s algorithm was designed for pure TAGs, while the structures used in the XTAG system are not trees, but rather tree schemata, grouped into linguistically pertinent tree families, which have to be instantiated by inflected forms for each given input sentence. That important difference stems from the radical difference in approaches between “classical” TAG parsing and “usual” RCL parsing. In the former, through lexicalization, the input sentence allows the selection of tree schemata which are then instantiated on the corresponding inflected forms, thus the TAG is not really part of the parser. While in the latter, the (non-lexicalized) grammar is precompiled into an optimized automaton.3 Since the instantiation of all tree schemata by the complete dictionary is impracticable, we designed a two-step process.</bodyText>
<footnote confidence="0.99760325">
1We assume here that the reader has at least some cursory
notions of this formalism. An introduction to TAG can be
found in (Joshi, 1987).
2We first stripped the original TAG of its feature struc-
tures in order to get a pure featureless TAG.
3The advantages of this approach might be balanced by
the size of the automaton, but we shall see later on that it can
be made to stay reasonable, at least in the case at hand.
</footnote>
<bodyText confidence="0.998833840909091">For example, from the sentence “George loved himself .”, a lever first produces the sequence “George n-n nxnn nn-n loved tnx0vnx1-v tnx0vnx1s2v tnx0vs1-v himself tnx0n1-n nxn-n .spu-punct spus-punct ”, and, in a second phase, this sequence is used as actual input to our parsers. The names between braces are pre-terminals. We assume that each terminal leaf of every elementary tree schema has been labeled by a pre-terminal name of the form where is the family of , is the category of (verb, noun,...) and is an optional occurrence index.4 Thus, the association George “ n-n nxn-n nn-n ” means that the inflected form “George” is a noun (suffix -n) that can occur in all trees of the “n”, “nxn” or “nn” families (everywhere a terminal leaf of category noun occurs). Since, in this two-step process, the inputs are not sequences of terminal symbols but instead simple DAG structures, as the one depicted in Figure 1, we have accordingly implemented in our RCG system the ability to handle inputs that are simple DAGs of tokens.5 In Section 3, we have seen that the language defined by a guiding grammar for some RCG , is a superset of , the language defined by . If is a simple PRCG, is a simple 1-PRCG, and thus is a CFL (see (Boullier, 2000a)). In other words, in the case of TAGs, our transformation algorithm approximates the initial tree-adjoining language by a CFL, and the steps of CF parsing performed by the guiding parser can well be understood in terms of TAG parsing. The original algorithm in (Boullier, 1998) performs a one-to-one mapping between elementary trees and clauses, initial trees generate simple unary clauses while auxiliary trees generate simple binary clauses. Our transformation algorithm leaves unary clauses unchanged (simple unary clauses are in fact CF productions). For binary -clauses, our algorithm generates two clauses,</bodyText>
<footnote confidence="0.96691">
4The usage of as component of is due to the fact
that in the XTAG syntactic dictionary, lemmas are associ-
ated with tree family names.
5This is done rather easily for linear RCGs. The process-
ing of non-linear RCGs with lattices as input is outside the
scope of this paper.
</footnote>
<figure confidence="0.995372357142857">
n-n
tnx0n1-n
tnx0vnx1-v
spu-punct
himself 3
nxn-n
0 George 1
nxn-n
nn-n
tnx0vnx1s2-v
tnx0vs1-v
loved 2
. 4
spus-punct
</figure>
<figureCaption confidence="0.999975">
Figure 1: Actual source text as a simple DAG structure
an -clause which corresponds to the part of the auxiliary tree to the left of the spine and an clause for the part to the right of the spine.</figureCaption>
<bodyText confidence="0.999830105263158">Both are CF clauses that the guiding parser calls independently. Therefore, for a TAG, the associated guiding parser performs substitutions as would a TAG parser, while each adjunction is replaced by two independent substitutions, such that there is no guarantee that any couple of -tree and tree can glue together to form a valid (adjoinable) -tree. In fact, guiding parsers perform some kind of (deep-grammar based) shallow parsing. For our experiments, we first transformed the English XTAG into an equivalent simple PRCG: the initial grammar . Then, using the algorithms of Section 3, we built, from , the corresponding guiding grammar , and from the guiding grammar. Table 1 gives some information on these grammars.6</bodyText>
<table confidence="0.9984605">
RCG initial guiding -guiding
22 33 4 204
476 476 476
1 144 1 696 5 554
15 578 15 618 17 722
degree 27 27 3
</table>
<bodyText confidence="0.972017166666667">For our experiments, we have used a test suite distributed with the XTAG system. It contains 31 sentences ranging from 4 to 17 words, with an average length of 8. All measures have been performed on a 800 MHz Pentium III with 640 MB of memory, running Linux. All parsers have been compiled with gcc without any optimization flag.</bodyText>
<footnote confidence="0.5574842">
6Note that the worst-case parse time for both the initial
and the guiding parsers is . As explained in Sec-
tion 3, this identical polynomial degrees comes
from an untransformed unary clause which itself is the result
of the translation of an initial tree.
</footnote>
<bodyText confidence="0.950342315789474">We have first compared the total time taken to produce the guiding structures, both by the guiding parser and by the guiding parser (see Table 2). On this sample set, the -guiding parser is twice as fast as the -guiding parser. We guess that, on such short sentences, the benefit yielded by the lowest degree has not yet offset the time needed to handle a much greater number of clauses. To validate this guess, we have tried longer sentences. With a 35-word sentence we have noted that the -guiding parser is almost six times faster than the -guiding parser and besides we have verified that the even crossing point seems to occur for sentences of around 16– 20 words.parser guiding -guiding sample set 0.990 1.870 35-word sent.30.560 5.210 parser load module
initial 3.063
guided 8.374
-guided 14.530</bodyText>
<tableCaption confidence="0.994102">
Table 2: Guiding parsers times (sec)
</tableCaption>
<tableCaption confidence="0.995655">
Table 3: RCL parser sizes (MB)
</tableCaption>
<table confidence="0.9769612">
parser sample set 35-word sent.
initial 5.810 3 679.570
guided 1.580 63.570
-guided 2.440 49.150
XTAG 4282.870 5 days
</table>
<tableCaption confidence="0.9998135">
Table 4: Parse times (sec)
Table 1: RCGs facts
</tableCaption>
<bodyText confidence="0.999319666666667">The sizes of these RCL parsers (load modules) are in Table 3 while their parse times are in Table 4.7 We have also noted in the last line, for reference, the times of the latest XTAG parser (February 2001),8 on our sample set and on the 35-word sentence.9</bodyText>
<sectionHeader confidence="0.623012" genericHeader="result">
6 Guiding Parser as Tree Filter
</sectionHeader>
<bodyText confidence="0.995711306122449">In (Sarkar, 2000), there is some evidence to indicate that in LTAG parsing the number of trees selected by the words in a sentence (a measure of the syntactic lexical ambiguity of the sentence) is a better predictor of complexity than the number of words in the sentence. Thus, the accuracy of the tree selection process may be crucial for parsing speeds. In this section, we wish to briefly compare the tree selections performed, on the one hand by the words in a sentence and, on the other hand, by a guiding parser. Such filters can be used, for example, as pre-processors in classical [L]TAG parsing. With a guiding parser as tree filter, a tree (i.e., a clause) is kept, not because it has been selected by a word in the input sentence, but because an instantiation of that clause belongs to the guiding structure. The recall of both filters is 100%, since all pertinent trees are necessarily selected by the input words and present in the guiding structure. On the other hand, for the tree selection by the words in a sentence, the precision measured on our sam7The time taken by the lexer phase is linear in the length of the input sentences and is negligible. 8It implements a chart-based head-corner parsing algorithm for lexicalized TAGs, see (Sarkar, 2000). This parser can be run in two phases, the second one being devoted to the evaluation of the features structures on the parse forest built during the first phase. Of course, the times reported in that paper are only those of the first pass. Moreover, the various parameters have been set so that the resulting parse trees and ours are similar. Almost half the sample sentences give identical results in both that system and ours. For the other half, it seems that the differences come from the way the co-anchoring problem is handled in both systems. To be fair, it must be noted that the time taken to output a complete parse forest is not included in the parse times reported for our parsers. Outputing those parse forests, similar to Sarkar’s ones, takes one second on the whole sample set and 80 seconds for the 35-word sentence (there are more than 3 600 000 instantiated clauses in the parse forest of that last sentence). 9Considering the last line of Table 2, one can notice that the times taken by the guided phases of the guided parser and the -guided parser are noticeably different, when they should be the same. This anomaly, not present on the sample set, is currently under investigation. ple set is 15.6% on the average, while it reaches 100% for the guiding parser (i.e., each and every selected tree is in the final parse forest).</bodyText>
<sectionHeader confidence="0.996738" genericHeader="conclusion">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999975849315069">The experiment related in this paper shows that some kind of guiding technique has to be considered when one wants to increase parsing efficiency. With a wide coverage English TAG, on a small sample set of short sentences, a guided parser is on the average three times faster than its non-guided counterpart, while, for longer sentences, more than one order of magnitude may be expected. However, the guided parser speed is very sensitive to the level of the guide, which must be chosen very carefully since potential benefits may be overcome by the time taken by the guiding structure book-keeping procedures. Of course, the filtering principle related in this paper is not novel (see for example (Lakshmanan and Yim, 1991) for deductive databases) but, if we consider the various attempts of guided parsing reported in the literature, ours is one of the very few examples in which important savings are noted. One reason for that seems to be the extreme simplicity of the interface between the guiding and the guided process: the guide only performs a direct access into the guiding structure. Moreover, this guiding structure is (part of) the usual parse forest output by the guiding parser, without any transduction (see for example in (Nederhof, 1998) how a FSA can guide a CF parser). As already noted by many authors (see for example (Carroll, 1994)), the choice of a (parsing) algorithm, as far as its throughput is concerned, cannot rely only on its theoretical complexity but must also take into account practical experiments. Complexity analysis gives worst-case upper bounds which may well not be reached, and which implies constants that may have a preponderant effect on the typical size ranges of the application. We have also noted that guiding parsers can be used in classical TAG parsers, as efficient and (very) accurate tree selectors. More generally, we are currently investigating the possibility to use guiding parsers as shallow parsers. The above results also show that (guided) RCL parsing is a valuable alternative to classical (lexicalized) TAG parsers since we have exhibited parse time savings of several orders of magnitude over the most recent XTAG parser. These savings even allow to consider the parsing of medium size sentences with the English XTAG. The global parse time for TAGs might also be further improved using the transformation described in (Boullier, 1999) which, starting from any TAG, constructs an equivalent RCG that can be parsed in . However, this improvement is not definite, since, on typical input sentences, the increase in size of the resulting grammar may well ruin the expected practical benefits, as in the case of the -guiding parser processing short sentences. We must also note that a (guided) parser may also be used as a guide for a unification-based parser in which feature terms are evaluated (see the experiment related in (Barth´elemy et al., 2000)). Although the related practical experiments have been conducted on a TAG, this guide technique is not dedicated to TAGs, and the speed of all PRCL parsers may be thus increased. This pertains in particular to the parsing of all languages whose grammars can be translated into equivalent PRCGs — MC-TAGs, LCFRS, .. .</bodyText>
<sectionHeader confidence="0.999281" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999764177419355">
F. Barth´elemy, P. Boullier, Ph. Deschamp, and ´E. de la
Clergerie. 2000. Shared forests can guide parsing.
In Proceedings of the Second Workshop on Tabula-
tion in Parsing and Deduction (TAPD’2000), Uni-
versity of Vigo, Spain, September.
P. Boullier. 1998. A generalization of mildly context-
sensitive formalisms. In Proceedings of the Fourth
International Workshop on Tree Adjoining Gram-
mars and Related Frameworks (TAG+4), pages 17–
20, University of Pennsylvania, Philadelphia, PA,
August.
P. Boullier. 1999. On tag parsing. In
conf´erence annuelle sur le Traitement Au-
tomatique des Langues Naturelles (TALN’99),
pages 75–84, Carg`ese, Corse, France,
July. See also Research Report N ˚ 3668
at http://www.inria.fr/RRRT/RR-
3668.html, INRIA-Rocquencourt, France, Apr.
1999, 39 pages.
P. Boullier. 2000a. A cubic time extension of context-
free grammars. Grammars, 3(2/3):111–131.
P. Boullier. 2000b. Range concatenation grammars.
In Proceedings of the Sixth International Workshop
on Parsing Technologies (IWPT 2000), pages 53–
64, Trento, Italy, February.
John Carroll. 1994. Relating complexity to practical
performance in parsing with wide-coverage unifi-
cation grammars. In Proceedings of the 32th An-
nual Meeting of the Association for Computational
Linguistics (ACL’94), pages 287–294, New Mexico
State University at Las Cruces, New Mexico, June.
A. K. Joshi. 1987. An introduction to tree adjoining
grammars. In A. Manaster-Ramer, editor, Math-
ematics of Language, pages 87–114. John Ben-
jamins, Amsterdam.
M. Kay. 2000. Guides and oracles for linear-time
parsing. In Proceedings of the Sixth International
Workshop on Parsing Technologies (IWPT 2000),
pages 6–9, Trento, Italy, February.
V.S. Lakshmanan and C.H. Yim. 1991. Can filters
do magic for deductive databases? In 3rd UK
Annual Conference on Logic Programming, pages
174–189, Edinburgh, April. Springer Verlag.
M.-J. Nederhof. 1998. Context-free parsing through
regular approximation. In Proceedings of the Inter-
national Workshop on Finite State Methods in Nat-
ural Language Processing, Ankara, Turkey, June-
July.
M.-J. Nederhof. 2000. Practical experiments with
regular approximation of context-free languages.
Computational Linguistics, 26(1):17–44.
A. Sarkar. 2000. Practical experiments in parsing
using tree adjoining grammars. In Proceedings of
the Fifth International Workshop on Tree Adjoin-
ing Grammars and Related Formalisms (TAG+5),
pages 193–198, University of Paris 7, Jussieu, Paris,
France, May.
the research group XTAG. 1995. A lexicalized tree
adjoining grammar for English. Technical Report
IRCS 95-03, Institute for Research in Cognitive
Science, University of Pennsylvania, Philadelphia,
PA, USA, March.
</reference>
<page confidence="0.646319">
`eme
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant confidence="0.236192" no="0">
<title confidence="0.995593">Guided Parsing of Range Concatenation Languages</title>
<author confidence="0.85237">Pierre Boullier Barth´elemy</author>
<author confidence="0.85237">Philippe Deschamp de_la Clergerie</author>
<email confidence="0.811655">INRIA-Rocquencourt</email>
<affiliation confidence="0.68645">Domaine de Voluceau</affiliation>
<address confidence="0.925738">B.P. 105 78153 Le Chesnay Cedex, France</address>
<title confidence="0.785013">Francois.Barthelemy Pierre.Boullier</title>
<author confidence="0.640455">Philippe Deschamp Eric De_La Clergerie inria fr</author>
<abstract confidence="0.99967972">The theoretical study of the range concatenation grammar [RCG] formalism has revealed many attractive properties which may be used in NLP. In particular, range concatenation languages [RCL] can be parsed in polynomial time and many classical grammatical formalisms can be translated into equivalent RCGs without increasing their worst-case parsing time complexity. For example, after translation into an equivalent RCG, any tree adjoining grammar can be parsed in time. In this paper, we study a parsing technique whose purpose is to improve the practical efficiency of RCL parsers. The non-deterministic parsing choices of the main parser for a language are directed by a guide which uses the shared derivation forest output by a prior RCL parser for a suitable superset of . The results of a practical evaluation of this method on a wide coverage English grammar are given.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Deschamp</author>
<author>´E de la Clergerie</author>
</authors>
<title>Shared forests can guide parsing.</title>
<date>2000</date>
<booktitle>In Proceedings of the Second Workshop on Tabulation in Parsing and Deduction (TAPD’2000),</booktitle>
<location>University of Vigo, Spain,</location>
<marker>Deschamp, Clergerie, 2000</marker>
<rawString>F. Barth´elemy, P. Boullier, Ph. Deschamp, and ´E. de la Clergerie. 2000. Shared forests can guide parsing. In Proceedings of the Second Workshop on Tabulation in Parsing and Deduction (TAPD’2000), University of Vigo, Spain, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Boullier</author>
</authors>
<title>A generalization of mildly contextsensitive formalisms.</title>
<date>1998</date>
<booktitle>In Proceedings of the Fourth International Workshop on Tree Adjoining Grammars and Related Frameworks (TAG+4),</booktitle>
<pages>17--20</pages>
<institution>University of Pennsylvania,</institution>
<location>Philadelphia, PA,</location>
<contexts>
<context citStr="Boullier, 1998" endWordPosition="2661" position="15008" startWordPosition="2660"> a practical point of view. The next section depicts the practical experiments we have performed to validate our approach. 5 Experiments with an English Grammar In order to compare a (normal) RCL parser and its guided versions, we looked for an existing widecoverage grammar. We chose the grammar for English designed for the XTAG system (XTAG, 1995), because it both is freely available and seems rather mature. Of course, that grammar uses the TAG formalism.1 Thus, we first had to transform that English TAG into an equivalent RCG. To perform this task, we implemented the algorithm described in (Boullier, 1998) (see also (Boullier, 1999)), which allows to transform any TAG into an equivalent simple PRCG.2 However, Boullier’s algorithm was designed for pure TAGs, while the structures used in the XTAG system are not trees, but rather tree schemata, grouped into linguistically pertinent tree families, which have to be instantiated by inflected forms for each given input sentence. That important difference stems from the radical difference in approaches between “classical” TAG parsing and “usual” RCL parsing. In the former, through lexicalization, the input sentence allows the selection of tree schemata</context>
<context citStr="Boullier, 1998" endWordPosition="3153" position="17887" startWordPosition="3152">Figure 1, we have accordingly implemented in our RCG system the ability to handle inputs that are simple DAGs of tokens.5 In Section 3, we have seen that the language defined by a guiding grammar for some RCG , is a superset of , the language defined by . If is a simple PRCG, is a simple 1-PRCG, and thus is a CFL (see (Boullier, 2000a)). In other words, in the case of TAGs, our transformation algorithm approximates the initial tree-adjoining language by a CFL, and the steps of CF parsing performed by the guiding parser can well be understood in terms of TAG parsing. The original algorithm in (Boullier, 1998) performs a one-to-one mapping between elementary trees and clauses, initial trees generate simple unary clauses while auxiliary trees generate simple binary clauses. Our transformation algorithm leaves unary clauses unchanged (simple unary clauses are in fact CF productions). For binary -clauses, our algorithm generates two clauses, 4The usage of as component of is due to the fact that in the XTAG syntactic dictionary, lemmas are associated with tree family names. 5This is done rather easily for linear RCGs. The processing of non-linear RCGs with lattices as input is outside the scope of this</context>
</contexts>
<marker>Boullier, 1998</marker>
<rawString>P. Boullier. 1998. A generalization of mildly contextsensitive formalisms. In Proceedings of the Fourth International Workshop on Tree Adjoining Grammars and Related Frameworks (TAG+4), pages 17– 20, University of Pennsylvania, Philadelphia, PA, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Boullier</author>
</authors>
<title>On tag parsing.</title>
<date>1999</date>
<booktitle>In conf´erence annuelle sur le Traitement Automatique des Langues Naturelles (TALN’99),</booktitle>
<pages>75--84</pages>
<location>Carg`ese, Corse, France,</location>
<contexts>
<context citStr="Boullier, 1999" endWordPosition="2665" position="15035" startWordPosition="2664"> The next section depicts the practical experiments we have performed to validate our approach. 5 Experiments with an English Grammar In order to compare a (normal) RCL parser and its guided versions, we looked for an existing widecoverage grammar. We chose the grammar for English designed for the XTAG system (XTAG, 1995), because it both is freely available and seems rather mature. Of course, that grammar uses the TAG formalism.1 Thus, we first had to transform that English TAG into an equivalent RCG. To perform this task, we implemented the algorithm described in (Boullier, 1998) (see also (Boullier, 1999)), which allows to transform any TAG into an equivalent simple PRCG.2 However, Boullier’s algorithm was designed for pure TAGs, while the structures used in the XTAG system are not trees, but rather tree schemata, grouped into linguistically pertinent tree families, which have to be instantiated by inflected forms for each given input sentence. That important difference stems from the radical difference in approaches between “classical” TAG parsing and “usual” RCL parsing. In the former, through lexicalization, the input sentence allows the selection of tree schemata which are then instantiate</context>
<context citStr="Boullier, 1999" endWordPosition="4668" position="26591" startWordPosition="4667">ssical TAG parsers, as efficient and (very) accurate tree selectors. More generally, we are currently investigating the possibility to use guiding parsers as shallow parsers. The above results also show that (guided) RCL parsing is a valuable alternative to classical (lexicalized) TAG parsers since we have exhibited parse time savings of several orders of magnitude over the most recent XTAG parser. These savings even allow to consider the parsing of medium size sentences with the English XTAG. The global parse time for TAGs might also be further improved using the transformation described in (Boullier, 1999) which, starting from any TAG, constructs an equivalent RCG that can be parsed in . However, this improvement is not definite, since, on typical input sentences, the increase in size of the resulting grammar may well ruin the expected practical benefits, as in the case of the -guiding parser processing short sentences. We must also note that a (guided) parser may also be used as a guide for a unification-based parser in which feature terms are evaluated (see the experiment related in (Barth´elemy et al., 2000)). Although the related practical experiments have been conducted on a TAG, this guid</context>
</contexts>
<marker>Boullier, 1999</marker>
<rawString>P. Boullier. 1999. On tag parsing. In conf´erence annuelle sur le Traitement Automatique des Langues Naturelles (TALN’99), pages 75–84, Carg`ese, Corse, France,</rawString>
</citation>
<citation valid="true">
<authors>
<author>July</author>
</authors>
<title>See also Research Report N ˚ 3668 at http://www.inria.fr/RRRT/RR3668.html, INRIA-Rocquencourt,</title>
<date>1999</date>
<volume>39</volume>
<pages>pages.</pages>
<location>France,</location>
<marker>July, 1999</marker>
<rawString>July. See also Research Report N ˚ 3668 at http://www.inria.fr/RRRT/RR3668.html, INRIA-Rocquencourt, France, Apr. 1999, 39 pages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Boullier</author>
</authors>
<title>A cubic time extension of contextfree grammars.</title>
<date>2000</date>
<journal>Grammars,</journal>
<pages>3--2</pages>
<contexts>
<context citStr="Boullier, 2000" endWordPosition="535" position="3227" startWordPosition="534">istic polynomial time. For example, any mildly context-sensitive language is a PRCL. In Section 2, we present the definitions of PRCGs and PRCLs. Then, in Section 3, we design an algorithm which transforms any PRCL into another PRCL ,such that the (theoretical) parse time for is less than or equal to the parse time for : the parser for will be guided by the parser for . Last, in Section 4, we relate some experiments with a wide coverage tree-adjoining grammar [TAG] for English. 2 Positive Range Concatenation Grammars This section only presents the basics of RCGs, more details can be found in (Boullier, 2000b). A positive range concatenation grammar [PRCG] is a 5-tuple where is a finite set of nonterminal symbols (also called predicate names), and are finite, disjoint sets of terminal symbols and variable symbols respectively, is the start predicate name, and is a finite set of clauses where and each of is a predicate of the form where is its arity, , and each of , , is an argument. Each occurrence of a predicate in the LHS (resp. RHS) of a clause is a predicate definition (resp. call). Clauses which define predicate name are called -clauses. Each predicate name has a fixed arity whose value is a</context>
<context citStr="Boullier, 2000" endWordPosition="1161" position="6657" startWordPosition="1160">n its RHS; simple if it is non-combinatorial, nonerasing and linear. These definitions extend naturally from clause to set of clauses (i.e., grammar). In this paper we will not consider negative RCGs, since the guide construction algorithm An input string ,is a sentence iff the empty string (of instantiated predicates) can be derived from , the instantiation of the start predicate on the whole source text. Such a sequence of instantiated predicates is called a complete derivation. presented is Section 3 is not valid for this class. Thus, in the sequel, we shall assume that RCGs are PRCGs. In (Boullier, 2000b) is presented a parsing algorithm which, for any RCG and any input string of length , produces a parse forest in time. The exponent , called degree of , is the maximum number of free (independent) bounds in a clause. For a non-bottom-uperasing RCG, is less than or equal to the maximum value, for all clauses, of the sum where, for a clause , is its arity and is the number of (different) variables in its LHS predicate. . Let be the initial PRCG and let be the generated 1-PRCG. Informally, to each -ary predicate name we shall associate unary predicate names , each corresponding to one argument </context>
<context citStr="Boullier, 2000" endWordPosition="1485" position="8366" startWordPosition="1484">, the following set of clauses, in which , and are variables and and are terminal symbols, defines the 3-copy language which is not a CF language [CFL] and even lies beyond the formal power of TAGs. This PRCG is transformed by the above algorithm into a 1-PRCG whose clause set is It is not difficult to show that . This transformation algorithm works for any PRCG. Moreover, if we restrict ourselves to the class of PRCGs that are non-combinatorial and non-bottom-up-erasing, it is easy to check that the constructed 1-PRCG is also non-combinatorial and non-bottom-up-erasing. It has been shown in (Boullier, 2000a) that non-combinatorial and nonbottom-up-erasing 1-RCLs can be parsed in cubic time after a simple grammatical transformation. In order to reach this cubic parse time, we assume in the sequel that any RCG at hand is a noncombinatorial and non-bottom-up-erasing PRCG. However, even if this cubic time transformation is not performed, we can show that the (theoretical) throughput of the parser for cannot be less than the throughput of the parser for . In other words, if we consider the parsers for and and if we recall the end of Section 2, it is easy to show that the degrees, say and , of their </context>
<context citStr="Boullier, 2000" endWordPosition="3108" position="17607" startWordPosition="3107">is a noun (suffix -n) that can occur in all trees of the “n”, “nxn” or “nn” families (everywhere a terminal leaf of category noun occurs). Since, in this two-step process, the inputs are not sequences of terminal symbols but instead simple DAG structures, as the one depicted in Figure 1, we have accordingly implemented in our RCG system the ability to handle inputs that are simple DAGs of tokens.5 In Section 3, we have seen that the language defined by a guiding grammar for some RCG , is a superset of , the language defined by . If is a simple PRCG, is a simple 1-PRCG, and thus is a CFL (see (Boullier, 2000a)). In other words, in the case of TAGs, our transformation algorithm approximates the initial tree-adjoining language by a CFL, and the steps of CF parsing performed by the guiding parser can well be understood in terms of TAG parsing. The original algorithm in (Boullier, 1998) performs a one-to-one mapping between elementary trees and clauses, initial trees generate simple unary clauses while auxiliary trees generate simple binary clauses. Our transformation algorithm leaves unary clauses unchanged (simple unary clauses are in fact CF productions). For binary -clauses, our algorithm generat</context>
</contexts>
<marker>Boullier, 2000</marker>
<rawString>P. Boullier. 2000a. A cubic time extension of contextfree grammars. Grammars, 3(2/3):111–131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Boullier</author>
</authors>
<title>Range concatenation grammars.</title>
<date>2000</date>
<booktitle>In Proceedings of the Sixth International Workshop on Parsing Technologies (IWPT</booktitle>
<pages>53--64</pages>
<location>Trento, Italy,</location>
<contexts>
<context citStr="Boullier, 2000" endWordPosition="535" position="3227" startWordPosition="534">istic polynomial time. For example, any mildly context-sensitive language is a PRCL. In Section 2, we present the definitions of PRCGs and PRCLs. Then, in Section 3, we design an algorithm which transforms any PRCL into another PRCL ,such that the (theoretical) parse time for is less than or equal to the parse time for : the parser for will be guided by the parser for . Last, in Section 4, we relate some experiments with a wide coverage tree-adjoining grammar [TAG] for English. 2 Positive Range Concatenation Grammars This section only presents the basics of RCGs, more details can be found in (Boullier, 2000b). A positive range concatenation grammar [PRCG] is a 5-tuple where is a finite set of nonterminal symbols (also called predicate names), and are finite, disjoint sets of terminal symbols and variable symbols respectively, is the start predicate name, and is a finite set of clauses where and each of is a predicate of the form where is its arity, , and each of , , is an argument. Each occurrence of a predicate in the LHS (resp. RHS) of a clause is a predicate definition (resp. call). Clauses which define predicate name are called -clauses. Each predicate name has a fixed arity whose value is a</context>
<context citStr="Boullier, 2000" endWordPosition="1161" position="6657" startWordPosition="1160">n its RHS; simple if it is non-combinatorial, nonerasing and linear. These definitions extend naturally from clause to set of clauses (i.e., grammar). In this paper we will not consider negative RCGs, since the guide construction algorithm An input string ,is a sentence iff the empty string (of instantiated predicates) can be derived from , the instantiation of the start predicate on the whole source text. Such a sequence of instantiated predicates is called a complete derivation. presented is Section 3 is not valid for this class. Thus, in the sequel, we shall assume that RCGs are PRCGs. In (Boullier, 2000b) is presented a parsing algorithm which, for any RCG and any input string of length , produces a parse forest in time. The exponent , called degree of , is the maximum number of free (independent) bounds in a clause. For a non-bottom-uperasing RCG, is less than or equal to the maximum value, for all clauses, of the sum where, for a clause , is its arity and is the number of (different) variables in its LHS predicate. . Let be the initial PRCG and let be the generated 1-PRCG. Informally, to each -ary predicate name we shall associate unary predicate names , each corresponding to one argument </context>
<context citStr="Boullier, 2000" endWordPosition="1485" position="8366" startWordPosition="1484">, the following set of clauses, in which , and are variables and and are terminal symbols, defines the 3-copy language which is not a CF language [CFL] and even lies beyond the formal power of TAGs. This PRCG is transformed by the above algorithm into a 1-PRCG whose clause set is It is not difficult to show that . This transformation algorithm works for any PRCG. Moreover, if we restrict ourselves to the class of PRCGs that are non-combinatorial and non-bottom-up-erasing, it is easy to check that the constructed 1-PRCG is also non-combinatorial and non-bottom-up-erasing. It has been shown in (Boullier, 2000a) that non-combinatorial and nonbottom-up-erasing 1-RCLs can be parsed in cubic time after a simple grammatical transformation. In order to reach this cubic parse time, we assume in the sequel that any RCG at hand is a noncombinatorial and non-bottom-up-erasing PRCG. However, even if this cubic time transformation is not performed, we can show that the (theoretical) throughput of the parser for cannot be less than the throughput of the parser for . In other words, if we consider the parsers for and and if we recall the end of Section 2, it is easy to show that the degrees, say and , of their </context>
<context citStr="Boullier, 2000" endWordPosition="3108" position="17607" startWordPosition="3107">is a noun (suffix -n) that can occur in all trees of the “n”, “nxn” or “nn” families (everywhere a terminal leaf of category noun occurs). Since, in this two-step process, the inputs are not sequences of terminal symbols but instead simple DAG structures, as the one depicted in Figure 1, we have accordingly implemented in our RCG system the ability to handle inputs that are simple DAGs of tokens.5 In Section 3, we have seen that the language defined by a guiding grammar for some RCG , is a superset of , the language defined by . If is a simple PRCG, is a simple 1-PRCG, and thus is a CFL (see (Boullier, 2000a)). In other words, in the case of TAGs, our transformation algorithm approximates the initial tree-adjoining language by a CFL, and the steps of CF parsing performed by the guiding parser can well be understood in terms of TAG parsing. The original algorithm in (Boullier, 1998) performs a one-to-one mapping between elementary trees and clauses, initial trees generate simple unary clauses while auxiliary trees generate simple binary clauses. Our transformation algorithm leaves unary clauses unchanged (simple unary clauses are in fact CF productions). For binary -clauses, our algorithm generat</context>
</contexts>
<marker>Boullier, 2000</marker>
<rawString>P. Boullier. 2000b. Range concatenation grammars. In Proceedings of the Sixth International Workshop on Parsing Technologies (IWPT 2000), pages 53– 64, Trento, Italy, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
</authors>
<title>Relating complexity to practical performance in parsing with wide-coverage unification grammars.</title>
<date>1994</date>
<booktitle>In Proceedings of the 32th Annual Meeting of the Association for Computational Linguistics (ACL’94),</booktitle>
<pages>287--294</pages>
<institution>Mexico State University at Las Cruces,</institution>
<location>New</location>
<contexts>
<context citStr="Carroll, 1994" endWordPosition="4498" position="25545" startWordPosition="4497">abases) but, if we consider the various attempts of guided parsing reported in the literature, ours is one of the very few examples in which important savings are noted. One reason for that seems to be the extreme simplicity of the interface between the guiding and the guided process: the guide only performs a direct access into the guiding structure. Moreover, this guiding structure is (part of) the usual parse forest output by the guiding parser, without any transduction (see for example in (Nederhof, 1998) how a FSA can guide a CF parser). As already noted by many authors (see for example (Carroll, 1994)), the choice of a (parsing) algorithm, as far as its throughput is concerned, cannot rely only on its theoretical complexity but must also take into account practical experiments. Complexity analysis gives worst-case upper bounds which may well not be reached, and which implies constants that may have a preponderant effect on the typical size ranges of the application. We have also noted that guiding parsers can be used in classical TAG parsers, as efficient and (very) accurate tree selectors. More generally, we are currently investigating the possibility to use guiding parsers as shallow par</context>
</contexts>
<marker>Carroll, 1994</marker>
<rawString>John Carroll. 1994. Relating complexity to practical performance in parsing with wide-coverage unification grammars. In Proceedings of the 32th Annual Meeting of the Association for Computational Linguistics (ACL’94), pages 287–294, New Mexico State University at Las Cruces, New Mexico, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
</authors>
<title>An introduction to tree adjoining grammars.</title>
<date>1987</date>
<booktitle>Mathematics of Language,</booktitle>
<pages>87--114</pages>
<editor>In A. Manaster-Ramer, editor,</editor>
<publisher>John Benjamins,</publisher>
<location>Amsterdam.</location>
<contexts>
<context citStr="Joshi, 1987" endWordPosition="2818" position="16000" startWordPosition="2817">mportant difference stems from the radical difference in approaches between “classical” TAG parsing and “usual” RCL parsing. In the former, through lexicalization, the input sentence allows the selection of tree schemata which are then instantiated on the corresponding inflected forms, thus the TAG is not really part of the parser. While in the latter, the (non-lexicalized) grammar is precompiled into an optimized automaton.3 Since the instantiation of all tree schemata 1We assume here that the reader has at least some cursory notions of this formalism. An introduction to TAG can be found in (Joshi, 1987). 2We first stripped the original TAG of its feature structures in order to get a pure featureless TAG. 3The advantages of this approach might be balanced by the size of the automaton, but we shall see later on that it can be made to stay reasonable, at least in the case at hand. by the complete dictionary is impracticable, we designed a two-step process. For example, from the sentence “George loved himself .”, a lever first produces the sequence “George n-n nxnn nn-n loved tnx0vnx1-v tnx0vnx1s2- v tnx0vs1-v himself tnx0n1-n nxn-n . spu-punct spus-punct ”, and, in a second phase, this sequence</context>
</contexts>
<marker>Joshi, 1987</marker>
<rawString>A. K. Joshi. 1987. An introduction to tree adjoining grammars. In A. Manaster-Ramer, editor, Mathematics of Language, pages 87–114. John Benjamins, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kay</author>
</authors>
<title>Guides and oracles for linear-time parsing.</title>
<date>2000</date>
<booktitle>In Proceedings of the Sixth International Workshop on Parsing Technologies (IWPT</booktitle>
<pages>6--9</pages>
<location>Trento, Italy,</location>
<contexts>
<context citStr="Kay, 2000" endWordPosition="288" position="1792" startWordPosition="287"> Introduction Usually, during a nondeterministic process, when a nondeterministic choice occurs, one explores all possible ways, either in parallel or one after the other, using a backtracking mechanism. In both cases, the nondeterministic process may be assisted by another process to which it asks its way. This assistant may be either a guide or an oracle. An oracle always indicates all the good ways that will eventually lead to success, and those good ways only, while a guide will indicate all the good ways but may also indicate some wrong ways. In other words, an oracle is a perfect guide (Kay, 2000), and the worst guide indicates all possible ways. Given two problems and and their respective solutions and , if they are such that , any algorithm which solves is a candidate guide for nondeterministic algorithms solving . Obviously, supplementary conditions have to be fulfilled for to be a guide. The first one deals with relative efficiency: it assumes that problem can be solved more efficiently than problem . Of course, parsers are privileged candidates to be guided. In this paper we apply this technique to the parsing of a subset of RCLs that are the languages defined by RCGs. The syntact</context>
</contexts>
<marker>Kay, 2000</marker>
<rawString>M. Kay. 2000. Guides and oracles for linear-time parsing. In Proceedings of the Sixth International Workshop on Parsing Technologies (IWPT 2000), pages 6–9, Trento, Italy, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V S Lakshmanan</author>
<author>C H Yim</author>
</authors>
<title>Can filters do magic for deductive databases?</title>
<date>1991</date>
<booktitle>In 3rd UK Annual Conference on Logic Programming,</booktitle>
<pages>174--189</pages>
<publisher>Springer Verlag.</publisher>
<location>Edinburgh,</location>
<contexts>
<context citStr="Lakshmanan and Yim, 1991" endWordPosition="4389" position="24913" startWordPosition="4386"> when one wants to increase parsing efficiency. With a wide coverage English TAG, on a small sample set of short sentences, a guided parser is on the average three times faster than its non-guided counterpart, while, for longer sentences, more than one order of magnitude may be expected. However, the guided parser speed is very sensitive to the level of the guide, which must be chosen very carefully since potential benefits may be overcome by the time taken by the guiding structure book-keeping procedures. Of course, the filtering principle related in this paper is not novel (see for example (Lakshmanan and Yim, 1991) for deductive databases) but, if we consider the various attempts of guided parsing reported in the literature, ours is one of the very few examples in which important savings are noted. One reason for that seems to be the extreme simplicity of the interface between the guiding and the guided process: the guide only performs a direct access into the guiding structure. Moreover, this guiding structure is (part of) the usual parse forest output by the guiding parser, without any transduction (see for example in (Nederhof, 1998) how a FSA can guide a CF parser). As already noted by many authors </context>
</contexts>
<marker>Lakshmanan, Yim, 1991</marker>
<rawString>V.S. Lakshmanan and C.H. Yim. 1991. Can filters do magic for deductive databases? In 3rd UK Annual Conference on Logic Programming, pages 174–189, Edinburgh, April. Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M-J Nederhof</author>
</authors>
<title>Context-free parsing through regular approximation.</title>
<date>1998</date>
<booktitle>In Proceedings of the International Workshop on Finite State Methods in Natural Language Processing,</booktitle>
<location>Ankara, Turkey, JuneJuly.</location>
<contexts>
<context citStr="Nederhof, 1998" endWordPosition="4478" position="25445" startWordPosition="4477">iple related in this paper is not novel (see for example (Lakshmanan and Yim, 1991) for deductive databases) but, if we consider the various attempts of guided parsing reported in the literature, ours is one of the very few examples in which important savings are noted. One reason for that seems to be the extreme simplicity of the interface between the guiding and the guided process: the guide only performs a direct access into the guiding structure. Moreover, this guiding structure is (part of) the usual parse forest output by the guiding parser, without any transduction (see for example in (Nederhof, 1998) how a FSA can guide a CF parser). As already noted by many authors (see for example (Carroll, 1994)), the choice of a (parsing) algorithm, as far as its throughput is concerned, cannot rely only on its theoretical complexity but must also take into account practical experiments. Complexity analysis gives worst-case upper bounds which may well not be reached, and which implies constants that may have a preponderant effect on the typical size ranges of the application. We have also noted that guiding parsers can be used in classical TAG parsers, as efficient and (very) accurate tree selectors. </context>
</contexts>
<marker>Nederhof, 1998</marker>
<rawString>M.-J. Nederhof. 1998. Context-free parsing through regular approximation. In Proceedings of the International Workshop on Finite State Methods in Natural Language Processing, Ankara, Turkey, JuneJuly.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M-J Nederhof</author>
</authors>
<title>Practical experiments with regular approximation of context-free languages.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>1</issue>
<contexts>
<context citStr="Nederhof, 2000" endWordPosition="2503" position="14105" startWordPosition="2502"> guided parser?” Clearly, in the general case, no definite answer can be brought to such a question, since the total parse time may depend not only on the input grammar, the (quality of) the guiding grammar (e.g., is not a too “large” superset of ), the guide level, but also it may depend on the parsed sentence itself. Thus, in our opinion, only the results of practical experiments may globally decide if using a guided parser is worthwhile . Another potential problem may come from the size of the guiding grammar itself. In particular, experiments with regular approximation of CFLs related in (Nederhof, 2000) show that most reported methods are not practical for large CF grammars, because of the high costs of obtaining the minimal DFSA. In our case, it can easily be shown that the increase in size of the guiding grammars is bounded by a constant factor and thus seems a priori acceptable from a practical point of view. The next section depicts the practical experiments we have performed to validate our approach. 5 Experiments with an English Grammar In order to compare a (normal) RCL parser and its guided versions, we looked for an existing widecoverage grammar. We chose the grammar for English des</context>
</contexts>
<marker>Nederhof, 2000</marker>
<rawString>M.-J. Nederhof. 2000. Practical experiments with regular approximation of context-free languages. Computational Linguistics, 26(1):17–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Sarkar</author>
</authors>
<title>Practical experiments in parsing using tree adjoining grammars.</title>
<date>2000</date>
<booktitle>In Proceedings of the Fifth International Workshop on Tree Adjoining Grammars and Related Formalisms (TAG+5),</booktitle>
<pages>193--198</pages>
<institution>University of Paris</institution>
<location>Jussieu, Paris, France,</location>
<contexts>
<context citStr="Sarkar, 2000" endWordPosition="3799" position="21576" startWordPosition="3798"> 30.560 5.210 Table 2: Guiding parsers times (sec) parser load module initial 3.063 guided 8.374 -guided 14.530 Table 3: RCL parser sizes (MB) parser sample set 35-word sent. initial 5.810 3 679.570 guided 1.580 63.570 -guided 2.440 49.150 XTAG 4282.870 5 days Table 4: Parse times (sec) Table 1: RCGs facts The sizes of these RCL parsers (load modules) are in Table 3 while their parse times are in Table 4.7 We have also noted in the last line, for reference, the times of the latest XTAG parser (February 2001),8 on our sample set and on the 35-word sentence.9 6 Guiding Parser as Tree Filter In (Sarkar, 2000), there is some evidence to indicate that in LTAG parsing the number of trees selected by the words in a sentence (a measure of the syntactic lexical ambiguity of the sentence) is a better predictor of complexity than the number of words in the sentence. Thus, the accuracy of the tree selection process may be crucial for parsing speeds. In this section, we wish to briefly compare the tree selections performed, on the one hand by the words in a sentence and, on the other hand, by a guiding parser. Such filters can be used, for example, as pre-processors in classical [L]TAG parsing. With a guidi</context>
<context citStr="Sarkar, 2000" endWordPosition="4022" position="22826" startWordPosition="4021">., a clause) is kept, not because it has been selected by a word in the input sentence, but because an instantiation of that clause belongs to the guiding structure. The recall of both filters is 100%, since all pertinent trees are necessarily selected by the input words and present in the guiding structure. On the other hand, for the tree selection by the words in a sentence, the precision measured on our sam7The time taken by the lexer phase is linear in the length of the input sentences and is negligible. 8It implements a chart-based head-corner parsing algorithm for lexicalized TAGs, see (Sarkar, 2000). This parser can be run in two phases, the second one being devoted to the evaluation of the features structures on the parse forest built during the first phase. Of course, the times reported in that paper are only those of the first pass. Moreover, the various parameters have been set so that the resulting parse trees and ours are similar. Almost half the sample sentences give identical results in both that system and ours. For the other half, it seems that the differences come from the way the co-anchoring problem is handled in both systems. To be fair, it must be noted that the time taken</context>
</contexts>
<marker>Sarkar, 2000</marker>
<rawString>A. Sarkar. 2000. Practical experiments in parsing using tree adjoining grammars. In Proceedings of the Fifth International Workshop on Tree Adjoining Grammars and Related Formalisms (TAG+5), pages 193–198, University of Paris 7, Jussieu, Paris, France, May.</rawString>
</citation>
<citation valid="true">
<title>the research group XTAG.</title>
<date>1995</date>
<tech>Technical Report IRCS 95-03,</tech>
<institution>Institute for Research in Cognitive Science, University of Pennsylvania,</institution>
<location>Philadelphia, PA, USA,</location>
<marker>1995</marker>
<rawString>the research group XTAG. 1995. A lexicalized tree adjoining grammar for English. Technical Report IRCS 95-03, Institute for Research in Cognitive Science, University of Pennsylvania, Philadelphia, PA, USA, March.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>