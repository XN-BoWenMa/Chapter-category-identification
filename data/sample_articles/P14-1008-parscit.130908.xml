<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant confidence="0.000000" no="0">
<title confidence="0.976789">
Logical Inference on Dependency-based Compositional Semantics
</title>
<author confidence="0.988554">
Ran Tian Yusuke Miyao Takuya Matsuzaki
</author>
<affiliation confidence="0.989679">
National Institute of Informatics, Japan
</affiliation>
<email confidence="0.992477">
{tianran,yusuke,takuya-matsuzaki}@nii.ac.jp
</email>
<sectionHeader confidence="0.994227" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.98505275">Dependency-based Compositional Semantics (DCS) is a framework of natural language semantics with easy-to-process structures as well as strict semantics. In this paper, we equip the DCS framework with logical inference, by defining abstract denotations as an abstraction of the computing process of denotations in original DCS. An inference engine is built to achieve inference on abstract denotations. Furthermore, we propose a way to generate on-the-fly knowledge in logical inference, by combining our framework with the idea of tree transformation. Experiments on FraCaS and PASCAL RTE datasets show promising results.</bodyText>
<sectionHeader confidence="0.998362" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.994279438596491">Dependency-based Compositional Semantics (DCS) provides an intuitive way to model semantics of questions, by using simple dependency-like trees (Liang et al., 2011). It is expressive enough to represent complex natural language queries on a relational database, yet simple enough to be latently learned from question-answer pairs. In this paper, we equip DCS with logical inference, which, in one point of view, is “the best way of testing an NLP system’s semantic capacity” (Cooper et al., 1996). It should be noted that, however, a framework primarily designed for question answering is not readily suited for logical inference. Because, answers returned by a query depend on the specific database, but implication is independent of any databases. For example, answers to the question “What books are read by students?”, should always be a subset of answers to “What books are ever read by anyone?”, no matter how we store the data of students and how many records of books are there in our database. Thus, our first step is to fix a notation which abstracts the calculation process of DCS trees, so as to clarify its meaning without the aid of any existing database. The idea is to borrow a minimal set of operators from relational algebra (Codd, 1970), which is already able to formulate the calculation in DCS and define abstract denotation, which is an abstraction of the computation of denotations guided by DCS trees. Meanings of sentences then can be represented by primary relations among abstract denotations. This formulation keeps the simpleness and computability of DCS trees mostly unaffected; for example, our semantic calculation for DCS trees is parallel to the denotation computation in original DCS. An inference engine is built to handle inference on abstract denotations. Moreover, to compensate the lack of background knowledge in practical inference, we combine our framework with the idea of tree transformation (Bar-Haim et al., 2007), to propose a way of generating knowledge in logical representation from entailment rules (Szpektor et al., 2007), which are by now typically considered as syntactic rewriting rules. We test our system on FraCaS (Cooper et al., 1996) and PASCAL RTE datasets (Dagan et al., 2006). The experiments show: (i) a competitive performance on FraCaS dataset; (ii) a big impact of our automatically generated on-the-fly knowledge in achieving high recall for a logicbased RTE system; and (iii) a result that outperforms state-of-the-art RTE system on RTE5 data. Our whole system is publicly released and can be downloaded from http://kmcs.nii.ac. jp/tianran/tifmo/.</bodyText>
<sectionHeader confidence="0.98569" genericHeader="method">
2 The Idea
</sectionHeader>
<bodyText confidence="0.99991225">In this section we describe the idea of representing natural language semantics by DCS trees, and achieving inference by computing logical relations among the corresponding abstract denotations.</bodyText>
<page confidence="0.985859">
79
</page>
<note confidence="0.798108">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 79–89,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
read
</note>
<figureCaption confidence="0.999299">
Figure 1: The DCS tree of “students read books”
</figureCaption>
<figure confidence="0.863422585365854">
OBJ
SUBJ
ARG ARG
student book
have
SUBJ
SUBJ
OBJ
ARG ⊂ ARG
ARG ARG
Mary dog
Tom animal
ARG
OBJ
have
love
SUBJ
OBJ
SUBJ
ARG ARG
ARG
Tom
dog
Mary
T: love H:
OBJ
read
OBJ
New York Times
A Tale of Two Cities
Ulysses
...
Figure 2: DCS trees of “Mary loves every dog”
(Left-Up), “Tom has a dog” (Left-Down), and
“Tom has an animal that Mary loves” (Right).
student book SUBJ
ARG ARG Mark
Mark A Tale of Two Cities Mary
John Ulysses John
Emily ... ...
...
</figure>
<tableCaption confidence="0.989776">
Table 1: Databases of student, book, and read
</tableCaption>
<subsectionHeader confidence="0.852995">
2.1 DCS trees
</subsectionHeader>
<bodyText confidence="0.99992276">DCS trees has been proposed to represent natural language semantics with a structure similar to dependency trees (Liang et al., 2011) (Figure 1). For the sentence “students read books”, imagine a database consists of three tables, namely, a set of students, a set of books, and a set of “reading” events (Table 1). The DCS tree in Figure 1 is interpreted as a command for querying these tables, obtaining “reading” entries whose “SUBJ” field is student and whose “OBJ” field is book. The result is a set {John reads Ulysses, ...1, which is called a denotation. DCS trees can be extended to represent linguistic phenomena such as quantification and coreference, with additional markers introducing additional operations on tables. Figure 2 shows an example with a quantifier “every”, which is marked as “C” on the edge (love)OBJ-ARG(dog) and interpreted as a division operator qOBJ ⊂ (§2.2). Optimistically, we believe DCS can provide a framework of semantic representation with sufficiently wide coverage for real-world texts. The strict semantics of DCS trees brings us the idea of applying DCS to logical inference. This is not trivial, however, because DCS works under the assumption that databases are explicitly available. Obviously this is unrealistic for logical inference on unrestricted texts, because we cannot prepare a database for everything in the world. This fact fairly restricts the applicable tasks of DCS. Our solution is to redefine DCS trees without the aid of any databases, by considering each node of a DCS tree as a content word in a sentence (but may no longer be a table in a specific database), while each edge represents semantic relations between two words. The labels on both ends of an edge, such as SUBJ (subject) and OBJ (object), are considered as semantic roles of the corresponding words1. To formulate the database querying process defined by a DCS tree, we provide formal semantics to DCS trees by employing relational algebra (Codd, 1970) for representing the query. As described below, we represent meanings of sentences with abstract denotations, and logical relations among sentences are computed as relations among their abstract denotations. In this way, we can perform inference over formulas of relational algebra, without computing database entries explicitly.</bodyText>
<subsectionHeader confidence="0.999197">
2.2 Abstract denotations
</subsectionHeader>
<bodyText confidence="0.981180217391304">Abstract denotations are formulas constructed from a minimal set of relational algebra (Codd, 1970) operators, which is already able to formulate the database queries defined by DCS trees. For example, the semantics of “students read books” is given by the abstract denotation: Fl = read n (studentSUBJ x bookOBJ), where read, student and book denote sets represented by these words respectively, and wr represents the set w considered as the domain of the semantic role r (e.g. bookOBJ is the set of books considered as objects). The operators n and x represent intersection and Cartesian product respectively, both borrowed from relational algebra. It is not hard to see the abstract denotation denotes the intersection of the “reading” set (as illustrated by the “read” table in Table 1) with the product of “student” set and “book” set, which results in the same denotation as computed by the DCS tree in Figure 1, i.e. {John reads Ulysses, ...1. However, the point is that Fl itself is an algebraic formula that does not depend on any concrete databases. Formally, we introduce the following constants:</bodyText>
<listItem confidence="0.996057">• W: a universal set containing all entities.</listItem>
<footnote confidence="0.993769">
1The semantic role ARG is specifically defined for denot-
ing nominal predicate.
</footnote>
<page confidence="0.99837">
80
</page>
<bodyText confidence="0.71686475">example phrase abstract denotation / statement compound noun petfish pet n fish modification nice day day n (WARG x niceMOD) temporal relation boys study at night study n (boySUBJ x nightTIME)</bodyText>
<figure confidence="0.575298875">
relative clause books that book n πOBJ(read
students read n(studentSUBJ x WOBJ))
quantification all men die man C πSUBJ(die)
hypernym dog C animal
derivation all criminals commit criminal C πSUBJ(commitn
a crime (WSUBJ x crimeOBJ))
antonym rise fall
negation no dogs are hurt dog πOBJ(hurt)
</figure>
<tableCaption confidence="0.993585">
Table 2: Abstract denotations and statements
</tableCaption>
<listItem confidence="0.992228">• Content words: a content word (e.g. read) defines a set representing the word (e.g. read={(x, y)  |read(x, y)}).</listItem>
<bodyText confidence="0.662887">In addition we introduce following functions:</bodyText>
<listItem confidence="0.914539076923077">• x: the Cartesian product of two sets. • n: the intersection of two sets. • 7rr: projection onto domain of semantic role r (e.g. 7rOBJ(read) = {y  |]x; read(x, y)}). Generally we admit projections onto multiple semantics roles, denoted by 7rR where R is a set of semantic roles. • Lr: relabeling (e.g. LOBJ(book) = bookOBJ). • qr ⊂: the division operator, where qr⊂(A, B) is defined as the largest set X which satisfies Br x X C A.2 This is used to formulate universal quantifiers, such as “Mary loves every dog” and “books read by all students”.</listItem>
<bodyText confidence="0.992787333333333">An abstract denotation is then defined as finite applications of functions on either constants or other abstract denotations.</bodyText>
<subsectionHeader confidence="0.997377">
2.3 Statements
</subsectionHeader>
<bodyText confidence="0.9068081">As the semantics of DCS trees is formulated by abstract denotations, the meanings of declarative sentences are represented by statements on abstract denotations. Statements are declarations of some relations among abstract denotations, for which we consider the following set relations: Non-emptiness A =� 0: the set A is not empty. Subsumption A C B: set A is subsumed by B.3 Roughly speaking, the relations correspond to the logical concepts satisfiability and entailment.</bodyText>
<footnote confidence="0.997839">
2If A and B has the same dimension, q⊂(A, B) is either
0 or {*} (0-dimension point set), depending on if A C B.
3Using division operator, subsumption can be represented
by non-emptiness, since for sets A, B of the same dimension,
</footnote>
<equation confidence="0.511749">
q⊂(A, B) =� 0 4* A C B.
</equation>
<bodyText confidence="0.99572875">Abstract denotations and statements are convenient for representing semantics of various types of expressions and linguistic knowledge. Some examples are shown in Table 2.4</bodyText>
<subsectionHeader confidence="0.994077">
2.4 Logical inference on DCS
</subsectionHeader>
<bodyText confidence="0.9992825">Based on abstract denotations, we briefly describe our process to apply DCS to textual inference.</bodyText>
<subsectionHeader confidence="0.63787">
2.4.1 Natural language to DCS trees
</subsectionHeader>
<bodyText confidence="0.9999594">To obtain DCS trees from natural language, we use Stanford CoreNLP5 for dependency parsing (Socher et al., 2013), and convert Stanford dependencies to DCS trees by pattern matching on POS tags and dependency labels.6 Currently we use the following semantic roles: ARG, SUBJ, OBJ, IOBJ, TIME and MOD. The semantic role MOD is used for any restrictive modifiers. Determiners such as “all”, “every” and “each” trigger quantifiers, as shown in Figure 2.</bodyText>
<subsectionHeader confidence="0.397484">
2.4.2 DCS trees to statements
</subsectionHeader>
<bodyText confidence="0.999975636363637">A DCS tree T = (N, £) is defined as a rooted tree, where each node a E N is labeled with a content word w(a) and each edge (a, a0) E £ C N x N is labeled with a pair of semantic roles (r, r0)7. Here a is the node nearer to the root. Furthermore, for each edge (a, a0) we can optionally assign a quantification marker. Abstract denotation of a DCS tree can be calculated in a bottom-up manner. For example, the abstract denotation of H in Figure 2 is calculated from the leaf node Mary, and then:</bodyText>
<equation confidence="0.732221">
Node love (Mary loves):
F2 = love n (MarySUBJ x WOBJ)
Node animal (Animal that Mary loves):
F3 = animal n 7rOBJ(F2)
Node have (Tom has an animal that Mary loves):
F4 = have n (TomSUBJ x (F3)OBJ).
</equation>
<bodyText confidence="0.9997875">Formally, suppose the root a of a DCS tree T has children 7-1, ... , 7-n, and edges (a, 7-1), ... , (a, 7-n) labeled by (r1, r01), ... , (rn, r0n), respectively. The abstract denotation of T is defined as:</bodyText>
<equation confidence="0.543132">
Lri(7rr'i([Tτi])) x WRo\ri),
</equation>
<footnote confidence="0.986399">
4Negation and disjointness (“I I”) are explained in §2.5.
5http://nlp.stanford.edu/software/
corenlp.shtml
6In (Liang et al., 2011) DCS trees are learned from QA
pairs and database entries. We obtain DCS trees from depen-
dency trees, to bypass the need of a concrete database.
7The definition differs slightly from the original Liang et
al. (2011), mainly for the sake of simplicity and clarity.
</footnote>
<equation confidence="0.987725615384615">
[T ]=w(a) n (
n
n
i=1
81
T
dog C 7rOBJ(F2) dog C animal Axiom 8
7rOBJ(F6) = dog n F7 F6 =� 0 Axiom 4 dog C F3
T
dog n F7 =� 0
dog n F7 C F3 n F7 Axiom 6
7rOBJ(F4) = F3 n F7 F3 n F7 =� 0 Axiom 4
F4 =� 0
</equation>
<figureCaption confidence="0.995392">
Figure 3: An example of proof using abstract denotations
</figureCaption>
<figure confidence="0.99010675">
1. W =�0
2.AnBCA
3. Br x qr⊂(A, B) C A
4. 7rR(A) =�0 G A =�0
</figure>
<listItem confidence="0.57833125">5. (A C B &amp; B C C) A C C 6. (A C B &amp; A =� 0) B =� 0 7. A C B 7rR(A) C 7rR(B) 8. (C C A &amp; C C B) C C A n B</listItem>
<tableCaption confidence="0.99764">
Table 3: An excerpt of axioms
where Tτi is the subtree of T rooted at τi, and Rσ is the set of possible semantic roles for content word w(σ) (e.g.</tableCaption>
<bodyText confidence="0.999874111111111">Rlove = {SUBJ, OBJ}), and WRσ\ri is the product of W which has dimension Rσ \ ri (e.g.W{SUBJ,OBJ}\SUBJ = WOBJ). When universal quantifiers are involved, we need to add division operators to the formula. If (σ, τi) is assigned by a quantification marker “C”8, then the abstract denotation is9 where T0 is the same tree as T except that the edge (σ, τi) is removed.</bodyText>
<equation confidence="0.893202">
[T ]=qri ⊂(πRσ\{r1,...,ri−1}([T �]),πr� i([Tτi])),
</equation>
<bodyText confidence="0.9973072">For example, the abstract denotation of the first sentence of T in Figure 2 (Mary loves every dog) is calculated from F2 (Mary loves) as</bodyText>
<equation confidence="0.9345895">
F5 = qOBJ
⊂ (πOBJ(F2), dog).
</equation>
<bodyText confidence="0.999889333333333">After the abstract denotation [T ] is calculated, the statement representing the meaning of the sentence is defined as [T ] =� 0. For example, the statement of “students read books” is read n (studentSUBJ x bookOBJ) =� 0, and the statement of “Mary loves every dog” is equivalent to dog C πOBJ(F2).10</bodyText>
<equation confidence="0.928346">
qOBJ
⊂ (πOBJ(F2), dog) =� 0, which is logically
</equation>
<subsectionHeader confidence="0.80615">
2.4.3 Logical inference
</subsectionHeader>
<bodyText confidence="0.999615666666667">Since meanings of sentences are represented by statements on abstract denotations, logical inference among sentences is reduced to deriving new relations among abstract denotations. This is done by applying axioms to known statements, and approximately 30 axioms are implemented (Table 3).</bodyText>
<footnote confidence="0.9818912">
8Multiple quantifiers can be processed similarly.
9The result of IT ] depends on the order of the children
T1, ... , Tn. Different orders correspond to readings of differ-
ent quantifier scopes.
10See Footnote 2,3.
</footnote>
<bodyText confidence="0.979391142857143">These are algebraic properties of abstract denotations, among which we choose a set of axioms that can be handled efficiently and enable most common types of inference seen in natural language. For the example in Figure 2, by constructing the following abstract denotations: Tom has a dog:</bodyText>
<equation confidence="0.668998666666667">
F6 = have n (TomSUBJ x dogOBJ)
Objects that Tom has:
F7 = πOBJ(have n (TomSUBJ x WOBJ)),
</equation>
<bodyText confidence="0.9982125">we can use the lexical knowledge dog C animal, the statements of T (i.e. dog C πOBJ(F2) and F6 =� 0), and the axioms in Table 3,11 to prove the statement of H (i.e. F4 =� 0) (Figure 3). We built an inference engine to perform logical inference on abstract denotations as above. In this logical system, we treat abstract denotations as terms and statements as atomic sentences, which are far more easier to handle than first order predicate logic (FOL) formulas. Furthermore, all implemented axioms are horn clauses, hence we can employ forward-chaining, which is very efficient.</bodyText>
<subsectionHeader confidence="0.968666">
2.5 Extensions
</subsectionHeader>
<bodyText confidence="0.999910125">Further extensions of our framework are made to deal with additional linguistic phenomena, as briefly explained below. Negation To deal with negation in our forwardchaining inference engine, we introduce one more relation on abstract denotations, namely disjointness A 11 B, meaning that A and B are disjoint sets. Using disjointness we implemented two types of negations: (i) atomic negation, for each content word w we allow negation w¯ of that word, characterized by the property w 11 ¯w; and (ii) root negation, for a DCS tree T and its denotation [T ], the negation of T is represented by T 11 T, meaning that T = 0 in its effect. Selection Selection operators in relational algebra select a subset from a set to satisfy some specific properties.</bodyText>
<footnote confidence="0.694646">
11Algebraic identities, such as IrOBJ(F4) = F3 ∩ F7 and
IrOBJ(F6) = dog ∩ F7, are also axioms.
</footnote>
<page confidence="0.986256">
82
</page>
<bodyText confidence="0.999958363636364">This can be employed to represent linguistic phenomena such as downward monotonicity and generalized quantifiers. In the current system, we implement (i) superlatives, e.g.shighest(mountain n (WARG x AsiaMOD)) (the highest mountain in Asia) and (ii) numerics, e.g.stwo(pet n fish) (two pet fish), where sf is a selection marker. Selection operators are implemented as markers assigned to abstract denotations, with specially designed axioms. For example superlatives satisfy the following property: A C B &amp; shighest(B) C A S shighest(B) = shighest(A). New rules can be added if necessary. Coreference We use Stanford CoreNLP to resolve coreferences (Raghunathan et al., 2010), whereas coreference is implemented as a special type of selection. If a node Q in a DCS tree T belongs to a mention cluster m, we take the abstract denotation [Tσ] and make a selection sm([Tσ]), which is regarded as the abstract denotation of that mention. Then all selections of the same mention cluster are declared to be equal.</bodyText>
<sectionHeader confidence="0.974924" genericHeader="method">
3 Generating On-the-fly Knowledge
</sectionHeader>
<bodyText confidence="0.99926575">Recognizing textual entailment (RTE) is the task of determining whether a given textual statement H can be inferred by a text passage T. For this, our primary textual inference system operates as:</bodyText>
<listItem confidence="0.977852625">1. For a T-H pair, apply dependency parsing and coreference resolution. 2. Perform rule-based conversion from dependency parses to DCS trees, which are translated to statements on abstract denotations. 3. Use statements of T and linguistic knowledge as premises, and try to prove statements of H by our inference engine.</listItem>
<bodyText confidence="0.999672416666667">However, this method does not work for realworld datasets such as PASCAL RTE (Dagan et al., 2006), because of the knowledge bottleneck: it is often the case that the lack of sufficient linguistic knowledge causes failure of inference, thus the system outputs “no entailment” for almost all pairs (Bos and Markert, 2005). The transparent syntax-to-semantics interface of DCS enables us to back off to NLP techniques during inference for catching up the lack of knowledge. We extract fragments of DCS trees as paraphrase candidates, translate them back to linguis-</bodyText>
<figureCaption confidence="0.99659">
Figure 4: RTE system
tic expressions, and apply distributional similarity to judge their validity.</figureCaption>
<bodyText confidence="0.996895428571429">In this way, our framework combines distributional and logical semantics, which is also the main subject of Lewis and Steedman (2013) and Beltagy et al.(2013). As follows, our full system (Figure 4) additionally invokes linguistic knowledge on-the-fly:</bodyText>
<listItem confidence="0.9630544">4. If H is not proven, compare DCS trees of T and H, and generate path alignments. 5. Aligned paths are evaluated by a similarity score to estimate their likelihood of being paraphrases. Path alignments with scores higher than a threshold are accepted. 6. Convert accepted path alignments into statements on abstract denotations, use them in logical inference as new knowledge, and try to prove H again.</listItem>
<subsectionHeader confidence="0.999117">
3.1 Generating path alignments
</subsectionHeader>
<bodyText confidence="0.991743928571428">On-the-fly knowledge is generated by aligning paths in DCS trees. A path is considered as joining two germs in a DCS tree, where a germ is defined as a specific semantic role of a node. For example, Figure 5 shows DCS trees of the following sentences (a simplified pair from RTE2-dev): T: Tropical storm Debby is blamed for deaths. H: A storm has caused loss of life. The germ OBJ(blame) and germ ARG(death) in DCS tree of T are joined by the underscored path. Two paths are aligned if the joined germs are aligned, and we impose constraints on aligned germs to inhibit meaningless alignments, as described below.</bodyText>
<subsectionHeader confidence="0.998792">
3.2 Aligning germs by logical clues
</subsectionHeader>
<bodyText confidence="0.9129375">Two germs are aligned if they are both at leaf nodes (e.g. ARG(death) in T and ARG(life) in H, Figure 5), or they already have part of their meanings in common, by some logical clues.</bodyText>
<figure confidence="0.994978630769231">
T/H
On-the-fly
knowledge
Language
resources
Parsing
Coreference
Inference
Yes/No
DCS trees
Axioms
Abstract
denotations
83
MOD
ARG
ARG
ARG
life
storm
MOD
ARG
tropical
MOD
ARG
tropical
OBJ
blame IOBJ H :
ARG ARG
Debby death
ARG
ARG
storm
MOD
ARG
tropical
T :
cause
SUBJ
ARG
storm
OBJ
ARG
loss
MOD
ARG
life
[[Whatnis tropical storm, Debby,
⊂[[What is icaf storm, le 11
ad is blamed fordeat and cause A of i JJ
T : blame T :
OBJ
IOBJ
ARG
Debby
cause
ARG ARG
Debby death
SUBJ
OBJ
ARG
loss
ARG
ARG
storm
</figure>
<figureCaption confidence="0.999461">
Figure 5: Aligned paths (underscored by the solid
lines) and aligned germs (joined by the dotted line)
</figureCaption>
<bodyText confidence="0.999618222222222">To formulate this properly, we define the abstract denotation of a germ, which, intuitively, represents the meaning of the germ in the specific sentence. The abstract denotation of a germ is defined in a top-down manner: for the root node P of a DCS tree T, we define its denotation [P]T as the denotation of the entire tree [T ]; for a non-root node T and its parent node Q, let the edge (Q, T) be labeled by semantic roles (r, r'), then define</bodyText>
<equation confidence="0.73316">
[T]T = [TT] n (ιr,(7rr([Q]T )) x WRτ\r,).
</equation>
<bodyText confidence="0.999084774193548">Now for a germ r(Q), the denotation is defined as the projection of the denotation of node Q onto the specific semantic role r: [r(Q)]T = 7rr([Q]T ). For example, the abstract denotation of germ ARG(book) in Figure 1 is defined as 7rARG(book n 7rOBJ(readn(studentSUBJ xbookOBJ))), meaning “books read by students”. Similarly, denotation of germ OBJ(blame) in T of Figure 5 indicates the object of “blame” as in the sentence “Tropical storm Debby is blamed for death”, which is a tropical storm, is Debby, etc. Technically, each germ in a DCS tree indicates a variable when the DCS tree is translated to a FOL formula, and the abstract denotation of the germ corresponds to the set of consistent values (Liang et al., 2011) of that variable. The logical clue to align germs is: if there exists an abstract denotation, other than W, that is a superset of both abstract denotations of two germs, then the two germs can be aligned. A simple example is that ARG(storm) in T can be aligned to ARG(storm) in H, because their denotations have a common superset other than W, namely 7rARG(storm). Amore complicated example is that OBJ(blame) and SUBJ(cause) can be aligned, because inference can induce [OBJ(blame)]T = [ARG(Debby)]T = [ARG(storm)]T, as well as [SUBJ(cause)]H = [ARG(storm)]H, so they also have the common superset 7rARG(storm). However, for example, logical clues can avoid aligning ARG(storm) to ARG(loss), which is obviously meaningless.</bodyText>
<figureCaption confidence="0.986411666666667">
Figure 6: Tree transformation and generated on-
the-fly knowledge (subsumption of denotations
shown above the trees)
</figureCaption>
<subsectionHeader confidence="0.99981">
3.3 Scoring path alignments by similarity
</subsectionHeader>
<bodyText confidence="0.999975333333333">Aligned paths are evaluated by a similarity score, for which we use distributional similarity of the words that appear in the paths (§4.1). Only path alignments with high similarity scores can be accepted. Also, we only accept paths of length &lt; 5, to prevent too long paths to be aligned.</bodyText>
<subsectionHeader confidence="0.998568">
3.4 Applying path alignments
</subsectionHeader>
<bodyText confidence="0.9999168">Accepted aligned paths are converted into statements, which are used as new knowledge. The conversion is done by first performing a DCS tree transformation according to the aligned paths, and then declare a subsumption relation between the denotations of aligned germs. For example, to apply the aligned path pair generated in Figure 5, we use it to transform T into a new tree T’ (Figure 6), and then the aligned germs, OBJ(blame) in T and SUBJ(cause) in T’, will generate the on-the-fly knowledge: [OBJ(blame)]T C [SUBJ(cause)]T’. Similar to the tree transformation based approach to RTE (Bar-Haim et al., 2007), this process can also utilize lexical-syntactic entailment rules (Szpektor et al., 2007). Furthermore, since the on-the-fly knowledge is generated by transformed pairs of DCS trees, all contexts are preserved: in Figure 6, though the tree transformation can be seen as generated from the entailment rule “X is blamed for death —* X causes loss of life”, the generated on-the-fly knowledge, as shown above the trees, only fires with the additional condition that X is a tropical storm and is Debby. Hence, the process can also be used to generate knowledge from context sensitive rules (Melamud et al., 2013), which are known to have higher quality (Pantel et al., 2007; Clark and Harrison, 2009). However, it should be noted that using on-thefly knowledge in logical inference is not a trivial task.</bodyText>
<page confidence="0.995524">
84
</page>
<bodyText confidence="0.982466">For example, the FOL formula of the rule “X is blamed for death —* X causes loss of life” is:</bodyText>
<equation confidence="0.99669">
bx; (1a; blame(x, a) &amp; death(a)) —*
(1b, c; cause(x, b) &amp; loss(b, c) &amp; life(c)),
</equation>
<bodyText confidence="0.994904166666667">which is not a horn clause. The FOL formula for the context-preserved rule in Figure 6 is even more involved. Still, it can be efficiently treated by our inference engine because as a statement, the formula QOBJ(blame)]T C QSUBJ(cause)]T’ is an atomic sentence, more than a horn clause.</bodyText>
<sectionHeader confidence="0.999199" genericHeader="evaluation and result">
4 Experiments
</sectionHeader>
<bodyText confidence="0.972197">In this section, we evaluate our system on FraCaS (§4.2) and PASCAL RTE datasets (§4.3).</bodyText>
<subsectionHeader confidence="0.993447">
4.1 Language Resources
</subsectionHeader>
<bodyText confidence="0.999589333333333">The lexical knowledge we use are synonyms, hypernyms and antonyms extracted from WordNet12. We also add axioms on named entities, stopwords, numerics and superlatives. For example, named entities are singletons, so we add axioms such as bx;(x C Tom &amp; x =�0) —* Tom C x. To calculate the similarity scores of path alignments, we use the sum of word vectors of the words from each path, and calculate the cosine similarity. For example, the similarity score of the path alignment “OBJ(blame)TOBJ-ARG(death) � SUBJ(cause)OBJ-ARG(loss)MOD-ARG(life)” is calculated as the cosine similarity of vectors blame+death and cause+loss+life. Other structures in the paths, such as semantic roles, are ignored in the calculation. The word vectors we use are from Mikolov et al. (2013)13 (Mikolov13), and additional results are also shown using Turian et al. (2010)14 (Turian10). The threshold for accepted path alignments is set to 0.4, based on preexperiments on RTE development sets.</bodyText>
<subsectionHeader confidence="0.973422">
4.2 Experiments on FraCaS
</subsectionHeader>
<bodyText confidence="0.999969428571429">The FraCaS test suite contains 346 inference problems divided into 9 sections, each focused on a category of semantic phenomena. We use the data by MacCartney and Manning (2007), and experiment on the first section, Quantifiers, following Lewis and Steedman (2013). This section has 44 single premise and 30 multi premise problems. Most of yes, no, and unknown), we output “yes” if H is proven, or try to prove the negation of H if H is not proven.</bodyText>
<footnote confidence="0.996905">
12http://wordnet.princeton.edu/
13http://code.google.com/p/word2vec/
14http://metaoptimize.com/projects/
wordreprs/
</footnote>
<table confidence="0.9840034">
Single Prem. Multi Prem.
Lewis13 70 50
MacCartney07 84.1 -
MacCartney08 97.7 -
Our Sys. 79.5 80.0
</table>
<tableCaption confidence="0.999427">
Table 4: Accuracy (%) on FraCaS
the problems do not require lexical knowledge, so we use our primary textual inference system without on-the-fly knowledge nor WordNet, to test the performance of the DCS framework as formal semantics. To obtain the three-valued output (i.e.</tableCaption>
<bodyText confidence="0.999978068965517">To negate H, we use the root negation as described in §2.5. If the negation of H is proven, we output “no”, otherwise we output “unknown”. The result is shown in Table 4. Since our system uses an off-the-shelf dependency parser, and semantic representations are obtained from simple rule-based conversion from dependency trees, there will be only one (right or wrong) interpretation in face of ambiguous sentences. Still, our system outperforms Lewis and Steedman (2013)’s probabilistic CCG-parser. Compared to MacCartney and Manning (2007) and MacCartney and Manning (2008), our system does not need a pretrained alignment model, and it improves by making multi-sentence inferences. To sum up, the result shows that DCS is good at handling universal quantifiers and negations. Most errors are due to wrongly generated DCS trees (e.g.wrongly assigned semantic roles) or unimplemented quantifier triggers (e.g.“neither”) or generalized quantifiers (e.g.“at least a few”). These could be addressed by future work.</bodyText>
<subsectionHeader confidence="0.999156">
4.3 Experiments on PASCAL RTE datasets
</subsectionHeader>
<bodyText confidence="0.999972666666667">On PASCAL RTE datasets, strict logical inference is known to have very low recall (Bos and Markert, 2005), so on-the-fly knowledge is crucial in this setting. We test the effect of on-the-fly knowledge on RTE2, RTE3, RTE4 and RTE5 datasets, and compare our system with other approaches.</bodyText>
<subsectionHeader confidence="0.966235">
4.3.1 Impact of on-the-fly knowledge
</subsectionHeader>
<bodyText confidence="0.999062">Results on test data are shown in Table 5. When only primary knowledge is used in inference (the first row), recalls are actually very low; After we activate the on-the-fly knowledge, recalls jump to over 50%, with a moderate fall of precision. As a result, accuracies significantly increase.</bodyText>
<page confidence="0.999203">
85
</page>
<table confidence="0.99975975">
RTE2 RTE3 RTE4 RTE5
Prec. Rec. Acc. Prec. Rec. Acc. Prec. Rec. Acc. Prec. Rec. Acc.
Primary 70.9 9.8 52.9 73.2 7.3 51.1 89.7 5.2 52.3 82.6 6.3 52.5
+On-the-fly 57.6 66.5 58.8 63.7 64.6 63.0 60.0 57.4 59.6 69.9 55.7 65.8
</table>
<tableCaption confidence="0.917567">
Table 5: Impact of on-the-fly knowledge
</tableCaption>
<table confidence="0.99996075">
RTE2 RTE3 RTE4 RTE5
Bos06 60.6 - - -
MacCartney08 - 59.4 - -
Clark08 - - 56.5 -
Wang10 63.0 61.1 - -
Stern11 61.6 67.1 - 63.5
Stern12 - - - 64.0
Our Sys. 58.8 63.0 59.6 65.8
</table>
<tableCaption confidence="0.999932">
Table 6: Comparison with other systems
</tableCaption>
<subsectionHeader confidence="0.462657">
4.3.2 Comparison to other RTE systems
</subsectionHeader>
<bodyText confidence="0.999963423076923">A comparison between our system and other RTE systems is shown in Table 6. Bos06 (Bos and Markert, 2006) is a hybrid system combining deep features from a theorem prover and a model builder, together with shallow features such as lexical overlap and text length. MacCartney08 (MacCartney and Manning, 2008) uses natural logic to calculate inference relations between two superficially aligned sentences. Clark08 (Clark and Harrison, 2008) is a logic-based system utilizing various resources including WordNet and DIRT paraphrases (Lin and Pantel, 2001), and is tolerant to partially unproven H sentences in some degree. All of the three systems pursue a logical approach, while combining various techniques to achieve robustness. The result shows that our system has comparable performance. On the other hand, Wang10 (Wang and Manning, 2010) learns a treeedit model from training data, and captures entailment relation by tree edit distance. Stern11 (Stern and Dagan, 2011) and Stern12 (Stern et al., 2012) extend this framework to utilize entailment rules as tree transformations. These are more tailored systems using machine learning with many handcrafted features. Still, our unsupervised system outperforms the state-of-the-art on RTE5 dataset.</bodyText>
<subsectionHeader confidence="0.975817">
4.3.3 Analysis
</subsectionHeader>
<bodyText confidence="0.9995245">Summing up test data from RTE2 to RTE5, Figure 7 shows the proportion of all proven pairs and their precision. Less than 5% pairs can be proven primarily, with a precision of 77%. Over 40% pairs can be proven by one piece of on-the-fly knowledge, yet pairs do exist in which more than 2 pieces are necessary. The precisions of 1 and 2 pieces on-the-fly knowledge application are over</bodyText>
<figure confidence="0.335149">
Applied on-the-fly knowledge
</figure>
<figureCaption confidence="0.998318">
Figure 7: Proportion of proven pairs and their pre-
cision, w.r.t. pieces of on-the-fly knowledge.
</figureCaption>
<bodyText confidence="0.99997">60%, which is fairly high, given our rough estimation of the similarity score. As a comparison, Dinu and Wang (2009) studied the proportion of proven pairs and precision by applying DIRT rules to tree skeletons in RTE2 and RTE3 data. The proportion is 8% with precision 65% on RTE2, and proportion 6% with precision 72% on RTE3. Applied by our logical system, the noisy on-the-fly knowledge can achieve a precision comparable to higher quality resources such as DIRT. A major type of error is caused by the ignorance of semantic roles in calculation of similarity scores. For example, though “Italy beats Kazakhstan” is not primarily proven from “Italy is defeated by Kazakhstan”, our system does produce the path alignment “SUBJ(beat)OBJ ≈ OBJ(defeat)SUBJ” with a high similarity score. The impact of such errors depends on the data making methodology, though. It lowers precisions in RTE2 and RTE3 data, particularly in “IE” subtask (where precisions drop under 0.5). On the other hand, it occurs less often in “IR” subtask. Finally, to see if we “get lucky” on RTE5 data in the choice of word vectors and thresholds, we change the thresholds from 0.1 to 0.7 and draw the precision-recall curve, using two types of word vectors, Mikolov13 and Turian10. As shown in Figure 8, though the precision drops for Turian10, both curves show the pattern that our system keeps gaining recall while maintaining precision to a certain level. Not too much “magic” in Mikolov13 actually: for over 80% pairs, every node in DCS tree of H can be covered by a path of length ≤ 5 that has a corresponding path of length ≤ 5 in T with a similarity score &gt; 0.4.</bodyText>
<figure confidence="0.983311857142857">
0 1 2 &gt;=3
0.9 Proportion of proven pairs
0.8 Precision
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
86
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7
Recall
</figure>
<figureCaption confidence="0.999963">
Figure 8: Precision-Recall curve.
</figureCaption>
<sectionHeader confidence="0.955908" genericHeader="other">
5 Conclusion and Discussion
</sectionHeader>
<bodyText confidence="0.999890977272727">We have presented a method of deriving abstract denotation from DCS trees, which enables logical inference on DCS, and we developed a textual inference system based on the framework. Experimental results have shown the power of the representation that allows both strict inference as on FraCaS data and robust reasoning as on RTE data. Exploration of an appropriate meaning representation for querying and reasoning on knowledge bases has a long history. Description logic, being less expressive than FOL but featuring more efficient reasoning, is used as a theory base for Semantic Web (W3C, 2012). Ideas similar to our framework, including the use of sets in a representation that benefits efficient reasoning, are also found in description logic and knowledge representation community (Baader et al., 2003; Sowa, 2000; Sukkarieh, 2003). To our knowledge, however, their applications to logical inference beyond the use for database querying have not been much explored in the context of NLP. The pursue of a logic more suitable for natural language inference is not new. For instance, MacCartney and Manning (2008) has implemented a model of natural logic (Lakoff, 1970). While being computationally efficient, various inference patterns are out of the scope of their system. Much work has been done in mapping natural language into database queries (Cai and Yates, 2013; Kwiatkowski et al., 2013; Poon, 2013). Among these, the (λ-)DCS (Liang et al., 2011; Berant et al., 2013) framework defines algorithms that transparently map a labeled tree to a database querying procedure. Essentially, this is because DCS trees restrict the querying process to a very limited subset of possible operations. Our main contribution, the abstract denotation of DCS trees, can thus be considered as an attempt to characterize a fragment of FOL that is suited for both natural language inference and transparent syntaxsemantics mapping, through the choice of operations and relations on sets. We have demonstrated the utility of logical inference on DCS through the RTE task. A wide variety of strategies tackling the RTE task have been investigated (Androutsopoulos and Malakasiotis, 2010), including the comparison of surface strings (Jijkoun and De Rijke, 2005), syntactic and semantic structures (Haghighi et al., 2005; Snow et al., 2006; Zanzotto et al., 2009; Burchardt et al., 2009; Heilman and Smith, 2010; Wang and Manning, 2010), semantic vectors (Erk and Pad´o, 2009) and logical representations (Bos and Markert, 2005; Raina et al., 2005; Tatu and Moldovan, 2005). Acquisition of basic knowledge for RTE is also a huge stream of research (Lin and Pantel, 2001; Shinyama et al., 2002; Sudo et al., 2003; Szpektor et al., 2004; Fujita et al., 2012; Weisman et al., 2012; Yan et al., 2013). These previous works include various techniques for acquiring and incorporating different kinds of linguistic and world knowledge, and further fight against the knowledge bottleneck problem, e.g. by back-off to shallower representations. Logic-based RTE systems employ various approaches to bridge knowledge gaps. Bos and Markert (2005) proposes features from a model builder; Raina et al. (2005) proposes an abduction process; Tatu and Moldovan (2006) shows handcrafted rules could drastically improve the performance of a logic-based RTE system. As such, our current RTE system is at a proofof-concept stage, in that many of the above techniques are yet to be implemented. Nonetheless, we would like to emphasize that it already shows performance competitive to state-of-the-art systems on one data set (RTE5). Other directions of our future work include further exploitation of the new semantic representation. For example, since abstract denotations are readily suited for data querying, they can be used to verify newly generated assumptions by fact search in a database. This may open a way towards a hybrid approach to RTE wherein logical inference is intermingled with large scale database querying. Acknowledgments This research was supported by the Todai Robot Project at National Institute of Informatics.</bodyText>
<figure confidence="0.998031181818182">
0.85
0.8
0.75
0.7
0.65
0.6
0.55
0.5
M&amp;o1oM
TW1aR10
Precision
</figure>
<page confidence="0.967026">
87
</page>
<note confidence="0.395253111111111">
Ido Dagan, O. Glickman, and B. Magnini. 2006. The
pascal recognising textual entailment challenge. In
Machine Learning Challenges. Evaluating Predic-
tive Uncertainty, Visual Object Classification, and
Recognising Tectual Entailment.
References
Ion Androutsopoulos and Prodromos Malakasiotis.
2010. A survey of paraphrasing and textual entail-
ment methods. J. Artif. Int. Res., 38(1).
</note>
<reference confidence="0.999165130434783">
Franz Baader, Diego Calvanese, Deborah L. McGuin-
ness, Daniele Nardi, and Peter F. Patel-Schneider,
editors. 2003. The Description Logic Handbook:
Theory, Implementation, and Applications. Cam-
bridge University Press, New York, NY, USA.
Roy Bar-Haim, Ido Dagan, Iddo Greental, and Eyal
Shnarch. 2007. Semantic inference at the lexical-
syntactic level. In Proceedings of AAAI 2007.
Islam Beltagy, Cuong Chau, Gemma Boleda, Dan Gar-
rette, Katrin Erk, and Raymond Mooney. 2013.
Montague meets markov: Deep semantics with
probabilistic logical form. In Second Joint Con-
ference on Lexical and Computational Semantics
(*SEM).
Jonathan Berant, Andrew Chou, Roy Frostig, and Percy
Liang. 2013. Semantic parsing on Freebase from
question-answer pairs. In Proceedings of EMNLP
2013.
Johan Bos and Katja Markert. 2005. Recognising tex-
tual entailment with logical inference. In Proceed-
ings of EMNLP 2005.
Johan Bos and Katja Markert. 2006. When logical
inference helps determining textual entailment (and
when it doesnt). In Proceedings of the 2nd PASCAL
RTE Challenge Workshop.
Aljoscha Burchardt, Marco Pennacchiotti, Stefan
Thater, and Manfred Pinkal. 2009. Assessing the
impact of frame semantics on textual entailment.
Nat. Lang. Eng., 15(4).
Qingqing Cai and Alexander Yates. 2013. Large-scale
semantic parsing via schema matching and lexicon
extension. In Proceedings of ACL 2013.
Peter Clark and Phil Harrison. 2008. Recognizing tex-
tual entailment with logical inference. In Proceed-
ings of 2008 Text Analysis Conference (TAC’08).
Peter Clark and Phil Harrison. 2009. Large-scale ex-
traction and use of knowledge from text. In Pro-
ceedings of the Fifth International Conference on
Knowledge Capture (K-CAP’09).
E. F. Codd. 1970. A relational model of data for large
shared data banks. Commun. ACM, 13(6).
Robin Cooper, Dick Crouch, Jan Van Eijck, Chris
Fox, Johan Van Genabith, Jan Jaspars, Hans Kamp,
David Milward, Manfred Pinkal, Massimo Poesio,
and et al. 1996. Using the framework. FraCaS De-
liverable D, 16.
Georgiana Dinu and Rui Wang. 2009. Inference rules
and their application to recognizing textual entail-
ment. In Proceedings of EACL 2009.
Katrin Erk and Sebastian Pad´o. 2009. Paraphrase as-
sessment in structured vector space: Exploring pa-
rameters and datasets. In Proceedings of the Work-
shop on Geometrical Models of Natural Language
Semantics.
Atsushi Fujita, Pierre Isabelle, and Roland Kuhn.
2012. Enlarging paraphrase collections through
generalization and instantiation. In Proceedings of
EMNLP 2012.
Aria Haghighi, Andrew Ng, and Christopher Manning.
2005. Robust textual inference via graph matching.
In Proceedings of EMNLP 2005.
Michael Heilman and Noah A. Smith. 2010. Tree edit
models for recognizing textual entailments, para-
phrases, and answers to questions. In Proceedings
of NAACL 2010.
Valentin Jijkoun and Maarten De Rijke. 2005. Rec-
ognizing textual entailment: Is word similarity
enough? In Machine Learning Challenge Work-
shop, volume 3944 of LNCS, Springer.
Tom Kwiatkowski, Eunsol Choi, Yoav Artzi, and Luke
Zettlemoyer. 2013. Scaling semantic parsers with
on-the-fly ontology matching. In Proceedings of
EMNLP 2013.
George Lakoff. 1970. Linguistics and natural logic.
Synthese, 22(1-2).
Mike Lewis and Mark Steedman. 2013. Combined
distributional and logical semantics. Transactions
ofACL, 1.
Percy Liang, Michael Jordan, and Dan Klein. 2011.
Learning dependency-based compositional seman-
tics. In Proceedings of ACL 2011.
Dekang Lin and Patrick Pantel. 2001. Discovery of
inference rules for question-answering. Nat. Lang.
Eng., 7(4).
Bill MacCartney and Christopher D. Manning. 2007.
Natural logic for textual inference. In Proceedings
of the ACL-PASCAL Workshop on Textual Entail-
ment and Paraphrasing.
Bill MacCartney and Christopher D. Manning. 2008.
Modeling semantic containment and exclusion in
natural language inference. In Proceedings of Col-
ing 2008.
</reference>
<page confidence="0.98717">
88
</page>
<reference confidence="0.999901100000001">
Oren Melamud, Jonathan Berant, Ido Dagan, Jacob
Goldberger, and Idan Szpektor. 2013. A two level
model for context sensitive inference rules. In Pro-
ceedings of ACL 2013.
Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.
2013. Linguistic regularities in continuous space
word representations. In Proceedings of NAACL
2013.
Patrick Pantel, Rahul Bhagat, Bonaventura Coppola,
Timothy Chklovski, and Eduard Hovy. 2007. ISP:
Learning inferential selectional preferences. In Pro-
ceedings of NAACL 2007.
Hoifung Poon. 2013. Grounded unsupervised seman-
tic parsing. In Proceedings of ACL 2013.
Karthik Raghunathan, Heeyoung Lee, Sudarshan Ran-
garajan, Nate Chambers, Mihai Surdeanu, Dan Ju-
rafsky, and Christopher Manning. 2010. A multi-
pass sieve for coreference resolution. In Proceed-
ings of EMNLP 2010.
Rajat Raina, Andrew Y. Ng, and Christopher D. Man-
ning. 2005. Robust textual inference via learning
and abductive reasoning. In Proceedings of AAAI
2005.
Yusuke Shinyama, Satoshi Sekine, and Kiyoshi Sudo.
2002. Automatic paraphrase acquisition from news
articles. In Proceedings of HLT 2002.
Rion Snow, Lucy Vanderwende, and Arul Menezes.
2006. Effectively using syntax for recognizing false
entailment. In Proceedings of NAACL 2006.
Richard Socher, John Bauer, Christopher D. Manning,
and Ng Andrew Y. 2013. Parsing with compo-
sitional vector grammars. In Proceedings of ACL
2013.
John F. Sowa. 2000. Knowledge Representation:
Logical, Philosophical and Computational Founda-
tions. Brooks/Cole Publishing Co., Pacific Grove,
CA, USA.
Asher Stern and Ido Dagan. 2011. A confidence model
for syntactically-motivated entailment proofs. In
Proceedings of RANLP 2011.
Asher Stern, Roni Stern, Ido Dagan, and Ariel Felner.
2012. Efficient search for transformation-based in-
ference. In Proceedings of ACL 2012.
Kiyoshi Sudo, Satoshi Sekine, and Ralph Grishman.
2003. An improved extraction pattern representa-
tion model for automatic ie pattern acquisition. In
Proceedings of ACL 2003.
JanaZ. Sukkarieh. 2003. An expressive efficient rep-
resentation: Bridging a gap between nlp and kr.
In Vasile Palade, RobertJ. Howlett, and Lakhmi
Jain, editors, Knowledge-Based Intelligent Informa-
tion and Engineering Systems. Springer Berlin Hei-
delberg.
Idan Szpektor, Hristo Tanev, Ido Dagan, and Bonaven-
tura Coppola. 2004. Scaling web-based acquisition
of entailment relations. In Proceedings of EMNLP
2004.
Idan Szpektor, Eyal Shnarch, and Ido Dagan. 2007.
Instance-based evaluation of entailment rule acqui-
sition. In Proceedings of ACL 2007.
Marta Tatu and Dan Moldovan. 2005. A semantic ap-
proach to recognizing textual entailment. In Pro-
ceedings of EMNLP 2005.
Marta Tatu and Dan Moldovan. 2006. A logic-
based semantic approach to recognizing textual en-
tailment. In Proceedings of the COLING/ACL 2006.
Joseph Turian, Lev-Arie Ratinov, and Yoshua Bengio.
2010. Word representations: A simple and general
method for semi-supervised learning. In Proceed-
ings of ACL 2010.
W3C. 2012. Owl 2 web ontology language document
overview (second edition). www.w3.org/TR/owl2-
overview/.
Mengqiu Wang and Christopher Manning. 2010.
Probabilistic tree-edit models with structured latent
variables for textual entailment and question answer-
ing. In Proceedings of Coling 2010.
Hila Weisman, Jonathan Berant, Idan Szpektor, and Ido
Dagan. 2012. Learning verb inference rules from
linguistically-motivated evidence. In Proceedings of
EMNLP 2012.
Yulan Yan, Chikara Hashimoto, Kentaro Torisawa,
Takao Kawai, Jun’ichi Kazama, and Stijn De Saeger.
2013. Minimally supervised method for multilin-
gual paraphrase extraction from definition sentences
on the web. In Proceedings of NAACL 2013.
Fabio massimo Zanzotto, Marco Pennacchiotti, and
Alessandro Moschitti. 2009. A machine learn-
ing approach to textual entailment recognition. Nat.
Lang. Eng., 15(4).
</reference>
<page confidence="0.999753">
89
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant confidence="0.925846" no="0">
<title confidence="0.996841">Logical Inference on Dependency-based Compositional Semantics</title>
<author confidence="0.998715">Ran Tian Yusuke Miyao Takuya Matsuzaki</author>
<affiliation confidence="0.999883">National Institute of Informatics,</affiliation>
<abstract confidence="0.992899117647059">Dependency-based Compositional Semantics (DCS) is a framework of natural language semantics with easy-to-process structures as well as strict semantics. In this paper, we equip the DCS framework logical inference, by defining abdenotations an abstraction of the computing process of denotations in original DCS. An inference engine is built to achieve inference on abstract denotations. Furthermore, we propose a way to generate on-the-fly knowledge in logical inference, by combining our framework with the idea of tree transformation. Experiments on FraCaS and PASCAL RTE datasets show promising results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>The Description Logic Handbook: Theory, Implementation, and Applications.</title>
<date>2003</date>
<editor>Franz Baader, Diego Calvanese, Deborah L. McGuinness, Daniele Nardi, and Peter F. Patel-Schneider, editors.</editor>
<publisher>Cambridge University Press,</publisher>
<location>New York, NY, USA.</location>
<marker>2003</marker>
<rawString>Franz Baader, Diego Calvanese, Deborah L. McGuinness, Daniele Nardi, and Peter F. Patel-Schneider, editors. 2003. The Description Logic Handbook: Theory, Implementation, and Applications. Cambridge University Press, New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roy Bar-Haim</author>
</authors>
<title>Ido Dagan, Iddo Greental, and Eyal Shnarch.</title>
<date>2007</date>
<booktitle>In Proceedings of AAAI</booktitle>
<marker>Bar-Haim, 2007</marker>
<rawString>Roy Bar-Haim, Ido Dagan, Iddo Greental, and Eyal Shnarch. 2007. Semantic inference at the lexicalsyntactic level. In Proceedings of AAAI 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Islam Beltagy</author>
<author>Cuong Chau</author>
<author>Gemma Boleda</author>
<author>Dan Garrette</author>
<author>Katrin Erk</author>
<author>Raymond Mooney</author>
</authors>
<title>Montague meets markov: Deep semantics with probabilistic logical form.</title>
<date>2013</date>
<booktitle>In Second Joint Conference on Lexical and Computational Semantics (*SEM).</booktitle>
<contexts>
<context citStr="Beltagy et al. (2013)" endWordPosition="3138" position="18464" startWordPosition="3135">owledge causes failure of inference, thus the system outputs “no entailment” for almost all pairs (Bos and Markert, 2005). The transparent syntax-to-semantics interface of DCS enables us to back off to NLP techniques during inference for catching up the lack of knowledge. We extract fragments of DCS trees as paraphrase candidates, translate them back to linguisFigure 4: RTE system tic expressions, and apply distributional similarity to judge their validity. In this way, our framework combines distributional and logical semantics, which is also the main subject of Lewis and Steedman (2013) and Beltagy et al. (2013). As follows, our full system (Figure 4) additionally invokes linguistic knowledge on-the-fly: 4. If H is not proven, compare DCS trees of T and H, and generate path alignments. 5. Aligned paths are evaluated by a similarity score to estimate their likelihood of being paraphrases. Path alignments with scores higher than a threshold are accepted. 6. Convert accepted path alignments into statements on abstract denotations, use them in logical inference as new knowledge, and try to prove H again. 3.1 Generating path alignments On-the-fly knowledge is generated by aligning paths in DCS trees. A pa</context>
</contexts>
<marker>Beltagy, Chau, Boleda, Garrette, Erk, Mooney, 2013</marker>
<rawString>Islam Beltagy, Cuong Chau, Gemma Boleda, Dan Garrette, Katrin Erk, and Raymond Mooney. 2013. Montague meets markov: Deep semantics with probabilistic logical form. In Second Joint Conference on Lexical and Computational Semantics (*SEM).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Berant</author>
<author>Andrew Chou</author>
<author>Roy Frostig</author>
<author>Percy Liang</author>
</authors>
<title>Semantic parsing on Freebase from question-answer pairs.</title>
<date>2013</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context citStr="Berant et al., 2013" endWordPosition="5776" position="34051" startWordPosition="5773">wever, their applications to logical inference beyond the use for database querying have not been much explored in the context of NLP. The pursue of a logic more suitable for natural language inference is not new. For instance, MacCartney and Manning (2008) has implemented a model of natural logic (Lakoff, 1970). While being computationally efficient, various inference patterns are out of the scope of their system. Much work has been done in mapping natural language into database queries (Cai and Yates, 2013; Kwiatkowski et al., 2013; Poon, 2013). Among these, the (λ-)DCS (Liang et al., 2011; Berant et al., 2013) framework defines algorithms that transparently map a labeled tree to a database querying procedure. Essentially, this is because DCS trees restrict the querying process to a very limited subset of possible operations. Our main contribution, the abstract denotation of DCS trees, can thus be considered as an attempt to characterize a fragment of FOL that is suited for both natural language inference and transparent syntaxsemantics mapping, through the choice of operations and relations on sets. We have demonstrated the utility of logical inference on DCS through the RTE task. A wide variety of</context>
</contexts>
<marker>Berant, Chou, Frostig, Liang, 2013</marker>
<rawString>Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. 2013. Semantic parsing on Freebase from question-answer pairs. In Proceedings of EMNLP 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
<author>Katja Markert</author>
</authors>
<title>Recognising textual entailment with logical inference.</title>
<date>2005</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context citStr="Bos and Markert, 2005" endWordPosition="3056" position="17964" startWordPosition="3053"> apply dependency parsing and coreference resolution. 2. Perform rule-based conversion from dependency parses to DCS trees, which are translated to statements on abstract denotations. 3. Use statements of T and linguistic knowledge as premises, and try to prove statements of H by our inference engine. However, this method does not work for realworld datasets such as PASCAL RTE (Dagan et al., 2006), because of the knowledge bottleneck: it is often the case that the lack of sufficient linguistic knowledge causes failure of inference, thus the system outputs “no entailment” for almost all pairs (Bos and Markert, 2005). The transparent syntax-to-semantics interface of DCS enables us to back off to NLP techniques during inference for catching up the lack of knowledge. We extract fragments of DCS trees as paraphrase candidates, translate them back to linguisFigure 4: RTE system tic expressions, and apply distributional similarity to judge their validity. In this way, our framework combines distributional and logical semantics, which is also the main subject of Lewis and Steedman (2013) and Beltagy et al. (2013). As follows, our full system (Figure 4) additionally invokes linguistic knowledge on-the-fly: 4. If</context>
<context citStr="Bos and Markert, 2005" endWordPosition="4738" position="27940" startWordPosition="4735">07) and MacCartney and Manning (2008), our system does not need a pretrained alignment model, and it improves by making multi-sentence inferences. To sum up, the result shows that DCS is good at handling universal quantifiers and negations. Most errors are due to wrongly generated DCS trees (e.g. wrongly assigned semantic roles) or unimplemented quantifier triggers (e.g. “neither”) or generalized quantifiers (e.g. “at least a few”). These could be addressed by future work. 4.3 Experiments on PASCAL RTE datasets On PASCAL RTE datasets, strict logical inference is known to have very low recall (Bos and Markert, 2005), so on-the-fly knowledge is crucial in this setting. We test the effect of on-the-fly knowledge on RTE2, RTE3, RTE4 and RTE5 datasets, and compare our system with other approaches. 4.3.1 Impact of on-the-fly knowledge Results on test data are shown in Table 5. When only primary knowledge is used in inference (the first row), recalls are actually very low; After we activate the on-the-fly knowledge, recalls jump to over 50%, with a moderate fall of precision. As a result, accuracies significantly increase. 85 RTE2 RTE3 RTE4 RTE5 Prec. Rec. Acc. Prec. Rec. Acc. Prec. Rec. Acc. Prec. Rec. Acc. P</context>
<context citStr="Bos and Markert, 2005" endWordPosition="5939" position="35087" startWordPosition="5935">ent syntaxsemantics mapping, through the choice of operations and relations on sets. We have demonstrated the utility of logical inference on DCS through the RTE task. A wide variety of strategies tackling the RTE task have been investigated (Androutsopoulos and Malakasiotis, 2010), including the comparison of surface strings (Jijkoun and De Rijke, 2005), syntactic and semantic structures (Haghighi et al., 2005; Snow et al., 2006; Zanzotto et al., 2009; Burchardt et al., 2009; Heilman and Smith, 2010; Wang and Manning, 2010), semantic vectors (Erk and Pad´o, 2009) and logical representations (Bos and Markert, 2005; Raina et al., 2005; Tatu and Moldovan, 2005). Acquisition of basic knowledge for RTE is also a huge stream of research (Lin and Pantel, 2001; Shinyama et al., 2002; Sudo et al., 2003; Szpektor et al., 2004; Fujita et al., 2012; Weisman et al., 2012; Yan et al., 2013). These previous works include various techniques for acquiring and incorporating different kinds of linguistic and world knowledge, and further fight against the knowledge bottleneck problem, e.g. by back-off to shallower representations. Logic-based RTE systems employ various approaches to bridge knowledge gaps. Bos and Markert</context>
</contexts>
<marker>Bos, Markert, 2005</marker>
<rawString>Johan Bos and Katja Markert. 2005. Recognising textual entailment with logical inference. In Proceedings of EMNLP 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
<author>Katja Markert</author>
</authors>
<title>When logical inference helps determining textual entailment (and when it doesnt).</title>
<date>2006</date>
<booktitle>In Proceedings of the 2nd PASCAL RTE Challenge Workshop.</booktitle>
<contexts>
<context citStr="Bos and Markert, 2006" endWordPosition="4940" position="29070" startWordPosition="4937">se. 85 RTE2 RTE3 RTE4 RTE5 Prec. Rec. Acc. Prec. Rec. Acc. Prec. Rec. Acc. Prec. Rec. Acc. Primary 70.9 9.8 52.9 73.2 7.3 51.1 89.7 5.2 52.3 82.6 6.3 52.5 +On-the-fly 57.6 66.5 58.8 63.7 64.6 63.0 60.0 57.4 59.6 69.9 55.7 65.8 Table 5: Impact of on-the-fly knowledge RTE2 RTE3 RTE4 RTE5 Bos06 60.6 - - - MacCartney08 - 59.4 - - Clark08 - - 56.5 - Wang10 63.0 61.1 - - Stern11 61.6 67.1 - 63.5 Stern12 - - - 64.0 Our Sys. 58.8 63.0 59.6 65.8 Table 6: Comparison with other systems 4.3.2 Comparison to other RTE systems A comparison between our system and other RTE systems is shown in Table 6. Bos06 (Bos and Markert, 2006) is a hybrid system combining deep features from a theorem prover and a model builder, together with shallow features such as lexical overlap and text length. MacCartney08 (MacCartney and Manning, 2008) uses natural logic to calculate inference relations between two superficially aligned sentences. Clark08 (Clark and Harrison, 2008) is a logic-based system utilizing various resources including WordNet and DIRT paraphrases (Lin and Pantel, 2001), and is tolerant to partially unproven H sentences in some degree. All of the three systems pursue a logical approach, while combining various techniqu</context>
</contexts>
<marker>Bos, Markert, 2006</marker>
<rawString>Johan Bos and Katja Markert. 2006. When logical inference helps determining textual entailment (and when it doesnt). In Proceedings of the 2nd PASCAL RTE Challenge Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aljoscha Burchardt</author>
<author>Marco Pennacchiotti</author>
<author>Stefan Thater</author>
<author>Manfred Pinkal</author>
</authors>
<title>Assessing the impact of frame semantics on textual entailment.</title>
<date>2009</date>
<journal>Nat. Lang. Eng.,</journal>
<volume>15</volume>
<issue>4</issue>
<contexts>
<context citStr="Burchardt et al., 2009" endWordPosition="5917" position="34946" startWordPosition="5914"> trees, can thus be considered as an attempt to characterize a fragment of FOL that is suited for both natural language inference and transparent syntaxsemantics mapping, through the choice of operations and relations on sets. We have demonstrated the utility of logical inference on DCS through the RTE task. A wide variety of strategies tackling the RTE task have been investigated (Androutsopoulos and Malakasiotis, 2010), including the comparison of surface strings (Jijkoun and De Rijke, 2005), syntactic and semantic structures (Haghighi et al., 2005; Snow et al., 2006; Zanzotto et al., 2009; Burchardt et al., 2009; Heilman and Smith, 2010; Wang and Manning, 2010), semantic vectors (Erk and Pad´o, 2009) and logical representations (Bos and Markert, 2005; Raina et al., 2005; Tatu and Moldovan, 2005). Acquisition of basic knowledge for RTE is also a huge stream of research (Lin and Pantel, 2001; Shinyama et al., 2002; Sudo et al., 2003; Szpektor et al., 2004; Fujita et al., 2012; Weisman et al., 2012; Yan et al., 2013). These previous works include various techniques for acquiring and incorporating different kinds of linguistic and world knowledge, and further fight against the knowledge bottleneck proble</context>
</contexts>
<marker>Burchardt, Pennacchiotti, Thater, Pinkal, 2009</marker>
<rawString>Aljoscha Burchardt, Marco Pennacchiotti, Stefan Thater, and Manfred Pinkal. 2009. Assessing the impact of frame semantics on textual entailment. Nat. Lang. Eng., 15(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qingqing Cai</author>
<author>Alexander Yates</author>
</authors>
<title>Large-scale semantic parsing via schema matching and lexicon extension.</title>
<date>2013</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context citStr="Cai and Yates, 2013" endWordPosition="5758" position="33944" startWordPosition="5755">nowledge representation community (Baader et al., 2003; Sowa, 2000; Sukkarieh, 2003). To our knowledge, however, their applications to logical inference beyond the use for database querying have not been much explored in the context of NLP. The pursue of a logic more suitable for natural language inference is not new. For instance, MacCartney and Manning (2008) has implemented a model of natural logic (Lakoff, 1970). While being computationally efficient, various inference patterns are out of the scope of their system. Much work has been done in mapping natural language into database queries (Cai and Yates, 2013; Kwiatkowski et al., 2013; Poon, 2013). Among these, the (λ-)DCS (Liang et al., 2011; Berant et al., 2013) framework defines algorithms that transparently map a labeled tree to a database querying procedure. Essentially, this is because DCS trees restrict the querying process to a very limited subset of possible operations. Our main contribution, the abstract denotation of DCS trees, can thus be considered as an attempt to characterize a fragment of FOL that is suited for both natural language inference and transparent syntaxsemantics mapping, through the choice of operations and relations on</context>
</contexts>
<marker>Cai, Yates, 2013</marker>
<rawString>Qingqing Cai and Alexander Yates. 2013. Large-scale semantic parsing via schema matching and lexicon extension. In Proceedings of ACL 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Clark</author>
<author>Phil Harrison</author>
</authors>
<title>Recognizing textual entailment with logical inference.</title>
<date>2008</date>
<booktitle>In Proceedings of 2008 Text Analysis Conference (TAC’08).</booktitle>
<contexts>
<context citStr="Clark and Harrison, 2008" endWordPosition="4992" position="29404" startWordPosition="4988">rk08 - - 56.5 - Wang10 63.0 61.1 - - Stern11 61.6 67.1 - 63.5 Stern12 - - - 64.0 Our Sys. 58.8 63.0 59.6 65.8 Table 6: Comparison with other systems 4.3.2 Comparison to other RTE systems A comparison between our system and other RTE systems is shown in Table 6. Bos06 (Bos and Markert, 2006) is a hybrid system combining deep features from a theorem prover and a model builder, together with shallow features such as lexical overlap and text length. MacCartney08 (MacCartney and Manning, 2008) uses natural logic to calculate inference relations between two superficially aligned sentences. Clark08 (Clark and Harrison, 2008) is a logic-based system utilizing various resources including WordNet and DIRT paraphrases (Lin and Pantel, 2001), and is tolerant to partially unproven H sentences in some degree. All of the three systems pursue a logical approach, while combining various techniques to achieve robustness. The result shows that our system has comparable performance. On the other hand, Wang10 (Wang and Manning, 2010) learns a treeedit model from training data, and captures entailment relation by tree edit distance. Stern11 (Stern and Dagan, 2011) and Stern12 (Stern et al., 2012) extend this framework to utiliz</context>
</contexts>
<marker>Clark, Harrison, 2008</marker>
<rawString>Peter Clark and Phil Harrison. 2008. Recognizing textual entailment with logical inference. In Proceedings of 2008 Text Analysis Conference (TAC’08).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Clark</author>
<author>Phil Harrison</author>
</authors>
<title>Large-scale extraction and use of knowledge from text.</title>
<date>2009</date>
<booktitle>In Proceedings of the Fifth International Conference on Knowledge Capture (K-CAP’09).</booktitle>
<contexts>
<context citStr="Clark and Harrison, 2009" endWordPosition="4122" position="24150" startWordPosition="4119">ktor et al., 2007). Furthermore, since the on-the-fly knowledge is generated by transformed pairs of DCS trees, all contexts are preserved: in Figure 6, though the tree transformation can be seen as generated from the entailment rule “X is blamed for death —* X causes loss of life”, the generated on-the-fly knowledge, as shown above the trees, only fires with the additional condition that X is a tropical storm and is Debby. Hence, the process can also be used to generate knowledge from context sensitive rules (Melamud et al., 2013), which are known to have higher quality (Pantel et al., 2007; Clark and Harrison, 2009). However, it should be noted that using on-thefly knowledge in logical inference is not a trivial 84 task. For example, the FOL formula of the rule “X is blamed for death —* X causes loss of life” is: bx; (1a; blame(x, a) &amp; death(a)) —* (1b, c; cause(x, b) &amp; loss(b, c) &amp; life(c)), which is not a horn clause. The FOL formula for the context-preserved rule in Figure 6 is even more involved. Still, it can be efficiently treated by our inference engine because as a statement, the formula QOBJ(blame)]T C QSUBJ(cause)]T’ is an atomic sentence, more than a horn clause. 4 Experiments In this section,</context>
</contexts>
<marker>Clark, Harrison, 2009</marker>
<rawString>Peter Clark and Phil Harrison. 2009. Large-scale extraction and use of knowledge from text. In Proceedings of the Fifth International Conference on Knowledge Capture (K-CAP’09).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E F Codd</author>
</authors>
<title>A relational model of data for large shared data banks.</title>
<date>1970</date>
<journal>Commun. ACM,</journal>
<volume>13</volume>
<issue>6</issue>
<contexts>
<context citStr="Codd, 1970" endWordPosition="323" position="2087" startWordPosition="322">ers returned by a query depend on the specific database, but implication is independent of any databases. For example, answers to the question “What books are read by students?”, should always be a subset of answers to “What books are ever read by anyone?”, no matter how we store the data of students and how many records of books are there in our database. Thus, our first step is to fix a notation which abstracts the calculation process of DCS trees, so as to clarify its meaning without the aid of any existing database. The idea is to borrow a minimal set of operators from relational algebra (Codd, 1970), which is already able to formulate the calculation in DCS and define abstract denotation, which is an abstraction of the computation of denotations guided by DCS trees. Meanings of sentences then can be represented by primary relations among abstract denotations. This formulation keeps the simpleness and computability of DCS trees mostly unaffected; for example, our semantic calculation for DCS trees is parallel to the denotation computation in original DCS. An inference engine is built to handle inference on abstract denotations. Moreover, to compensate the lack of background knowledge in p</context>
<context citStr="Codd, 1970" endWordPosition="1036" position="6393" startWordPosition="1035">. This fact fairly restricts the applicable tasks of DCS. Our solution is to redefine DCS trees without the aid of any databases, by considering each node of a DCS tree as a content word in a sentence (but may no longer be a table in a specific database), while each edge represents semantic relations between two words. The labels on both ends of an edge, such as SUBJ (subject) and OBJ (object), are considered as semantic roles of the corresponding words1. To formulate the database querying process defined by a DCS tree, we provide formal semantics to DCS trees by employing relational algebra (Codd, 1970) for representing the query. As described below, we represent meanings of sentences with abstract denotations, and logical relations among sentences are computed as relations among their abstract denotations. In this way, we can perform inference over formulas of relational algebra, without computing database entries explicitly. 2.2 Abstract denotations Abstract denotations are formulas constructed from a minimal set of relational algebra (Codd, 1970) operators, which is already able to formulate the database queries defined by DCS trees. For example, the semantics of “students read books” is </context>
</contexts>
<marker>Codd, 1970</marker>
<rawString>E. F. Codd. 1970. A relational model of data for large shared data banks. Commun. ACM, 13(6).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robin Cooper</author>
<author>Dick Crouch</author>
<author>Jan Van Eijck</author>
<author>Chris Fox</author>
<author>Johan Van Genabith</author>
<author>Jan Jaspars</author>
<author>Hans Kamp</author>
<author>David Milward</author>
<author>Manfred Pinkal</author>
<author>Massimo Poesio</author>
</authors>
<title>Using the framework.</title>
<date>1996</date>
<journal>FraCaS Deliverable D,</journal>
<volume>16</volume>
<marker>Cooper, Crouch, Van Eijck, Fox, Van Genabith, Jaspars, Kamp, Milward, Pinkal, Poesio, 1996</marker>
<rawString>Robin Cooper, Dick Crouch, Jan Van Eijck, Chris Fox, Johan Van Genabith, Jan Jaspars, Hans Kamp, David Milward, Manfred Pinkal, Massimo Poesio, and et al. 1996. Using the framework. FraCaS Deliverable D, 16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Georgiana Dinu</author>
<author>Rui Wang</author>
</authors>
<title>Inference rules and their application to recognizing textual entailment.</title>
<date>2009</date>
<booktitle>In Proceedings of EACL</booktitle>
<contexts>
<context citStr="Dinu and Wang (2009)" endWordPosition="5228" position="30857" startWordPosition="5225">g up test data from RTE2 to RTE5, Figure 7 shows the proportion of all proven pairs and their precision. Less than 5% pairs can be proven primarily, with a precision of 77%. Over 40% pairs can be proven by one piece of on-the-fly knowledge, yet pairs do exist in which more than 2 pieces are necessary. The precisions of 1 and 2 pieces on-the-fly knowledge application are over Applied on-the-fly knowledge Figure 7: Proportion of proven pairs and their precision, w.r.t. pieces of on-the-fly knowledge. 60%, which is fairly high, given our rough estimation of the similarity score. As a comparison, Dinu and Wang (2009) studied the proportion of proven pairs and precision by applying DIRT rules to tree skeletons in RTE2 and RTE3 data. The proportion is 8% with precision 65% on RTE2, and proportion 6% with precision 72% on RTE3. Applied by our logical system, the noisy on-the-fly knowledge can achieve a precision comparable to higher quality resources such as DIRT. A major type of error is caused by the ignorance of semantic roles in calculation of similarity scores. For example, though “Italy beats Kazakhstan” is not primarily proven from “Italy is defeated by Kazakhstan”, our system does produce the path al</context>
</contexts>
<marker>Dinu, Wang, 2009</marker>
<rawString>Georgiana Dinu and Rui Wang. 2009. Inference rules and their application to recognizing textual entailment. In Proceedings of EACL 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
<author>Sebastian Pad´o</author>
</authors>
<title>Paraphrase assessment in structured vector space: Exploring parameters and datasets.</title>
<date>2009</date>
<booktitle>In Proceedings of the Workshop on Geometrical Models of Natural Language Semantics.</booktitle>
<marker>Erk, Pad´o, 2009</marker>
<rawString>Katrin Erk and Sebastian Pad´o. 2009. Paraphrase assessment in structured vector space: Exploring parameters and datasets. In Proceedings of the Workshop on Geometrical Models of Natural Language Semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Atsushi Fujita</author>
<author>Pierre Isabelle</author>
<author>Roland Kuhn</author>
</authors>
<title>Enlarging paraphrase collections through generalization and instantiation.</title>
<date>2012</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context citStr="Fujita et al., 2012" endWordPosition="5980" position="35315" startWordPosition="5977">nvestigated (Androutsopoulos and Malakasiotis, 2010), including the comparison of surface strings (Jijkoun and De Rijke, 2005), syntactic and semantic structures (Haghighi et al., 2005; Snow et al., 2006; Zanzotto et al., 2009; Burchardt et al., 2009; Heilman and Smith, 2010; Wang and Manning, 2010), semantic vectors (Erk and Pad´o, 2009) and logical representations (Bos and Markert, 2005; Raina et al., 2005; Tatu and Moldovan, 2005). Acquisition of basic knowledge for RTE is also a huge stream of research (Lin and Pantel, 2001; Shinyama et al., 2002; Sudo et al., 2003; Szpektor et al., 2004; Fujita et al., 2012; Weisman et al., 2012; Yan et al., 2013). These previous works include various techniques for acquiring and incorporating different kinds of linguistic and world knowledge, and further fight against the knowledge bottleneck problem, e.g. by back-off to shallower representations. Logic-based RTE systems employ various approaches to bridge knowledge gaps. Bos and Markert (2005) proposes features from a model builder; Raina et al. (2005) proposes an abduction process; Tatu and Moldovan (2006) shows handcrafted rules could drastically improve the performance of a logic-based RTE system. As such, </context>
</contexts>
<marker>Fujita, Isabelle, Kuhn, 2012</marker>
<rawString>Atsushi Fujita, Pierre Isabelle, and Roland Kuhn. 2012. Enlarging paraphrase collections through generalization and instantiation. In Proceedings of EMNLP 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Andrew Ng</author>
<author>Christopher Manning</author>
</authors>
<title>Robust textual inference via graph matching.</title>
<date>2005</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context citStr="Haghighi et al., 2005" endWordPosition="5905" position="34880" startWordPosition="5902">operations. Our main contribution, the abstract denotation of DCS trees, can thus be considered as an attempt to characterize a fragment of FOL that is suited for both natural language inference and transparent syntaxsemantics mapping, through the choice of operations and relations on sets. We have demonstrated the utility of logical inference on DCS through the RTE task. A wide variety of strategies tackling the RTE task have been investigated (Androutsopoulos and Malakasiotis, 2010), including the comparison of surface strings (Jijkoun and De Rijke, 2005), syntactic and semantic structures (Haghighi et al., 2005; Snow et al., 2006; Zanzotto et al., 2009; Burchardt et al., 2009; Heilman and Smith, 2010; Wang and Manning, 2010), semantic vectors (Erk and Pad´o, 2009) and logical representations (Bos and Markert, 2005; Raina et al., 2005; Tatu and Moldovan, 2005). Acquisition of basic knowledge for RTE is also a huge stream of research (Lin and Pantel, 2001; Shinyama et al., 2002; Sudo et al., 2003; Szpektor et al., 2004; Fujita et al., 2012; Weisman et al., 2012; Yan et al., 2013). These previous works include various techniques for acquiring and incorporating different kinds of linguistic and world kn</context>
</contexts>
<marker>Haghighi, Ng, Manning, 2005</marker>
<rawString>Aria Haghighi, Andrew Ng, and Christopher Manning. 2005. Robust textual inference via graph matching. In Proceedings of EMNLP 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Heilman</author>
<author>Noah A Smith</author>
</authors>
<title>Tree edit models for recognizing textual entailments, paraphrases, and answers to questions.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL</booktitle>
<contexts>
<context citStr="Heilman and Smith, 2010" endWordPosition="5921" position="34971" startWordPosition="5918">idered as an attempt to characterize a fragment of FOL that is suited for both natural language inference and transparent syntaxsemantics mapping, through the choice of operations and relations on sets. We have demonstrated the utility of logical inference on DCS through the RTE task. A wide variety of strategies tackling the RTE task have been investigated (Androutsopoulos and Malakasiotis, 2010), including the comparison of surface strings (Jijkoun and De Rijke, 2005), syntactic and semantic structures (Haghighi et al., 2005; Snow et al., 2006; Zanzotto et al., 2009; Burchardt et al., 2009; Heilman and Smith, 2010; Wang and Manning, 2010), semantic vectors (Erk and Pad´o, 2009) and logical representations (Bos and Markert, 2005; Raina et al., 2005; Tatu and Moldovan, 2005). Acquisition of basic knowledge for RTE is also a huge stream of research (Lin and Pantel, 2001; Shinyama et al., 2002; Sudo et al., 2003; Szpektor et al., 2004; Fujita et al., 2012; Weisman et al., 2012; Yan et al., 2013). These previous works include various techniques for acquiring and incorporating different kinds of linguistic and world knowledge, and further fight against the knowledge bottleneck problem, e.g. by back-off to sh</context>
</contexts>
<marker>Heilman, Smith, 2010</marker>
<rawString>Michael Heilman and Noah A. Smith. 2010. Tree edit models for recognizing textual entailments, paraphrases, and answers to questions. In Proceedings of NAACL 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Valentin Jijkoun</author>
<author>Maarten De Rijke</author>
</authors>
<title>Recognizing textual entailment: Is word similarity enough?</title>
<date>2005</date>
<booktitle>In Machine Learning Challenge Workshop,</booktitle>
<volume>3944</volume>
<publisher>Springer.</publisher>
<marker>Jijkoun, De Rijke, 2005</marker>
<rawString>Valentin Jijkoun and Maarten De Rijke. 2005. Recognizing textual entailment: Is word similarity enough? In Machine Learning Challenge Workshop, volume 3944 of LNCS, Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom Kwiatkowski</author>
<author>Eunsol Choi</author>
<author>Yoav Artzi</author>
<author>Luke Zettlemoyer</author>
</authors>
<title>Scaling semantic parsers with on-the-fly ontology matching.</title>
<date>2013</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context citStr="Kwiatkowski et al., 2013" endWordPosition="5762" position="33970" startWordPosition="5759">on community (Baader et al., 2003; Sowa, 2000; Sukkarieh, 2003). To our knowledge, however, their applications to logical inference beyond the use for database querying have not been much explored in the context of NLP. The pursue of a logic more suitable for natural language inference is not new. For instance, MacCartney and Manning (2008) has implemented a model of natural logic (Lakoff, 1970). While being computationally efficient, various inference patterns are out of the scope of their system. Much work has been done in mapping natural language into database queries (Cai and Yates, 2013; Kwiatkowski et al., 2013; Poon, 2013). Among these, the (λ-)DCS (Liang et al., 2011; Berant et al., 2013) framework defines algorithms that transparently map a labeled tree to a database querying procedure. Essentially, this is because DCS trees restrict the querying process to a very limited subset of possible operations. Our main contribution, the abstract denotation of DCS trees, can thus be considered as an attempt to characterize a fragment of FOL that is suited for both natural language inference and transparent syntaxsemantics mapping, through the choice of operations and relations on sets. We have demonstrate</context>
</contexts>
<marker>Kwiatkowski, Choi, Artzi, Zettlemoyer, 2013</marker>
<rawString>Tom Kwiatkowski, Eunsol Choi, Yoav Artzi, and Luke Zettlemoyer. 2013. Scaling semantic parsers with on-the-fly ontology matching. In Proceedings of EMNLP 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Lakoff</author>
</authors>
<date>1970</date>
<booktitle>Linguistics and natural logic. Synthese,</booktitle>
<pages>22--1</pages>
<contexts>
<context citStr="Lakoff, 1970" endWordPosition="5726" position="33744" startWordPosition="5725">eory base for Semantic Web (W3C, 2012). Ideas similar to our framework, including the use of sets in a representation that benefits efficient reasoning, are also found in description logic and knowledge representation community (Baader et al., 2003; Sowa, 2000; Sukkarieh, 2003). To our knowledge, however, their applications to logical inference beyond the use for database querying have not been much explored in the context of NLP. The pursue of a logic more suitable for natural language inference is not new. For instance, MacCartney and Manning (2008) has implemented a model of natural logic (Lakoff, 1970). While being computationally efficient, various inference patterns are out of the scope of their system. Much work has been done in mapping natural language into database queries (Cai and Yates, 2013; Kwiatkowski et al., 2013; Poon, 2013). Among these, the (λ-)DCS (Liang et al., 2011; Berant et al., 2013) framework defines algorithms that transparently map a labeled tree to a database querying procedure. Essentially, this is because DCS trees restrict the querying process to a very limited subset of possible operations. Our main contribution, the abstract denotation of DCS trees, can thus be </context>
</contexts>
<marker>Lakoff, 1970</marker>
<rawString>George Lakoff. 1970. Linguistics and natural logic. Synthese, 22(1-2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Lewis</author>
<author>Mark Steedman</author>
</authors>
<title>Combined distributional and logical semantics.</title>
<date>2013</date>
<journal>Transactions ofACL,</journal>
<volume>1</volume>
<contexts>
<context citStr="Lewis and Steedman (2013)" endWordPosition="3133" position="18438" startWordPosition="3130">ck of sufficient linguistic knowledge causes failure of inference, thus the system outputs “no entailment” for almost all pairs (Bos and Markert, 2005). The transparent syntax-to-semantics interface of DCS enables us to back off to NLP techniques during inference for catching up the lack of knowledge. We extract fragments of DCS trees as paraphrase candidates, translate them back to linguisFigure 4: RTE system tic expressions, and apply distributional similarity to judge their validity. In this way, our framework combines distributional and logical semantics, which is also the main subject of Lewis and Steedman (2013) and Beltagy et al. (2013). As follows, our full system (Figure 4) additionally invokes linguistic knowledge on-the-fly: 4. If H is not proven, compare DCS trees of T and H, and generate path alignments. 5. Aligned paths are evaluated by a similarity score to estimate their likelihood of being paraphrases. Path alignments with scores higher than a threshold are accepted. 6. Convert accepted path alignments into statements on abstract denotations, use them in logical inference as new knowledge, and try to prove H again. 3.1 Generating path alignments On-the-fly knowledge is generated by alignin</context>
<context citStr="Lewis and Steedman (2013)" endWordPosition="4449" position="26108" startWordPosition="4446">ructures in the paths, such as semantic roles, are ignored in the calculation. The word vectors we use are from Mikolov et al. (2013)13 (Mikolov13), and additional results are also shown using Turian et al. (2010)14 (Turian10). The threshold for accepted path alignments is set to 0.4, based on preexperiments on RTE development sets. 4.2 Experiments on FraCaS The FraCaS test suite contains 346 inference problems divided into 9 sections, each focused on a category of semantic phenomena. We use the data by MacCartney and Manning (2007), and experiment on the first section, Quantifiers, following Lewis and Steedman (2013). This section has 44 single premise and 30 multi premise problems. Most of 12http://wordnet.princeton.edu/ 13http://code.google.com/p/word2vec/ 14http://metaoptimize.com/projects/ wordreprs/ Single Prem. Multi Prem. Lewis13 70 50 MacCartney07 84.1 - MacCartney08 97.7 - Our Sys. 79.5 80.0 Table 4: Accuracy (%) on FraCaS the problems do not require lexical knowledge, so we use our primary textual inference system without on-the-fly knowledge nor WordNet, to test the performance of the DCS framework as formal semantics. To obtain the three-valued output (i.e. yes, no, and unknown), we output “ye</context>
</contexts>
<marker>Lewis, Steedman, 2013</marker>
<rawString>Mike Lewis and Mark Steedman. 2013. Combined distributional and logical semantics. Transactions ofACL, 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Michael Jordan</author>
<author>Dan Klein</author>
</authors>
<title>Learning dependency-based compositional semantics.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context citStr="Liang et al., 2011" endWordPosition="135" position="996" startWordPosition="132">CS framework with logical inference, by defining abstract denotations as an abstraction of the computing process of denotations in original DCS. An inference engine is built to achieve inference on abstract denotations. Furthermore, we propose a way to generate on-the-fly knowledge in logical inference, by combining our framework with the idea of tree transformation. Experiments on FraCaS and PASCAL RTE datasets show promising results. 1 Introduction Dependency-based Compositional Semantics (DCS) provides an intuitive way to model semantics of questions, by using simple dependency-like trees (Liang et al., 2011). It is expressive enough to represent complex natural language queries on a relational database, yet simple enough to be latently learned from question-answer pairs. In this paper, we equip DCS with logical inference, which, in one point of view, is “the best way of testing an NLP system’s semantic capacity” (Cooper et al., 1996). It should be noted that, however, a framework primarily designed for question answering is not readily suited for logical inference. Because, answers returned by a query depend on the specific database, but implication is independent of any databases. For example, a</context>
<context citStr="Liang et al., 2011" endWordPosition="724" position="4548" startWordPosition="721">t book have SUBJ SUBJ OBJ ARG ⊂ ARG ARG ARG Mary dog Tom animal ARG OBJ have love SUBJ OBJ SUBJ ARG ARG ARG Tom dog Mary T: love H: OBJ read OBJ New York Times A Tale of Two Cities Ulysses ... Figure 2: DCS trees of “Mary loves every dog” (Left-Up), “Tom has a dog” (Left-Down), and “Tom has an animal that Mary loves” (Right). student book SUBJ ARG ARG Mark Mark A Tale of Two Cities Mary John Ulysses John Emily ... ... ... Table 1: Databases of student, book, and read 2.1 DCS trees DCS trees has been proposed to represent natural language semantics with a structure similar to dependency trees (Liang et al., 2011) (Figure 1). For the sentence “students read books”, imagine a database consists of three tables, namely, a set of students, a set of books, and a set of “reading” events (Table 1). The DCS tree in Figure 1 is interpreted as a command for querying these tables, obtaining “reading” entries whose “SUBJ” field is student and whose “OBJ” field is book. The result is a set {John reads Ulysses, ...1, which is called a denotation. DCS trees can be extended to represent linguistic phenomena such as quantification and coreference, with additional markers introducing additional operations on tables. Fig</context>
<context citStr="Liang et al., 2011" endWordPosition="1973" position="11965" startWordPosition="1970">igure 2 is calculated from the leaf node Mary, and then: Node love (Mary loves): F2 = love n (MarySUBJ x WOBJ) Node animal (Animal that Mary loves): F3 = animal n 7rOBJ(F2) Node have (Tom has an animal that Mary loves): F4 = have n (TomSUBJ x (F3)OBJ). Formally, suppose the root a of a DCS tree T has children 7-1, ... , 7-n, and edges (a, 7-1), ... , (a, 7-n) labeled by (r1, r01), ... , (rn, r0n), respectively. The abstract denotation of T is defined as: Lri(7rr'i([Tτi])) x WRo\ri), 4Negation and disjointness (“I I”) are explained in §2.5. 5http://nlp.stanford.edu/software/ corenlp.shtml 6In (Liang et al., 2011) DCS trees are learned from QA pairs and database entries. We obtain DCS trees from dependency trees, to bypass the need of a concrete database. 7The definition differs slightly from the original Liang et al. (2011), mainly for the sake of simplicity and clarity. [T ]=w(a) n ( n n i=1 81 T dog C 7rOBJ(F2) dog C animal Axiom 8 7rOBJ(F6) = dog n F7 F6 =� 0 Axiom 4 dog C F3 T dog n F7 =� 0 dog n F7 C F3 n F7 Axiom 6 7rOBJ(F4) = F3 n F7 F3 n F7 =� 0 Axiom 4 F4 =� 0 Figure 3: An example of proof using abstract denotations 1. W =�0 2.AnBCA 3. Br x qr⊂(A, B) C A 4. 7rR(A) =�0 G A =�0 5. (A C B &amp; B C </context>
<context citStr="Liang et al., 2011" endWordPosition="3708" position="21639" startWordPosition="3705">pecific semantic role r: [r(Q)]T = 7rr([Q]T ). For example, the abstract denotation of germ ARG(book) in Figure 1 is defined as 7rARG(book n 7rOBJ(readn(studentSUBJ xbookOBJ))), meaning “books read by students”. Similarly, denotation of germ OBJ(blame) in T of Figure 5 indicates the object of “blame” as in the sentence “Tropical storm Debby is blamed for death”, which is a tropical storm, is Debby, etc. Technically, each germ in a DCS tree indicates a variable when the DCS tree is translated to a FOL formula, and the abstract denotation of the germ corresponds to the set of consistent values (Liang et al., 2011) of that variable. The logical clue to align germs is: if there exists an abstract denotation, other than W, that is a superset of both abstract denotations of two germs, then the two germs can be aligned. A simple example is that ARG(storm) in T can be aligned to ARG(storm) in H, because their denotations have a common superset other than W, namely 7rARG(storm). Amore complicated example is that OBJ(blame) and SUBJ(cause) can be aligned, because inference can induce [OBJ(blame)]T = [ARG(Debby)]T = [ARG(storm)]T, as well as [SUBJ(cause)]H = [ARG(storm)]H, so they also have the common superset </context>
<context citStr="Liang et al., 2011" endWordPosition="5772" position="34029" startWordPosition="5769">To our knowledge, however, their applications to logical inference beyond the use for database querying have not been much explored in the context of NLP. The pursue of a logic more suitable for natural language inference is not new. For instance, MacCartney and Manning (2008) has implemented a model of natural logic (Lakoff, 1970). While being computationally efficient, various inference patterns are out of the scope of their system. Much work has been done in mapping natural language into database queries (Cai and Yates, 2013; Kwiatkowski et al., 2013; Poon, 2013). Among these, the (λ-)DCS (Liang et al., 2011; Berant et al., 2013) framework defines algorithms that transparently map a labeled tree to a database querying procedure. Essentially, this is because DCS trees restrict the querying process to a very limited subset of possible operations. Our main contribution, the abstract denotation of DCS trees, can thus be considered as an attempt to characterize a fragment of FOL that is suited for both natural language inference and transparent syntaxsemantics mapping, through the choice of operations and relations on sets. We have demonstrated the utility of logical inference on DCS through the RTE t</context>
</contexts>
<marker>Liang, Jordan, Klein, 2011</marker>
<rawString>Percy Liang, Michael Jordan, and Dan Klein. 2011. Learning dependency-based compositional semantics. In Proceedings of ACL 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>Discovery of inference rules for question-answering.</title>
<date>2001</date>
<journal>Nat. Lang. Eng.,</journal>
<volume>7</volume>
<issue>4</issue>
<contexts>
<context citStr="Lin and Pantel, 2001" endWordPosition="5010" position="29518" startWordPosition="5007"> Comparison with other systems 4.3.2 Comparison to other RTE systems A comparison between our system and other RTE systems is shown in Table 6. Bos06 (Bos and Markert, 2006) is a hybrid system combining deep features from a theorem prover and a model builder, together with shallow features such as lexical overlap and text length. MacCartney08 (MacCartney and Manning, 2008) uses natural logic to calculate inference relations between two superficially aligned sentences. Clark08 (Clark and Harrison, 2008) is a logic-based system utilizing various resources including WordNet and DIRT paraphrases (Lin and Pantel, 2001), and is tolerant to partially unproven H sentences in some degree. All of the three systems pursue a logical approach, while combining various techniques to achieve robustness. The result shows that our system has comparable performance. On the other hand, Wang10 (Wang and Manning, 2010) learns a treeedit model from training data, and captures entailment relation by tree edit distance. Stern11 (Stern and Dagan, 2011) and Stern12 (Stern et al., 2012) extend this framework to utilize entailment rules as tree transformations. These are more tailored systems using machine learning with many handc</context>
<context citStr="Lin and Pantel, 2001" endWordPosition="5964" position="35229" startWordPosition="5961">CS through the RTE task. A wide variety of strategies tackling the RTE task have been investigated (Androutsopoulos and Malakasiotis, 2010), including the comparison of surface strings (Jijkoun and De Rijke, 2005), syntactic and semantic structures (Haghighi et al., 2005; Snow et al., 2006; Zanzotto et al., 2009; Burchardt et al., 2009; Heilman and Smith, 2010; Wang and Manning, 2010), semantic vectors (Erk and Pad´o, 2009) and logical representations (Bos and Markert, 2005; Raina et al., 2005; Tatu and Moldovan, 2005). Acquisition of basic knowledge for RTE is also a huge stream of research (Lin and Pantel, 2001; Shinyama et al., 2002; Sudo et al., 2003; Szpektor et al., 2004; Fujita et al., 2012; Weisman et al., 2012; Yan et al., 2013). These previous works include various techniques for acquiring and incorporating different kinds of linguistic and world knowledge, and further fight against the knowledge bottleneck problem, e.g. by back-off to shallower representations. Logic-based RTE systems employ various approaches to bridge knowledge gaps. Bos and Markert (2005) proposes features from a model builder; Raina et al. (2005) proposes an abduction process; Tatu and Moldovan (2006) shows handcrafted </context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Dekang Lin and Patrick Pantel. 2001. Discovery of inference rules for question-answering. Nat. Lang. Eng., 7(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Natural logic for textual inference.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing.</booktitle>
<contexts>
<context citStr="MacCartney and Manning (2007)" endWordPosition="4437" position="26021" startWordPosition="4434">is calculated as the cosine similarity of vectors blame+death and cause+loss+life. Other structures in the paths, such as semantic roles, are ignored in the calculation. The word vectors we use are from Mikolov et al. (2013)13 (Mikolov13), and additional results are also shown using Turian et al. (2010)14 (Turian10). The threshold for accepted path alignments is set to 0.4, based on preexperiments on RTE development sets. 4.2 Experiments on FraCaS The FraCaS test suite contains 346 inference problems divided into 9 sections, each focused on a category of semantic phenomena. We use the data by MacCartney and Manning (2007), and experiment on the first section, Quantifiers, following Lewis and Steedman (2013). This section has 44 single premise and 30 multi premise problems. Most of 12http://wordnet.princeton.edu/ 13http://code.google.com/p/word2vec/ 14http://metaoptimize.com/projects/ wordreprs/ Single Prem. Multi Prem. Lewis13 70 50 MacCartney07 84.1 - MacCartney08 97.7 - Our Sys. 79.5 80.0 Table 4: Accuracy (%) on FraCaS the problems do not require lexical knowledge, so we use our primary textual inference system without on-the-fly knowledge nor WordNet, to test the performance of the DCS framework as formal </context>
<context citStr="MacCartney and Manning (2007)" endWordPosition="4639" position="27321" startWordPosition="4635">), we output “yes” if H is proven, or try to prove the negation of H if H is not proven. To negate H, we use the root negation as described in §2.5. If the negation of H is proven, we output “no”, otherwise we output “unknown”. The result is shown in Table 4. Since our system uses an off-the-shelf dependency parser, and semantic representations are obtained from simple rule-based conversion from dependency trees, there will be only one (right or wrong) interpretation in face of ambiguous sentences. Still, our system outperforms Lewis and Steedman (2013)’s probabilistic CCG-parser. Compared to MacCartney and Manning (2007) and MacCartney and Manning (2008), our system does not need a pretrained alignment model, and it improves by making multi-sentence inferences. To sum up, the result shows that DCS is good at handling universal quantifiers and negations. Most errors are due to wrongly generated DCS trees (e.g. wrongly assigned semantic roles) or unimplemented quantifier triggers (e.g. “neither”) or generalized quantifiers (e.g. “at least a few”). These could be addressed by future work. 4.3 Experiments on PASCAL RTE datasets On PASCAL RTE datasets, strict logical inference is known to have very low recall (Bos</context>
</contexts>
<marker>MacCartney, Manning, 2007</marker>
<rawString>Bill MacCartney and Christopher D. Manning. 2007. Natural logic for textual inference. In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Modeling semantic containment and exclusion in natural language inference.</title>
<date>2008</date>
<booktitle>In Proceedings of Coling</booktitle>
<contexts>
<context citStr="MacCartney and Manning (2008)" endWordPosition="4644" position="27355" startWordPosition="4641"> or try to prove the negation of H if H is not proven. To negate H, we use the root negation as described in §2.5. If the negation of H is proven, we output “no”, otherwise we output “unknown”. The result is shown in Table 4. Since our system uses an off-the-shelf dependency parser, and semantic representations are obtained from simple rule-based conversion from dependency trees, there will be only one (right or wrong) interpretation in face of ambiguous sentences. Still, our system outperforms Lewis and Steedman (2013)’s probabilistic CCG-parser. Compared to MacCartney and Manning (2007) and MacCartney and Manning (2008), our system does not need a pretrained alignment model, and it improves by making multi-sentence inferences. To sum up, the result shows that DCS is good at handling universal quantifiers and negations. Most errors are due to wrongly generated DCS trees (e.g. wrongly assigned semantic roles) or unimplemented quantifier triggers (e.g. “neither”) or generalized quantifiers (e.g. “at least a few”). These could be addressed by future work. 4.3 Experiments on PASCAL RTE datasets On PASCAL RTE datasets, strict logical inference is known to have very low recall (Bos and Markert, 2005), so on-the-fly</context>
<context citStr="MacCartney and Manning, 2008" endWordPosition="4973" position="29272" startWordPosition="4969">0 60.0 57.4 59.6 69.9 55.7 65.8 Table 5: Impact of on-the-fly knowledge RTE2 RTE3 RTE4 RTE5 Bos06 60.6 - - - MacCartney08 - 59.4 - - Clark08 - - 56.5 - Wang10 63.0 61.1 - - Stern11 61.6 67.1 - 63.5 Stern12 - - - 64.0 Our Sys. 58.8 63.0 59.6 65.8 Table 6: Comparison with other systems 4.3.2 Comparison to other RTE systems A comparison between our system and other RTE systems is shown in Table 6. Bos06 (Bos and Markert, 2006) is a hybrid system combining deep features from a theorem prover and a model builder, together with shallow features such as lexical overlap and text length. MacCartney08 (MacCartney and Manning, 2008) uses natural logic to calculate inference relations between two superficially aligned sentences. Clark08 (Clark and Harrison, 2008) is a logic-based system utilizing various resources including WordNet and DIRT paraphrases (Lin and Pantel, 2001), and is tolerant to partially unproven H sentences in some degree. All of the three systems pursue a logical approach, while combining various techniques to achieve robustness. The result shows that our system has comparable performance. On the other hand, Wang10 (Wang and Manning, 2010) learns a treeedit model from training data, and captures entailm</context>
<context citStr="MacCartney and Manning (2008)" endWordPosition="5717" position="33688" startWordPosition="5713">ressive than FOL but featuring more efficient reasoning, is used as a theory base for Semantic Web (W3C, 2012). Ideas similar to our framework, including the use of sets in a representation that benefits efficient reasoning, are also found in description logic and knowledge representation community (Baader et al., 2003; Sowa, 2000; Sukkarieh, 2003). To our knowledge, however, their applications to logical inference beyond the use for database querying have not been much explored in the context of NLP. The pursue of a logic more suitable for natural language inference is not new. For instance, MacCartney and Manning (2008) has implemented a model of natural logic (Lakoff, 1970). While being computationally efficient, various inference patterns are out of the scope of their system. Much work has been done in mapping natural language into database queries (Cai and Yates, 2013; Kwiatkowski et al., 2013; Poon, 2013). Among these, the (λ-)DCS (Liang et al., 2011; Berant et al., 2013) framework defines algorithms that transparently map a labeled tree to a database querying procedure. Essentially, this is because DCS trees restrict the querying process to a very limited subset of possible operations. Our main contribu</context>
</contexts>
<marker>MacCartney, Manning, 2008</marker>
<rawString>Bill MacCartney and Christopher D. Manning. 2008. Modeling semantic containment and exclusion in natural language inference. In Proceedings of Coling 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Melamud</author>
<author>Jonathan Berant</author>
<author>Ido Dagan</author>
<author>Jacob Goldberger</author>
<author>Idan Szpektor</author>
</authors>
<title>A two level model for context sensitive inference rules.</title>
<date>2013</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context citStr="Melamud et al., 2013" endWordPosition="4107" position="24062" startWordPosition="4104">t al., 2007), this process can also utilize lexical-syntactic entailment rules (Szpektor et al., 2007). Furthermore, since the on-the-fly knowledge is generated by transformed pairs of DCS trees, all contexts are preserved: in Figure 6, though the tree transformation can be seen as generated from the entailment rule “X is blamed for death —* X causes loss of life”, the generated on-the-fly knowledge, as shown above the trees, only fires with the additional condition that X is a tropical storm and is Debby. Hence, the process can also be used to generate knowledge from context sensitive rules (Melamud et al., 2013), which are known to have higher quality (Pantel et al., 2007; Clark and Harrison, 2009). However, it should be noted that using on-thefly knowledge in logical inference is not a trivial 84 task. For example, the FOL formula of the rule “X is blamed for death —* X causes loss of life” is: bx; (1a; blame(x, a) &amp; death(a)) —* (1b, c; cause(x, b) &amp; loss(b, c) &amp; life(c)), which is not a horn clause. The FOL formula for the context-preserved rule in Figure 6 is even more involved. Still, it can be efficiently treated by our inference engine because as a statement, the formula QOBJ(blame)]T C QSUBJ(</context>
</contexts>
<marker>Melamud, Berant, Dagan, Goldberger, Szpektor, 2013</marker>
<rawString>Oren Melamud, Jonathan Berant, Ido Dagan, Jacob Goldberger, and Idan Szpektor. 2013. A two level model for context sensitive inference rules. In Proceedings of ACL 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Wen-tau Yih</author>
<author>Geoffrey Zweig</author>
</authors>
<title>Linguistic regularities in continuous space word representations.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL</booktitle>
<contexts>
<context citStr="Mikolov et al. (2013)" endWordPosition="4370" position="25616" startWordPosition="4367"> and superlatives. For example, named entities are singletons, so we add axioms such as bx;(x C Tom &amp; x =�0) —* Tom C x. To calculate the similarity scores of path alignments, we use the sum of word vectors of the words from each path, and calculate the cosine similarity. For example, the similarity score of the path alignment “OBJ(blame)TOBJ-ARG(death) � SUBJ(cause)OBJ-ARG(loss)MOD-ARG(life)” is calculated as the cosine similarity of vectors blame+death and cause+loss+life. Other structures in the paths, such as semantic roles, are ignored in the calculation. The word vectors we use are from Mikolov et al. (2013)13 (Mikolov13), and additional results are also shown using Turian et al. (2010)14 (Turian10). The threshold for accepted path alignments is set to 0.4, based on preexperiments on RTE development sets. 4.2 Experiments on FraCaS The FraCaS test suite contains 346 inference problems divided into 9 sections, each focused on a category of semantic phenomena. We use the data by MacCartney and Manning (2007), and experiment on the first section, Quantifiers, following Lewis and Steedman (2013). This section has 44 single premise and 30 multi premise problems. Most of 12http://wordnet.princeton.edu/ </context>
</contexts>
<marker>Mikolov, Yih, Zweig, 2013</marker>
<rawString>Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig. 2013. Linguistic regularities in continuous space word representations. In Proceedings of NAACL 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Rahul Bhagat</author>
<author>Bonaventura Coppola</author>
<author>Timothy Chklovski</author>
<author>Eduard Hovy</author>
</authors>
<title>ISP: Learning inferential selectional preferences.</title>
<date>2007</date>
<booktitle>In Proceedings of NAACL</booktitle>
<contexts>
<context citStr="Pantel et al., 2007" endWordPosition="4118" position="24123" startWordPosition="4115">ntailment rules (Szpektor et al., 2007). Furthermore, since the on-the-fly knowledge is generated by transformed pairs of DCS trees, all contexts are preserved: in Figure 6, though the tree transformation can be seen as generated from the entailment rule “X is blamed for death —* X causes loss of life”, the generated on-the-fly knowledge, as shown above the trees, only fires with the additional condition that X is a tropical storm and is Debby. Hence, the process can also be used to generate knowledge from context sensitive rules (Melamud et al., 2013), which are known to have higher quality (Pantel et al., 2007; Clark and Harrison, 2009). However, it should be noted that using on-thefly knowledge in logical inference is not a trivial 84 task. For example, the FOL formula of the rule “X is blamed for death —* X causes loss of life” is: bx; (1a; blame(x, a) &amp; death(a)) —* (1b, c; cause(x, b) &amp; loss(b, c) &amp; life(c)), which is not a horn clause. The FOL formula for the context-preserved rule in Figure 6 is even more involved. Still, it can be efficiently treated by our inference engine because as a statement, the formula QOBJ(blame)]T C QSUBJ(cause)]T’ is an atomic sentence, more than a horn clause. 4 E</context>
</contexts>
<marker>Pantel, Bhagat, Coppola, Chklovski, Hovy, 2007</marker>
<rawString>Patrick Pantel, Rahul Bhagat, Bonaventura Coppola, Timothy Chklovski, and Eduard Hovy. 2007. ISP: Learning inferential selectional preferences. In Proceedings of NAACL 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoifung Poon</author>
</authors>
<title>Grounded unsupervised semantic parsing.</title>
<date>2013</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context citStr="Poon, 2013" endWordPosition="5764" position="33983" startWordPosition="5763">., 2003; Sowa, 2000; Sukkarieh, 2003). To our knowledge, however, their applications to logical inference beyond the use for database querying have not been much explored in the context of NLP. The pursue of a logic more suitable for natural language inference is not new. For instance, MacCartney and Manning (2008) has implemented a model of natural logic (Lakoff, 1970). While being computationally efficient, various inference patterns are out of the scope of their system. Much work has been done in mapping natural language into database queries (Cai and Yates, 2013; Kwiatkowski et al., 2013; Poon, 2013). Among these, the (λ-)DCS (Liang et al., 2011; Berant et al., 2013) framework defines algorithms that transparently map a labeled tree to a database querying procedure. Essentially, this is because DCS trees restrict the querying process to a very limited subset of possible operations. Our main contribution, the abstract denotation of DCS trees, can thus be considered as an attempt to characterize a fragment of FOL that is suited for both natural language inference and transparent syntaxsemantics mapping, through the choice of operations and relations on sets. We have demonstrated the utility</context>
</contexts>
<marker>Poon, 2013</marker>
<rawString>Hoifung Poon. 2013. Grounded unsupervised semantic parsing. In Proceedings of ACL 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karthik Raghunathan</author>
<author>Heeyoung Lee</author>
<author>Sudarshan Rangarajan</author>
<author>Nate Chambers</author>
<author>Mihai Surdeanu</author>
<author>Dan Jurafsky</author>
<author>Christopher Manning</author>
</authors>
<title>A multipass sieve for coreference resolution.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context citStr="Raghunathan et al., 2010" endWordPosition="2854" position="16760" startWordPosition="2851">na such as downward monotonicity and generalized quantifiers. In the current system, we implement (i) superlatives, e.g. shighest(mountain n (WARG x AsiaMOD)) (the highest mountain in Asia) and (ii) numerics, e.g. stwo(pet n fish) (two pet fish), where sf is a selection marker. Selection operators are implemented as markers assigned to abstract denotations, with specially designed axioms. For example superlatives satisfy the following property: A C B &amp; shighest(B) C A S shighest(B) = shighest(A). New rules can be added if necessary. Coreference We use Stanford CoreNLP to resolve coreferences (Raghunathan et al., 2010), whereas coreference is implemented as a special type of selection. If a node Q in a DCS tree T belongs to a mention cluster m, we take the abstract denotation [Tσ] and make a selection sm([Tσ]), which is regarded as the abstract denotation of that mention. Then all selections of the same mention cluster are declared to be equal. 3 Generating On-the-fly Knowledge Recognizing textual entailment (RTE) is the task of determining whether a given textual statement H can be inferred by a text passage T. For this, our primary textual inference system operates as: 1. For a T-H pair, apply dependency </context>
</contexts>
<marker>Raghunathan, Lee, Rangarajan, Chambers, Surdeanu, Jurafsky, Manning, 2010</marker>
<rawString>Karthik Raghunathan, Heeyoung Lee, Sudarshan Rangarajan, Nate Chambers, Mihai Surdeanu, Dan Jurafsky, and Christopher Manning. 2010. A multipass sieve for coreference resolution. In Proceedings of EMNLP 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rajat Raina</author>
<author>Andrew Y Ng</author>
<author>Christopher D Manning</author>
</authors>
<title>Robust textual inference via learning and abductive reasoning.</title>
<date>2005</date>
<booktitle>In Proceedings of AAAI</booktitle>
<contexts>
<context citStr="Raina et al., 2005" endWordPosition="5943" position="35107" startWordPosition="5940">ping, through the choice of operations and relations on sets. We have demonstrated the utility of logical inference on DCS through the RTE task. A wide variety of strategies tackling the RTE task have been investigated (Androutsopoulos and Malakasiotis, 2010), including the comparison of surface strings (Jijkoun and De Rijke, 2005), syntactic and semantic structures (Haghighi et al., 2005; Snow et al., 2006; Zanzotto et al., 2009; Burchardt et al., 2009; Heilman and Smith, 2010; Wang and Manning, 2010), semantic vectors (Erk and Pad´o, 2009) and logical representations (Bos and Markert, 2005; Raina et al., 2005; Tatu and Moldovan, 2005). Acquisition of basic knowledge for RTE is also a huge stream of research (Lin and Pantel, 2001; Shinyama et al., 2002; Sudo et al., 2003; Szpektor et al., 2004; Fujita et al., 2012; Weisman et al., 2012; Yan et al., 2013). These previous works include various techniques for acquiring and incorporating different kinds of linguistic and world knowledge, and further fight against the knowledge bottleneck problem, e.g. by back-off to shallower representations. Logic-based RTE systems employ various approaches to bridge knowledge gaps. Bos and Markert (2005) proposes fea</context>
</contexts>
<marker>Raina, Ng, Manning, 2005</marker>
<rawString>Rajat Raina, Andrew Y. Ng, and Christopher D. Manning. 2005. Robust textual inference via learning and abductive reasoning. In Proceedings of AAAI 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Shinyama</author>
<author>Satoshi Sekine</author>
<author>Kiyoshi Sudo</author>
</authors>
<title>Automatic paraphrase acquisition from news articles.</title>
<date>2002</date>
<booktitle>In Proceedings of HLT</booktitle>
<contexts>
<context citStr="Shinyama et al., 2002" endWordPosition="5968" position="35252" startWordPosition="5965">k. A wide variety of strategies tackling the RTE task have been investigated (Androutsopoulos and Malakasiotis, 2010), including the comparison of surface strings (Jijkoun and De Rijke, 2005), syntactic and semantic structures (Haghighi et al., 2005; Snow et al., 2006; Zanzotto et al., 2009; Burchardt et al., 2009; Heilman and Smith, 2010; Wang and Manning, 2010), semantic vectors (Erk and Pad´o, 2009) and logical representations (Bos and Markert, 2005; Raina et al., 2005; Tatu and Moldovan, 2005). Acquisition of basic knowledge for RTE is also a huge stream of research (Lin and Pantel, 2001; Shinyama et al., 2002; Sudo et al., 2003; Szpektor et al., 2004; Fujita et al., 2012; Weisman et al., 2012; Yan et al., 2013). These previous works include various techniques for acquiring and incorporating different kinds of linguistic and world knowledge, and further fight against the knowledge bottleneck problem, e.g. by back-off to shallower representations. Logic-based RTE systems employ various approaches to bridge knowledge gaps. Bos and Markert (2005) proposes features from a model builder; Raina et al. (2005) proposes an abduction process; Tatu and Moldovan (2006) shows handcrafted rules could drastically</context>
</contexts>
<marker>Shinyama, Sekine, Sudo, 2002</marker>
<rawString>Yusuke Shinyama, Satoshi Sekine, and Kiyoshi Sudo. 2002. Automatic paraphrase acquisition from news articles. In Proceedings of HLT 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rion Snow</author>
<author>Lucy Vanderwende</author>
<author>Arul Menezes</author>
</authors>
<title>Effectively using syntax for recognizing false entailment.</title>
<date>2006</date>
<booktitle>In Proceedings of NAACL</booktitle>
<contexts>
<context citStr="Snow et al., 2006" endWordPosition="5909" position="34899" startWordPosition="5906">ntribution, the abstract denotation of DCS trees, can thus be considered as an attempt to characterize a fragment of FOL that is suited for both natural language inference and transparent syntaxsemantics mapping, through the choice of operations and relations on sets. We have demonstrated the utility of logical inference on DCS through the RTE task. A wide variety of strategies tackling the RTE task have been investigated (Androutsopoulos and Malakasiotis, 2010), including the comparison of surface strings (Jijkoun and De Rijke, 2005), syntactic and semantic structures (Haghighi et al., 2005; Snow et al., 2006; Zanzotto et al., 2009; Burchardt et al., 2009; Heilman and Smith, 2010; Wang and Manning, 2010), semantic vectors (Erk and Pad´o, 2009) and logical representations (Bos and Markert, 2005; Raina et al., 2005; Tatu and Moldovan, 2005). Acquisition of basic knowledge for RTE is also a huge stream of research (Lin and Pantel, 2001; Shinyama et al., 2002; Sudo et al., 2003; Szpektor et al., 2004; Fujita et al., 2012; Weisman et al., 2012; Yan et al., 2013). These previous works include various techniques for acquiring and incorporating different kinds of linguistic and world knowledge, and furthe</context>
</contexts>
<marker>Snow, Vanderwende, Menezes, 2006</marker>
<rawString>Rion Snow, Lucy Vanderwende, and Arul Menezes. 2006. Effectively using syntax for recognizing false entailment. In Proceedings of NAACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>John Bauer</author>
<author>Christopher D Manning</author>
<author>Ng Andrew Y</author>
</authors>
<title>Parsing with compositional vector grammars.</title>
<date>2013</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context citStr="Socher et al., 2013" endWordPosition="1712" position="10539" startWordPosition="1709"> set), depending on if A C B. 3Using division operator, subsumption can be represented by non-emptiness, since for sets A, B of the same dimension, q⊂(A, B) =� 0 4* A C B. Abstract denotations and statements are convenient for representing semantics of various types of expressions and linguistic knowledge. Some examples are shown in Table 2.4 2.4 Logical inference on DCS Based on abstract denotations, we briefly describe our process to apply DCS to textual inference. 2.4.1 Natural language to DCS trees To obtain DCS trees from natural language, we use Stanford CoreNLP5 for dependency parsing (Socher et al., 2013), and convert Stanford dependencies to DCS trees by pattern matching on POS tags and dependency labels.6 Currently we use the following semantic roles: ARG, SUBJ, OBJ, IOBJ, TIME and MOD. The semantic role MOD is used for any restrictive modifiers. Determiners such as “all”, “every” and “each” trigger quantifiers, as shown in Figure 2. 2.4.2 DCS trees to statements A DCS tree T = (N, £) is defined as a rooted tree, where each node a E N is labeled with a content word w(a) and each edge (a, a0) E £ C N x N is labeled with a pair of semantic roles (r, r0)7. Here a is the node nearer to the root.</context>
</contexts>
<marker>Socher, Bauer, Manning, Y, 2013</marker>
<rawString>Richard Socher, John Bauer, Christopher D. Manning, and Ng Andrew Y. 2013. Parsing with compositional vector grammars. In Proceedings of ACL 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John F Sowa</author>
</authors>
<title>Knowledge Representation: Logical, Philosophical and Computational Foundations. Brooks/Cole Publishing Co.,</title>
<date>2000</date>
<location>Pacific Grove, CA, USA.</location>
<contexts>
<context citStr="Sowa, 2000" endWordPosition="5668" position="33391" startWordPosition="5667">hown the power of the representation that allows both strict inference as on FraCaS data and robust reasoning as on RTE data. Exploration of an appropriate meaning representation for querying and reasoning on knowledge bases has a long history. Description logic, being less expressive than FOL but featuring more efficient reasoning, is used as a theory base for Semantic Web (W3C, 2012). Ideas similar to our framework, including the use of sets in a representation that benefits efficient reasoning, are also found in description logic and knowledge representation community (Baader et al., 2003; Sowa, 2000; Sukkarieh, 2003). To our knowledge, however, their applications to logical inference beyond the use for database querying have not been much explored in the context of NLP. The pursue of a logic more suitable for natural language inference is not new. For instance, MacCartney and Manning (2008) has implemented a model of natural logic (Lakoff, 1970). While being computationally efficient, various inference patterns are out of the scope of their system. Much work has been done in mapping natural language into database queries (Cai and Yates, 2013; Kwiatkowski et al., 2013; Poon, 2013). Among </context>
</contexts>
<marker>Sowa, 2000</marker>
<rawString>John F. Sowa. 2000. Knowledge Representation: Logical, Philosophical and Computational Foundations. Brooks/Cole Publishing Co., Pacific Grove, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asher Stern</author>
<author>Ido Dagan</author>
</authors>
<title>A confidence model for syntactically-motivated entailment proofs.</title>
<date>2011</date>
<booktitle>In Proceedings of RANLP</booktitle>
<contexts>
<context citStr="Stern and Dagan, 2011" endWordPosition="5078" position="29939" startWordPosition="5075">lations between two superficially aligned sentences. Clark08 (Clark and Harrison, 2008) is a logic-based system utilizing various resources including WordNet and DIRT paraphrases (Lin and Pantel, 2001), and is tolerant to partially unproven H sentences in some degree. All of the three systems pursue a logical approach, while combining various techniques to achieve robustness. The result shows that our system has comparable performance. On the other hand, Wang10 (Wang and Manning, 2010) learns a treeedit model from training data, and captures entailment relation by tree edit distance. Stern11 (Stern and Dagan, 2011) and Stern12 (Stern et al., 2012) extend this framework to utilize entailment rules as tree transformations. These are more tailored systems using machine learning with many handcrafted features. Still, our unsupervised system outperforms the state-of-the-art on RTE5 dataset. 4.3.3 Analysis Summing up test data from RTE2 to RTE5, Figure 7 shows the proportion of all proven pairs and their precision. Less than 5% pairs can be proven primarily, with a precision of 77%. Over 40% pairs can be proven by one piece of on-the-fly knowledge, yet pairs do exist in which more than 2 pieces are necessary.</context>
</contexts>
<marker>Stern, Dagan, 2011</marker>
<rawString>Asher Stern and Ido Dagan. 2011. A confidence model for syntactically-motivated entailment proofs. In Proceedings of RANLP 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asher Stern</author>
<author>Roni Stern</author>
<author>Ido Dagan</author>
<author>Ariel Felner</author>
</authors>
<title>Efficient search for transformation-based inference.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context citStr="Stern et al., 2012" endWordPosition="5084" position="29972" startWordPosition="5081">igned sentences. Clark08 (Clark and Harrison, 2008) is a logic-based system utilizing various resources including WordNet and DIRT paraphrases (Lin and Pantel, 2001), and is tolerant to partially unproven H sentences in some degree. All of the three systems pursue a logical approach, while combining various techniques to achieve robustness. The result shows that our system has comparable performance. On the other hand, Wang10 (Wang and Manning, 2010) learns a treeedit model from training data, and captures entailment relation by tree edit distance. Stern11 (Stern and Dagan, 2011) and Stern12 (Stern et al., 2012) extend this framework to utilize entailment rules as tree transformations. These are more tailored systems using machine learning with many handcrafted features. Still, our unsupervised system outperforms the state-of-the-art on RTE5 dataset. 4.3.3 Analysis Summing up test data from RTE2 to RTE5, Figure 7 shows the proportion of all proven pairs and their precision. Less than 5% pairs can be proven primarily, with a precision of 77%. Over 40% pairs can be proven by one piece of on-the-fly knowledge, yet pairs do exist in which more than 2 pieces are necessary. The precisions of 1 and 2 pieces</context>
</contexts>
<marker>Stern, Stern, Dagan, Felner, 2012</marker>
<rawString>Asher Stern, Roni Stern, Ido Dagan, and Ariel Felner. 2012. Efficient search for transformation-based inference. In Proceedings of ACL 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kiyoshi Sudo</author>
<author>Satoshi Sekine</author>
<author>Ralph Grishman</author>
</authors>
<title>An improved extraction pattern representation model for automatic ie pattern acquisition.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context citStr="Sudo et al., 2003" endWordPosition="5972" position="35271" startWordPosition="5969">rategies tackling the RTE task have been investigated (Androutsopoulos and Malakasiotis, 2010), including the comparison of surface strings (Jijkoun and De Rijke, 2005), syntactic and semantic structures (Haghighi et al., 2005; Snow et al., 2006; Zanzotto et al., 2009; Burchardt et al., 2009; Heilman and Smith, 2010; Wang and Manning, 2010), semantic vectors (Erk and Pad´o, 2009) and logical representations (Bos and Markert, 2005; Raina et al., 2005; Tatu and Moldovan, 2005). Acquisition of basic knowledge for RTE is also a huge stream of research (Lin and Pantel, 2001; Shinyama et al., 2002; Sudo et al., 2003; Szpektor et al., 2004; Fujita et al., 2012; Weisman et al., 2012; Yan et al., 2013). These previous works include various techniques for acquiring and incorporating different kinds of linguistic and world knowledge, and further fight against the knowledge bottleneck problem, e.g. by back-off to shallower representations. Logic-based RTE systems employ various approaches to bridge knowledge gaps. Bos and Markert (2005) proposes features from a model builder; Raina et al. (2005) proposes an abduction process; Tatu and Moldovan (2006) shows handcrafted rules could drastically improve the perfor</context>
</contexts>
<marker>Sudo, Sekine, Grishman, 2003</marker>
<rawString>Kiyoshi Sudo, Satoshi Sekine, and Ralph Grishman. 2003. An improved extraction pattern representation model for automatic ie pattern acquisition. In Proceedings of ACL 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sukkarieh</author>
</authors>
<title>An expressive efficient representation: Bridging a gap between nlp and kr.</title>
<date>2003</date>
<editor>In Vasile Palade, RobertJ. Howlett, and Lakhmi Jain, editors, Knowledge-Based</editor>
<publisher>Springer</publisher>
<location>Berlin Heidelberg.</location>
<contexts>
<context citStr="Sukkarieh, 2003" endWordPosition="5670" position="33409" startWordPosition="5669">er of the representation that allows both strict inference as on FraCaS data and robust reasoning as on RTE data. Exploration of an appropriate meaning representation for querying and reasoning on knowledge bases has a long history. Description logic, being less expressive than FOL but featuring more efficient reasoning, is used as a theory base for Semantic Web (W3C, 2012). Ideas similar to our framework, including the use of sets in a representation that benefits efficient reasoning, are also found in description logic and knowledge representation community (Baader et al., 2003; Sowa, 2000; Sukkarieh, 2003). To our knowledge, however, their applications to logical inference beyond the use for database querying have not been much explored in the context of NLP. The pursue of a logic more suitable for natural language inference is not new. For instance, MacCartney and Manning (2008) has implemented a model of natural logic (Lakoff, 1970). While being computationally efficient, various inference patterns are out of the scope of their system. Much work has been done in mapping natural language into database queries (Cai and Yates, 2013; Kwiatkowski et al., 2013; Poon, 2013). Among these, the (λ-)DCS</context>
</contexts>
<marker>Sukkarieh, 2003</marker>
<rawString>JanaZ. Sukkarieh. 2003. An expressive efficient representation: Bridging a gap between nlp and kr. In Vasile Palade, RobertJ. Howlett, and Lakhmi Jain, editors, Knowledge-Based Intelligent Information and Engineering Systems. Springer Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Idan Szpektor</author>
<author>Hristo Tanev</author>
<author>Ido Dagan</author>
<author>Bonaventura Coppola</author>
</authors>
<title>Scaling web-based acquisition of entailment relations.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context citStr="Szpektor et al., 2004" endWordPosition="5976" position="35294" startWordPosition="5973">he RTE task have been investigated (Androutsopoulos and Malakasiotis, 2010), including the comparison of surface strings (Jijkoun and De Rijke, 2005), syntactic and semantic structures (Haghighi et al., 2005; Snow et al., 2006; Zanzotto et al., 2009; Burchardt et al., 2009; Heilman and Smith, 2010; Wang and Manning, 2010), semantic vectors (Erk and Pad´o, 2009) and logical representations (Bos and Markert, 2005; Raina et al., 2005; Tatu and Moldovan, 2005). Acquisition of basic knowledge for RTE is also a huge stream of research (Lin and Pantel, 2001; Shinyama et al., 2002; Sudo et al., 2003; Szpektor et al., 2004; Fujita et al., 2012; Weisman et al., 2012; Yan et al., 2013). These previous works include various techniques for acquiring and incorporating different kinds of linguistic and world knowledge, and further fight against the knowledge bottleneck problem, e.g. by back-off to shallower representations. Logic-based RTE systems employ various approaches to bridge knowledge gaps. Bos and Markert (2005) proposes features from a model builder; Raina et al. (2005) proposes an abduction process; Tatu and Moldovan (2006) shows handcrafted rules could drastically improve the performance of a logic-based </context>
</contexts>
<marker>Szpektor, Tanev, Dagan, Coppola, 2004</marker>
<rawString>Idan Szpektor, Hristo Tanev, Ido Dagan, and Bonaventura Coppola. 2004. Scaling web-based acquisition of entailment relations. In Proceedings of EMNLP 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Idan Szpektor</author>
<author>Eyal Shnarch</author>
<author>Ido Dagan</author>
</authors>
<title>Instance-based evaluation of entailment rule acquisition.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context citStr="Szpektor et al., 2007" endWordPosition="447" position="2906" startWordPosition="444"> can be represented by primary relations among abstract denotations. This formulation keeps the simpleness and computability of DCS trees mostly unaffected; for example, our semantic calculation for DCS trees is parallel to the denotation computation in original DCS. An inference engine is built to handle inference on abstract denotations. Moreover, to compensate the lack of background knowledge in practical inference, we combine our framework with the idea of tree transformation (Bar-Haim et al., 2007), to propose a way of generating knowledge in logical representation from entailment rules (Szpektor et al., 2007), which are by now typically considered as syntactic rewriting rules. We test our system on FraCaS (Cooper et al., 1996) and PASCAL RTE datasets (Dagan et al., 2006). The experiments show: (i) a competitive performance on FraCaS dataset; (ii) a big impact of our automatically generated on-the-fly knowledge in achieving high recall for a logicbased RTE system; and (iii) a result that outperforms state-of-the-art RTE system on RTE5 data. Our whole system is publicly released and can be downloaded from http://kmcs.nii.ac. jp/tianran/tifmo/. 2 The Idea In this section we describe the idea of repre</context>
<context citStr="Szpektor et al., 2007" endWordPosition="4018" position="23543" startWordPosition="4015">edge. The conversion is done by first performing a DCS tree transformation according to the aligned paths, and then declare a subsumption relation between the denotations of aligned germs. For example, to apply the aligned path pair generated in Figure 5, we use it to transform T into a new tree T’ (Figure 6), and then the aligned germs, OBJ(blame) in T and SUBJ(cause) in T’, will generate the on-the-fly knowledge: [OBJ(blame)]T C [SUBJ(cause)]T’. Similar to the tree transformation based approach to RTE (Bar-Haim et al., 2007), this process can also utilize lexical-syntactic entailment rules (Szpektor et al., 2007). Furthermore, since the on-the-fly knowledge is generated by transformed pairs of DCS trees, all contexts are preserved: in Figure 6, though the tree transformation can be seen as generated from the entailment rule “X is blamed for death —* X causes loss of life”, the generated on-the-fly knowledge, as shown above the trees, only fires with the additional condition that X is a tropical storm and is Debby. Hence, the process can also be used to generate knowledge from context sensitive rules (Melamud et al., 2013), which are known to have higher quality (Pantel et al., 2007; Clark and Harrison</context>
</contexts>
<marker>Szpektor, Shnarch, Dagan, 2007</marker>
<rawString>Idan Szpektor, Eyal Shnarch, and Ido Dagan. 2007. Instance-based evaluation of entailment rule acquisition. In Proceedings of ACL 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marta Tatu</author>
<author>Dan Moldovan</author>
</authors>
<title>A semantic approach to recognizing textual entailment.</title>
<date>2005</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context citStr="Tatu and Moldovan, 2005" endWordPosition="5947" position="35133" startWordPosition="5944">oice of operations and relations on sets. We have demonstrated the utility of logical inference on DCS through the RTE task. A wide variety of strategies tackling the RTE task have been investigated (Androutsopoulos and Malakasiotis, 2010), including the comparison of surface strings (Jijkoun and De Rijke, 2005), syntactic and semantic structures (Haghighi et al., 2005; Snow et al., 2006; Zanzotto et al., 2009; Burchardt et al., 2009; Heilman and Smith, 2010; Wang and Manning, 2010), semantic vectors (Erk and Pad´o, 2009) and logical representations (Bos and Markert, 2005; Raina et al., 2005; Tatu and Moldovan, 2005). Acquisition of basic knowledge for RTE is also a huge stream of research (Lin and Pantel, 2001; Shinyama et al., 2002; Sudo et al., 2003; Szpektor et al., 2004; Fujita et al., 2012; Weisman et al., 2012; Yan et al., 2013). These previous works include various techniques for acquiring and incorporating different kinds of linguistic and world knowledge, and further fight against the knowledge bottleneck problem, e.g. by back-off to shallower representations. Logic-based RTE systems employ various approaches to bridge knowledge gaps. Bos and Markert (2005) proposes features from a model builder</context>
</contexts>
<marker>Tatu, Moldovan, 2005</marker>
<rawString>Marta Tatu and Dan Moldovan. 2005. A semantic approach to recognizing textual entailment. In Proceedings of EMNLP 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marta Tatu</author>
<author>Dan Moldovan</author>
</authors>
<title>A logicbased semantic approach to recognizing textual entailment.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL</booktitle>
<contexts>
<context citStr="Tatu and Moldovan (2006)" endWordPosition="6055" position="35810" startWordPosition="6052">ge stream of research (Lin and Pantel, 2001; Shinyama et al., 2002; Sudo et al., 2003; Szpektor et al., 2004; Fujita et al., 2012; Weisman et al., 2012; Yan et al., 2013). These previous works include various techniques for acquiring and incorporating different kinds of linguistic and world knowledge, and further fight against the knowledge bottleneck problem, e.g. by back-off to shallower representations. Logic-based RTE systems employ various approaches to bridge knowledge gaps. Bos and Markert (2005) proposes features from a model builder; Raina et al. (2005) proposes an abduction process; Tatu and Moldovan (2006) shows handcrafted rules could drastically improve the performance of a logic-based RTE system. As such, our current RTE system is at a proofof-concept stage, in that many of the above techniques are yet to be implemented. Nonetheless, we would like to emphasize that it already shows performance competitive to state-of-the-art systems on one data set (RTE5). Other directions of our future work include further exploitation of the new semantic representation. For example, since abstract denotations are readily suited for data querying, they can be used to verify newly generated assumptions by fa</context>
</contexts>
<marker>Tatu, Moldovan, 2006</marker>
<rawString>Marta Tatu and Dan Moldovan. 2006. A logicbased semantic approach to recognizing textual entailment. In Proceedings of the COLING/ACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Turian</author>
<author>Lev-Arie Ratinov</author>
<author>Yoshua Bengio</author>
</authors>
<title>Word representations: A simple and general method for semi-supervised learning.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context citStr="Turian et al. (2010)" endWordPosition="4382" position="25696" startWordPosition="4379">uch as bx;(x C Tom &amp; x =�0) —* Tom C x. To calculate the similarity scores of path alignments, we use the sum of word vectors of the words from each path, and calculate the cosine similarity. For example, the similarity score of the path alignment “OBJ(blame)TOBJ-ARG(death) � SUBJ(cause)OBJ-ARG(loss)MOD-ARG(life)” is calculated as the cosine similarity of vectors blame+death and cause+loss+life. Other structures in the paths, such as semantic roles, are ignored in the calculation. The word vectors we use are from Mikolov et al. (2013)13 (Mikolov13), and additional results are also shown using Turian et al. (2010)14 (Turian10). The threshold for accepted path alignments is set to 0.4, based on preexperiments on RTE development sets. 4.2 Experiments on FraCaS The FraCaS test suite contains 346 inference problems divided into 9 sections, each focused on a category of semantic phenomena. We use the data by MacCartney and Manning (2007), and experiment on the first section, Quantifiers, following Lewis and Steedman (2013). This section has 44 single premise and 30 multi premise problems. Most of 12http://wordnet.princeton.edu/ 13http://code.google.com/p/word2vec/ 14http://metaoptimize.com/projects/ wordrep</context>
</contexts>
<marker>Turian, Ratinov, Bengio, 2010</marker>
<rawString>Joseph Turian, Lev-Arie Ratinov, and Yoshua Bengio. 2010. Word representations: A simple and general method for semi-supervised learning. In Proceedings of ACL 2010.</rawString>
</citation>
<citation valid="false">
<authors>
<author>W3C</author>
</authors>
<title>Owl 2 web ontology language document overview</title>
<note>(second edition). www.w3.org/TR/owl2-overview/.</note>
<marker>W3C, </marker>
<rawString>W3C. 2012. Owl 2 web ontology language document overview (second edition). www.w3.org/TR/owl2-overview/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mengqiu Wang</author>
<author>Christopher Manning</author>
</authors>
<title>Probabilistic tree-edit models with structured latent variables for textual entailment and question answering.</title>
<date>2010</date>
<booktitle>In Proceedings of Coling</booktitle>
<contexts>
<context citStr="Wang and Manning, 2010" endWordPosition="5056" position="29807" startWordPosition="5053">res such as lexical overlap and text length. MacCartney08 (MacCartney and Manning, 2008) uses natural logic to calculate inference relations between two superficially aligned sentences. Clark08 (Clark and Harrison, 2008) is a logic-based system utilizing various resources including WordNet and DIRT paraphrases (Lin and Pantel, 2001), and is tolerant to partially unproven H sentences in some degree. All of the three systems pursue a logical approach, while combining various techniques to achieve robustness. The result shows that our system has comparable performance. On the other hand, Wang10 (Wang and Manning, 2010) learns a treeedit model from training data, and captures entailment relation by tree edit distance. Stern11 (Stern and Dagan, 2011) and Stern12 (Stern et al., 2012) extend this framework to utilize entailment rules as tree transformations. These are more tailored systems using machine learning with many handcrafted features. Still, our unsupervised system outperforms the state-of-the-art on RTE5 dataset. 4.3.3 Analysis Summing up test data from RTE2 to RTE5, Figure 7 shows the proportion of all proven pairs and their precision. Less than 5% pairs can be proven primarily, with a precision of 7</context>
<context citStr="Wang and Manning, 2010" endWordPosition="5925" position="34996" startWordPosition="5922">haracterize a fragment of FOL that is suited for both natural language inference and transparent syntaxsemantics mapping, through the choice of operations and relations on sets. We have demonstrated the utility of logical inference on DCS through the RTE task. A wide variety of strategies tackling the RTE task have been investigated (Androutsopoulos and Malakasiotis, 2010), including the comparison of surface strings (Jijkoun and De Rijke, 2005), syntactic and semantic structures (Haghighi et al., 2005; Snow et al., 2006; Zanzotto et al., 2009; Burchardt et al., 2009; Heilman and Smith, 2010; Wang and Manning, 2010), semantic vectors (Erk and Pad´o, 2009) and logical representations (Bos and Markert, 2005; Raina et al., 2005; Tatu and Moldovan, 2005). Acquisition of basic knowledge for RTE is also a huge stream of research (Lin and Pantel, 2001; Shinyama et al., 2002; Sudo et al., 2003; Szpektor et al., 2004; Fujita et al., 2012; Weisman et al., 2012; Yan et al., 2013). These previous works include various techniques for acquiring and incorporating different kinds of linguistic and world knowledge, and further fight against the knowledge bottleneck problem, e.g. by back-off to shallower representations. </context>
</contexts>
<marker>Wang, Manning, 2010</marker>
<rawString>Mengqiu Wang and Christopher Manning. 2010. Probabilistic tree-edit models with structured latent variables for textual entailment and question answering. In Proceedings of Coling 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hila Weisman</author>
<author>Jonathan Berant</author>
<author>Idan Szpektor</author>
<author>Ido Dagan</author>
</authors>
<title>Learning verb inference rules from linguistically-motivated evidence.</title>
<date>2012</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context citStr="Weisman et al., 2012" endWordPosition="5985" position="35337" startWordPosition="5981">opoulos and Malakasiotis, 2010), including the comparison of surface strings (Jijkoun and De Rijke, 2005), syntactic and semantic structures (Haghighi et al., 2005; Snow et al., 2006; Zanzotto et al., 2009; Burchardt et al., 2009; Heilman and Smith, 2010; Wang and Manning, 2010), semantic vectors (Erk and Pad´o, 2009) and logical representations (Bos and Markert, 2005; Raina et al., 2005; Tatu and Moldovan, 2005). Acquisition of basic knowledge for RTE is also a huge stream of research (Lin and Pantel, 2001; Shinyama et al., 2002; Sudo et al., 2003; Szpektor et al., 2004; Fujita et al., 2012; Weisman et al., 2012; Yan et al., 2013). These previous works include various techniques for acquiring and incorporating different kinds of linguistic and world knowledge, and further fight against the knowledge bottleneck problem, e.g. by back-off to shallower representations. Logic-based RTE systems employ various approaches to bridge knowledge gaps. Bos and Markert (2005) proposes features from a model builder; Raina et al. (2005) proposes an abduction process; Tatu and Moldovan (2006) shows handcrafted rules could drastically improve the performance of a logic-based RTE system. As such, our current RTE system</context>
</contexts>
<marker>Weisman, Berant, Szpektor, Dagan, 2012</marker>
<rawString>Hila Weisman, Jonathan Berant, Idan Szpektor, and Ido Dagan. 2012. Learning verb inference rules from linguistically-motivated evidence. In Proceedings of EMNLP 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yulan Yan</author>
</authors>
<title>Chikara Hashimoto, Kentaro Torisawa, Takao</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL</booktitle>
<marker>Yan, 2013</marker>
<rawString>Yulan Yan, Chikara Hashimoto, Kentaro Torisawa, Takao Kawai, Jun’ichi Kazama, and Stijn De Saeger. 2013. Minimally supervised method for multilingual paraphrase extraction from definition sentences on the web. In Proceedings of NAACL 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabio massimo Zanzotto</author>
<author>Marco Pennacchiotti</author>
<author>Alessandro Moschitti</author>
</authors>
<title>A machine learning approach to textual entailment recognition.</title>
<date>2009</date>
<journal>Nat. Lang. Eng.,</journal>
<volume>15</volume>
<issue>4</issue>
<contexts>
<context citStr="Zanzotto et al., 2009" endWordPosition="5913" position="34922" startWordPosition="5910">tract denotation of DCS trees, can thus be considered as an attempt to characterize a fragment of FOL that is suited for both natural language inference and transparent syntaxsemantics mapping, through the choice of operations and relations on sets. We have demonstrated the utility of logical inference on DCS through the RTE task. A wide variety of strategies tackling the RTE task have been investigated (Androutsopoulos and Malakasiotis, 2010), including the comparison of surface strings (Jijkoun and De Rijke, 2005), syntactic and semantic structures (Haghighi et al., 2005; Snow et al., 2006; Zanzotto et al., 2009; Burchardt et al., 2009; Heilman and Smith, 2010; Wang and Manning, 2010), semantic vectors (Erk and Pad´o, 2009) and logical representations (Bos and Markert, 2005; Raina et al., 2005; Tatu and Moldovan, 2005). Acquisition of basic knowledge for RTE is also a huge stream of research (Lin and Pantel, 2001; Shinyama et al., 2002; Sudo et al., 2003; Szpektor et al., 2004; Fujita et al., 2012; Weisman et al., 2012; Yan et al., 2013). These previous works include various techniques for acquiring and incorporating different kinds of linguistic and world knowledge, and further fight against the kno</context>
</contexts>
<marker>Zanzotto, Pennacchiotti, Moschitti, 2009</marker>
<rawString>Fabio massimo Zanzotto, Marco Pennacchiotti, and Alessandro Moschitti. 2009. A machine learning approach to textual entailment recognition. Nat. Lang. Eng., 15(4).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>