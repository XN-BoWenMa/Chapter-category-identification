<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant confidence="0.000078" no="0">
<title confidence="0.913509">
Named Entity Transliteration with Comparable Corpora
</title>
<author confidence="0.993194">
Richard Sproat, Tao Tao, ChengXiang Zhai
</author>
<affiliation confidence="0.995209">
University of Illinois at Urbana-Champaign, Urbana, IL, 61801
</affiliation>
<email confidence="0.994201">
rws@uiuc.edu, {taotao,czhai}@cs.uiuc.edu
</email>
<sectionHeader confidence="0.994757" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999373">In this paper we investigate ChineseEnglish name transliteration using comparable corpora, corpora where texts in the two languages deal in some of the same topics — and therefore share references to named entities — but are not translations of each other. We present two distinct methods for transliteration, one approach using phonetic transliteration, and the second using the temporal distribution of candidate pairs. Each of these approaches works quite well, but by combining the approaches one can achieve even better results. We then propose a novel score propagation method that utilizes the co-occurrence of transliteration pairs within document pairs. This propagation method achieves further improvement over the best results from the previous step.</bodyText>
<sectionHeader confidence="0.998784" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99997346">As part of a more general project on multilingual named entity identification, we are interested in the problem of name transliteration across languages that use different scripts. One particular issue is the discovery of named entities in “comparable” texts in multiple languages, where by comparable we mean texts that are about the same topic, but are not in general translations of each other. For example, if one were to go through an English, Chinese and Arabic newspaper on the same day, it is likely that the more important international events in various topics such as politics, business, science and sports, would each be covered in each of the newspapers. Names of the same persons, locations and so forth — which are often transliterated rather than translated — would be found in comparable stories across the three papers.1 We wish to use this expectation to leverage transliteration, and thus the identification of named entities across languages. Our idea is that the occurrence of a cluster of names in, say, an English text, should be useful if we find a cluster of what looks like the same names in a Chinese or Arabic text. An example of what we are referring to can be found in Figure 1. These are fragments of two stories from the June 8, 2001 Xinhua English and Chinese newswires, each covering an international women’s badminton championship. Though these two stories are from the same newswire source, and cover the same event, they are not translations of each other. Still, not surprisingly, a lot of the names that occur in one, also occur in the other. Thus (Camilla) Martin shows up in the Chinese version asAi'1: ma-er-ting; Judith Meulendijks is T V fL' A A JW yu mo-lun-di-ke-si; and Mette Sorensen is ) fL' V mai su-lun-sen. Several other correspondences also occur. While some of the transliterations are “standard” — thus Martin is conventionally transliterated asAi'1: ma-erting — many of them were clearly more novel, though all of them follow the standard Chinese conventions for transliterating foreign names. These sample documents illustrate an important point: if a document in language L1 has a set of names, and one finds a document in L2 containing a set of names that look as if they could be transliterations of the names in the L1 document, then this should boost one’s confidence that the two sets of names are indeed transliterations of each other. We will demonstrate that this intuition is correct.</bodyText>
<footnote confidence="0.9962978">
1Many names, particularly of organizations, maybe trans-
lated rather than transliterated; the transliteration method we
discuss here obviously will not account for such cases, though
the time correlation and propagation methods we discuss will
still be useful.
</footnote>
<page confidence="0.980066">
73
</page>
<note confidence="0.968339555555556">
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 73–80,
Sydney, July 2006. c�2006 Association for Computational Linguistics
Dai Yun Nips World No. 1 Martin to Shake off Olympic
Shadow ... In the day’s other matches, second seed Zhou Mi
overwhelmed Ling Wan Ting of Hong Kong, China 11-4, 11-
4, Zhang Ning defeat Judith Meulendijks of Netherlands 11-
2, 11-9 and third seed Gong Ruina took 21 minutes to elimi-
nate Tine Rasmussen of Denmark 11-1, 11-1, enabling China
to claim five quarterfinal places in the women’s singles.
</note>
<equation confidence="0.895260833333333">
. . .������,�������¤4��Q�,�1. . .
417E*ÀQiOrpQt Ö4--l4V,4/�N,
������������11:1�����Ö
������,������11:2�11:9������
�������,������11:4�11:1�¤��Q
���Ö���
</equation>
<figureCaption confidence="0.9834565">
Figure 1: Sample from two stories about an inter-
national women’s badminton championship.
</figureCaption>
<sectionHeader confidence="0.990931" genericHeader="related work">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.995975216216216">In previous work on Chinese named-entity transliteration — e.g. (Meng et al., 2001; Gao et al., 2004), the problem has been cast as the problem of producing, for a given Chinese name, an English equivalent such as one might need in a machine translation system. For example, for the nameI-A*��wei wei-lian-mu-si, one would like to arrive at the English name V(enus) Williams. Common approaches include sourcechannel methods, following (Knight and Graehl, 1998) or maximum-entropy models. Comparable corpora have been studied extensively in the literature (e.g.,(Fung, 1995; Rapp, 1995; Tanaka and Iwasaki, 1996; Franz et al., 1998; Ballesteros and Croft, 1998; Masuichi et al., 2000; Sadat et al., 2003)), but transliteration in the context of comparable corpora has not been well addressed. The general idea of exploiting frequency correlations to acquire word translations from comparable corpora has been explored in several previous studies (e.g., (Fung, 1995; Rapp, 1995; Tanaka and Iwasaki, 1996)).Recently, a method based on Pearson correlation was proposed to mine word pairs from comparable corpora (Tao and Zhai, 2005), an idea similar to the method used in (Kay and Roscheisen, 1993) for sentence alignment. In our work, we adopt the method proposed in (Tao and Zhai, 2005) and apply it to the problem of transliteration. We also study several variations of the similarity measures. Mining transliterations from multilingual web pages was studied in (Zhang and Vines, 2004); Our work differs from this work in that we use comparable corpora (in particular, news data) and leverage the time correlation information naturally available in comparable corpora.</bodyText>
<sectionHeader confidence="0.945681" genericHeader="method">
3 Chinese Transliteration with
</sectionHeader>
<subsectionHeader confidence="0.514316">
Comparable Corpora
</subsectionHeader>
<bodyText confidence="0.996727466666667">We assume that we have comparable corpora, consisting of newspaper articles in English and Chinese from the same day, or almost the same day. In our experiments we use data from the English and Chinese stories from the Xinhua News agency for about 6 months of 2001.2 We assume that we have identified names for persons and locations—two types that have a strong tendency to be transliterated wholly or mostly phonetically—in the English text; in this work we use the named-entity recognizer described in (Li et al., 2004), which is based on the SNoW machine learning toolkit (Carlson et al., 1999). To perform the transliteration task, we propose the following general three-step approach:</bodyText>
<listItem confidence="0.8987615625">1. Given an English name, identify candidate Chinese character n-grams as possible transliterations. 2. Score each candidate based on how likely the candidate is to be a transliteration of the English name. We propose two different scoring methods. The first involves phonetic scoring, and the second uses the frequency profile of the candidate pair over time. We will show that each of these approaches works quite well, but by combining the approaches one can achieve even better results. 3. Propagate scores of all the candidate transliteration pairs globally based on their cooccurrences in document pairs in the comparable corpora.</listItem>
<bodyText confidence="0.999882875">The intuition behind the third step is the following. Suppose several high-confidence name transliteration pairs occur in a pair of English and Chinese documents. Intuitively, this would increase our confidence in the other plausible transliteration pairs in the same document pair. We thus propose a score propagation method to allow these high-confidence pairs to propagate some of their scores to other co-occurring transliteration pairs.</bodyText>
<footnote confidence="0.996255">
2Available from the LDC via the English Gigaword
(LDC2003T05) and Chinese Gigaword (LDC2003T09) cor-
pora.
</footnote>
<page confidence="0.999361">
74
</page>
<bodyText confidence="0.999729333333333">As we will show later, such a propagation strategy can generally further improve the transliteration accuracy; in particular, it can further improve the already high performance from combining the two scoring methods.</bodyText>
<subsectionHeader confidence="0.999387">
3.1 Candidate Selection
</subsectionHeader>
<bodyText confidence="0.99997764">The English named entity candidate selection process was already described above. Candidate Chinese transliterations are generated by consulting a list of characters that are frequently used for transliterating foreign names. As discussed elsewhere (Sproat et al., 1996), a subset of a few hundred characters (out of several thousand) tends to be used overwhelmingly for transliterating foreign names into Chinese. We use a list of 495 such characters, derived from various online dictionaries. A sequence of three or more characters from the list is taken as a possible name. If the character “�” occurs, which is frequently used to represent the space between parts of an English name, then at least one character to the left and right of this character will be collected, even if the character in question is not in the list of “foreign” characters. Armed with the English and Chinese candidate lists, we then consider the pairing of every English candidate with every Chinese candidate. Obviously it would be impractical to do this for all of the candidates generated for, say, an entire year: we consider as plausible pairings those candidates that occur within a day of each other in the two corpora.</bodyText>
<subsectionHeader confidence="0.911545">
3.2 Candidate scoring based on
pronunciation
</subsectionHeader>
<bodyText confidence="0.999988102040816">We adopt a source-channel model for scoring English-Chinese transliteration pairs. In general, we seek to estimate P(elc), where e is a word in Roman script, and c is a word in Chinese script. Since Chinese transliteration is mostly based on pronunciation, we estimate P(e′|c′), where e′ is the pronunciation of e and c′ is the pronunciation of c. Again following standard practice, we decompose the estimate of P(e′|c′) as P(e′|c′) _ Ili P(e′i|c′i). Here, e′i is the ith subsequence of the English phone string, and c′i is the ith subsequence of the Chinese phone string. Since Chinese transliteration attempts to match the syllablesized characters to equivalent sounding spans of the English language, we fix the c′i to be syllables, and let the e′i range over all possible subsequences of the English phone string. For training data we have a small list of 721 names in Roman script and their Chinese equivalent.3 Pronunciations for English words are obtained using the Festival text-tospeech system (Taylor et al., 1998); for Chinese, we use the standard pinyin transliteration of the characters. English-Chinese pairs in our training dictionary were aligned using the alignment algorithm from (Kruskal, 1999), and a hand-derived set of 21 rules-of-thumb: for example, we have rules that encode the fact that Chinese /l/ can correspond to English /r/, /n/ or /er/; and that Chinese /w/ may be used to represent /v/. Given that there are over 400 syllables in Mandarin (not counting tone) and each of these syllables can match a large number of potential English phone spans, this is clearly not enough training data to cover all the parameters, and so we use Good-Turing estimation to estimate probabilities for unseen correspondences. Since we would like to filter implausible transliteration pairs we are less lenient than standard estimation techniques in that we are willing to assign zero probability to some correspondences. Thus we set a hard rule that for an English phone span to correspond to a Chinese syllable, the initial phone of the English span must have been seen in the training data as corresponding to the initial of the Chinese syllable some minimum number of times. For consonant-initial syllables we set the minimum to 4. We omit further details of our estimation technique for lack of space. This phonetic correspondence model can then be used to score putative transliteration pairs.</bodyText>
<subsectionHeader confidence="0.9824555">
3.3 Candidate Scoring based on Frequency
Correlation
</subsectionHeader>
<bodyText confidence="0.9999464">Names of the same entity that occur in different languages often have correlated frequency patterns due to common triggers such as a major event. Thus if we have comparable news articles over a sufficiently long time period, it is possible to exploit such correlations to learn the associations of names in different languages. The idea of exploiting frequency correlation has been well studied. (See the previous work section.) We adopt the method proposed in (Tao and Zhai, 2005), which works as follows: We pool all documents in a single day to form a large pseudo-document.</bodyText>
<footnote confidence="0.930308857142857">
3The LDC provides a much larger list of transliterated
Chinese-English names, but we did not use this here for two
reasons. First, we have found it it be quite noisy. Secondly,
we were interested in seeing how well one could do with a
limited resource ofjust a few hundred names, which is a more
realistic scenario for languages that have fewer resources than
English and Chinese.
</footnote>
<page confidence="0.99842">
75
</page>
<bodyText confidence="0.999928375">Then, for each transliteration candidate (both Chinese and English), we compute its frequency in each of those pseudo-documents and obtain a raw frequency vector. We further normalize the raw frequency vector so that it becomes a frequency distribution over all the time points (days). In order to compute the similarity between two distribution vectors, The Pearson correlation coefficient was used in (Tao and Zhai, 2005); here we also considered two other commonly used measures – cosine (Salton and McGill, 1983), and Jensen-Shannon divergence (Lin, 1991), though our results show that Pearson correlation coefficient performs better than these two other methods.</bodyText>
<subsectionHeader confidence="0.904433">
3.4 Score Propagation
</subsectionHeader>
<bodyText confidence="0.994814057142857">In both scoring methods described above, scoring of each candidate transliteration pair is independent of the other. As we have noted, document pairs that contain lots of plausible transliteration pairs should be viewed as more plausible document pairs; at the same time, in such a situation we should also trust the putative transliteration pairs more. Thus these document pairs and transliteration pairs mutually “reinforce” each other, and this can be exploited to further optimize our transliteration scores by allowing transliteration pairs to propagate their scores to each other according to their co-occurrence strengths. Formally, suppose the current generation of transliteration scores are (ei, ci, wi) i = 1, ..., n, where (ei, ci) is a distinct pair of English and Chinese names. Note that although for any i =6 j, we have (ei, ci) =6 (ej, cj), it is possible that ei = ej or ci = cj for some i =6 j. wi is the transliteration score of (ei, ci). These pairs along with their co-occurrence relation computed based on our comparable corpora can be formally represented by a graph as shown in Figure 2. In such a graph, a node represents (ei, ci, wi). An edge between (ei, ci, wi) and (ej, cj, wj) is constructed iff (ei, ci) and (ej, cj) co-occur in a certain document pair (Et, Ct), i.e. there exists a document pair (Et, Ct), such that ei, ej ∈ Et and ci, cj ∈ Ct. Given a node (ei, ci, wi), we refer to all its directly-connected nodes as its “neighbors”. The documents do not appear explicitly in the graph, but they implicitly affect the graph’s topology and the weight of each edge. Our idea of score propagation can now be formulated as the following recursive equation for updating the scores of all the transliteration pairs.</bodyText>
<figureCaption confidence="0.8413185">
Figure 2: Graph representing transliteration pairs
and cooccurence relations.
</figureCaption>
<equation confidence="0.991005333333333">
wi = � ~ w(k−1)
(k) + (1 � �) ~
i
</equation>
<bodyText confidence="0.918331916666667">where w(k) i is the new score of the pair (ei, ci) after an iteration, while w(k−1) is its old score i before updating; α ∈ [0, 1] is a parameter to control the overall amount of propagation (when α = 1, no propagation occurs); P(j|i) is the conditional probability of propagating a score from node (ej, cj, wj) to node (ei, ci, wi). We estimate P (j|i) in two different ways: 1) The number of cooccurrences in the whole collection (Denote as CO). P(j|i) = C(i,j) where</bodyText>
<equation confidence="0.981859">
�j′ C(i,j′),
C(i, j) is the cooccurrence count of (ei, ci) and
(ej, cj); 2) A mutual information-based method
(Denote as MI). P(j|i) = MI(i,j) where
�j′ MI (i,j′),
</equation>
<bodyText confidence="0.985300857142857">MI(i, j) is the mutual information of (ei, ci) and (ej, cj). As we will show, the CO method works better. Note that the transition probabilities between indirect neighbors are always 0. Thus propagation only happens between direct neighbors. This formulation is very similar to PageRank, a link-based ranking algorithm for Web retrieval (Brin and Page, 1998). However, our motivation is propagating scores to exploit cooccurrences, so we do not necessarily want the equation to converge. Indeed, our results show that although the initial iterations always help improve accuracy, too many iterations actually would decrease the performance.</bodyText>
<sectionHeader confidence="0.99931" genericHeader="evaluation and result">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.9999005">We use a comparable English-Chinese corpus to evaluate our methods for Chinese transliteration. We take one day’s worth of comparable news articles (234 Chinese stories and 322 English stories), generate about 600 English names with the entity recognizer (Li et al., 2004) as described above, and find potential Chinese transliterations also as previously described.</bodyText>
<equation confidence="0.97495294117647">
(e4, c4)
(e2, c2)
w4
(e5, c5)
w2
w1
w3
w7
(e3, c3)
w5
(e5, c5)
wS
(e7, c7)
(eS, cS)
n (w(k−1) ~ P(jj�)),
E j
j6=i,j=1
</equation>
<page confidence="0.867917">
76
</page>
<bodyText confidence="0.999964952380952">We generated 627 Chinese candidates. In principle, all these 600 x 627 pairs are potential transliterations. We then apply the phonetic and time correlation methods to score and rank all the candidate Chinese-English correspondences. To evaluate the proposed transliteration methods quantitatively, we measure the accuracy of the ranked list by Mean Reciprocal Rank (MRR), a measure commonly used in information retrieval when there is precisely one correct answer (Kantor and Voorhees, 2000). The reciprocal rank is the reciprocal of the rank of the correct answer. For example, if the correct answer is ranked as the first, the reciprocal rank would be 1.0, whereas if it is ranked the second, it would be 0.5, and so forth. To evaluate the results for a set of English names, we take the mean of the reciprocal rank of each English name. We attempted to create a complete set of answers for all the English names in our test set, but a small number of English names do not seem to have any standard transliteration according to the resources that we consulted. We ended up with a list of about 490 out of the 600 English names judged. We further notice that some answers (about 20%) are not in our Chinese candidate set. This could be due to two reasons: (1) The answer does not occur in the Chinese news articles we look at.(2) The answer is there, but our candidate generation method has missed it. In order to see more clearly how accurate each method is for ranking the candidates, we also compute the MRR for the subset of English names whose transliteration answers are in our candidate list. We distinguish the MRRs computed on these two sets of English names as “AllMRR” and “CoreMRR”. Below we first discuss the results of each of the two methods. We then compare the two methods and discuss results from combining the two methods.</bodyText>
<subsectionHeader confidence="0.988236">
4.1 Phonetic Correspondence
</subsectionHeader>
<bodyText confidence="0.999967">We show sample results for the phonetic scoring method in Table 1. This table shows the 10 highest scoring transliterations for each Chinese character sequence based on all texts in the Chinese and English Xinhua newswire for the 13th of August, 2001. 8 out of these 10 are correct. For all the English names the MRR is 0.3, and for the core names it is 0.89.</bodyText>
<equation confidence="0.8290505">
*paris AURA pei-lei-si 3.51
iraq Ip #s A yi-la-ke 3.74
staub A f W si-ta-bo 4.45
canada N * *. j ia-na-da 4.85
belfast 911:'j: a A ti bei-er-fa-si-te 4.90
fischer F � i'J: fei-she-er 4.91
philippine r 0 4� fei-l¨u-bin 4.97
lesotho M lai-suo-two 5.12
*tirana A#M tye-lu-na 5.15
freeman A _W_ 0 fu-li-man 5.26
</equation>
<tableCaption confidence="0.827854">
Table 1: Ten highest-scoring matches for the Xin-
hua corpus for 8/13/01. The final column is the −log P estimate for the transliteration.Starred entries are incorrect.</tableCaption>
<bodyText confidence="0.939578166666667">Thus on average, the correct answer, if it is included in our candidate list, is ranked mostly as the first one.</bodyText>
<subsectionHeader confidence="0.748865">
4.2 Frequency correlation
</subsectionHeader>
<table confidence="0.99460475">
Similarity AllMRR CoreMRR
Pearson 0.1360 0.3643
Cosine 0.1141 0.3015
JS-div 0.0785 0.2016
</table>
<tableCaption confidence="0.878858">
Table 2: MRRs of the frequency correlation meth-
ods.
</tableCaption>
<bodyText confidence="0.999953047619048">We proposed three similarity measures for the frequency correlation method, i.e., the Cosine, Pearson coefficient, and Jensen-Shannon divergence. In Table 2, we show their MRRs. Given that the only resource the method needs is comparable text documents over a sufficiently long period, these results are quite encouraging. For example, with Pearson correlation, when the Chinese transliteration of an English name is included in our candidate list, the correct answer is, on average, ranked at the 3rd place or better. The results thus show that the idea of exploiting frequency correlation does work. We also see that among the three similarity measures, Pearson correlation performs the best; it performs better than Cosine, which is better than JS-divergence. Compared with the phonetic correspondence method, the performance of the frequency correlation method is in general much worse, which is not surprising, given the fact that terms may be correlated merely because they are topically related.</bodyText>
<page confidence="0.996861">
77
</page>
<note confidence="0.3262165">
4.3 Combination of phonetic correspondence
and frequency correlation
</note>
<table confidence="0.9997006">
Method AllMRR CoreMRR
Phonetic 0.2999 0.8895
Freq 0.1360 0.3643
Freq+PhoneticFilter 0.3062 0.9083
Freq+PhoneticScore 0.3194 0.9474
</table>
<tableCaption confidence="0.9911155">
Table 3: Effectiveness of combining the two scor-
ing methods.
</tableCaption>
<bodyText confidence="0.999968348837209">Since the two methods exploit complementary resources, it is natural to see if we can improve performance by combining the two methods. Indeed, intuitively the best candidate is the one that has a good pronunciation alignment as well as a correlated frequency distribution with the English name. We evaluated two strategies for combining the two methods. The first strategy is to use the phonetic model to filter out (clearly impossible) candidates and then use the frequency correlation method to rank the candidates. The second is to combine the scores of these two methods. Since the correlation coefficient has a maximum value of 1, we normalize the phonetic correspondence score by dividing all scores by the maximum score so that the maximum normalized value is also 1. We then take the average of the two scores and rank the candidates based on their average scores. Note that the second strategy implies the application of the first strategy. The results of these two combination strategies are shown in Table 3 along with the results of the two individual methods. We see that both combination strategies are effective and the MRRs of the combined results are all better than those of the two individual methods. It is interesting to see that the benefit of applying the phonetic correspondence model as a filter is quite significant. Indeed, although the performance of the frequency correlation method alone is much worse than that of the phonetic correspondence method, when working on the subset of candidates passing the phonetic filter (i.e., those candidates that have a reasonable phonetic alignment with the English name), it can outperform the phonetic correspondence method. This once again indicates that exploiting the frequency correlation can be effective. When combining the scores of these two methods, we not only (implicitly) apply the phonetic filter, but also exploit the discriminative power provided by the phonetic correspondence scores and this is shown to bring in additional benefit, giving the best performance among all the methods.</bodyText>
<subsectionHeader confidence="0.990025">
4.4 Error Analysis
</subsectionHeader>
<bodyText confidence="0.999897714285714">From the results above, we see that the MRRs for the core English names are substantially higher than those for all the English names. This means that our methods perform very well whenever we have the answer in our candidate list, but we have also missed the answers for many English names. The missing of an answer in the candidate list is thus a major source of errors. To further understand the upper bound of our method, we manually add the missing correct answers to our candidate set and apply all the methods to rank this augmented set of candidates. The performance is reported in Table 4 with the corresponding performance on the original candidate set. We see that, as expected, the performance on the augmented candidate list, which can be interpreted as an upper bound of our method, is indeed much better, suggesting that if we can somehow improve the candidate generation method to include the answers in the list, we can expect to significantly improve the performance for all the methods.</bodyText>
<table confidence="0.998485666666667">
Method ALLMRR
Original Augmented
Phonetic 0.2999 0.7157
Freq 0.1360 0.3455
Freq+PhoneticFilter 0.3062 0.6232
Freq+PhoneticScore 0.3194 0.7338
</table>
<tableCaption confidence="0.999754">
Table 4: MRRs on the augmented candidate list.
</tableCaption>
<bodyText confidence="0.999972263157895">This is clearly an interesting topic for further research. The relative performance of different methods on this augmented candidate list is roughly the same as on the original candidate list, except that the “Freq+PhoneticFilter” is slightly worse than that of the phonetic method alone, though it is still much better than the performance of the frequency correlation alone. One possible explanation may be that since these names do not necessarily occur in our comparable corpora, we may not have sufficient frequency observations for some of the names.</bodyText>
<page confidence="0.995608">
78
</page>
<table confidence="0.99907025">
Method AllMRR CoreMRR
init. CO MI init. CO MI
Freq+PhoneticFilter 0.3171 0.3255 0.3255 0.9058 0.9372 0.9372
Freq+PhoneticScore 0.3290 0.3373 0.3392 0.9422 0.9659 0.9573
</table>
<tableCaption confidence="0.999584">
Table 5: Effectiveness of score propagation.
</tableCaption>
<figure confidence="0.999523222222222">
0.98
0.96
0.94
0.92
0.88
0.86
0.84
0.82
0.78
0.76
0.9
0.8
alpha=0.9, MI
alpha=0.9, CO
alpha=0.95, MI
alpha=0.95, CO
0 2 4 6 8 10 12 14 16 18 20
number of iterations
</figure>
<figureCaption confidence="0.999038">
Figure 3: Propagation: Core items
</figureCaption>
<subsectionHeader confidence="0.968784">
4.5 Experiments on score propagation
</subsectionHeader>
<bodyText confidence="0.9999970625">To demonstrate that score propagation can further help transliteration, we use the combination scores in Table 3 as the initial scores, and apply our propagation algorithm to iteratively update them. We remove the entries when they do not co-occur with others. There are 25 such English name candidates. Thus, the initial scores are actually slightly different from the values in Table 3. We show the new scores and the best propagation scores in Table 5. In the table, “init.” refers to the initial scores. and “CO” and “MI” stand for best scores obtained using either the co-occurrence or mutual information method. While both methods result in gains, CO very slightly outperforms the MI approach. In the score propagation process, we introduce two additional parameters: the interpolation parameter α and the number of iterations k. Figure 3 and Figure 4 show the effects of these parameters. Intuitively, we want to preserve the initial score of a pair, but add a slight boost from its neighbors. Thus, we set α very close to 1 (0.9 and 0.95), and allow the system to perform 20 iterations. In both figures, the first few iterations certainly leverage the transliteration, demonstrating that the propagation method works. However, we observe that the performance drops when more iterations are used, presumably due to noise introduced from more distantly connected nodes. Thus, a relatively conservative approach is to choose a high α value, and run only a few iterations. Note, finally, that the CO method seems to be more stable than the MI method.</bodyText>
<sectionHeader confidence="0.675413" genericHeader="conclusion">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999322263157895">In this paper we have discussed the problem of Chinese-English name transliteration as one component of a system to find matching names in comparable corpora. We have proposed two methods for transliteration, one that is more traditional and based on phonetic correspondences, and one that is based on word distributions and adopts methods from information retrieval. We have shown that both methods yield good results, and that even better results can be achieved by combining the methods. We have further showed that one can improve upon the combined model by using reinforcement via score propagation when transliteration pairs cluster together in document pairs. The work we report is ongoing. We are investigating transliterations among several language pairs, and are extending these methods to Korean, Arabic, Russian and Hindi — see (Tao et al., 2006).</bodyText>
<sectionHeader confidence="0.999038" genericHeader="acknowledgments">
6 Acknowledgments
</sectionHeader>
<bodyText confidence="0.998000666666667">This work was funded by Dept. of the Interior contract NBCHC040176 (REFLEX). We also thank three anonymous reviewers for ACL06.</bodyText>
<sectionHeader confidence="0.998305" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9905995">
Lisa Ballesteros and W. Bruce Croft. 1998. Resolv-
ing ambiguity for cross-language retrieval. In Re-
search and Development in Information Retrieval,
pages 64–71.
Sergey Brin and Lawrence Page. 1998. The anatomy
of a large-scale hypertextual Web search engine.
Computer Networks and ISDN Systems, 30:107–
117.
</reference>
<page confidence="0.991562">
79
</page>
<figure confidence="0.990891">
MRR values
0 2 4 6 8 10 12 14 16 18 20
number of iterations
</figure>
<figureCaption confidence="0.984506">
Figure 4: Propagation: All items
</figureCaption>
<reference confidence="0.999067450704225">
A. Carlson, C. Cumby, J. Rosen, and D. Roth. 1999.
The SNoW learning architecture. Technical Report
UIUCDCS-R-99-2101, UIUC CS Dept.
Martin Franz, J. Scott McCarley, and Salim Roukos.
1998. Ad hoc and multilingual information retrieval
at IBM. In Text REtrieval Conference, pages 104–
115.
Pascale Fung. 1995. A pattern matching method
for finding noun and proper noun translations from
noisy parallel corpora. In Proceedings ofACL 1995,
pages 236–243.
W. Gao, K.-F. Wong, and W. Lam. 2004. Phoneme-
based transliteration of foreign names for OOV
problem. In IJCNLP, pages 374–381, Sanya,
Hainan.
P. Kantor and E. Voorhees. 2000. The TREC-5 confu-
sion track: Comparing retrieval methods for scanned
text. Information Retrieval, 2:165–176.
M. Kay and M. Roscheisen. 1993. Text translation
alignment. Computational Linguistics, 19(1):75–
102.
K. Knight and J. Graehl. 1998. Machine translitera-
tion. CL, 24(4).
J. Kruskal. 1999. An overview of sequence compar-
ison. In D. Sankoff and J. Kruskal, editors, Time
Warps, String Edits, and Macromolecules, chapter 1,
pages 1–44. CSLI, 2nd edition.
X. Li, P. Morie, and D. Roth. 2004. Robust reading:
Identification and tracing of ambiguous names. In
NAACL-2004.
J. Lin. 1991. Divergence measures based on the shan-
non entropy. IEEE Transactions on Information
Theory, 37(1):145–151.
H. Masuichi, R. Flournoy, S. Kaufmann, and S. Peters.
2000. A bootstrapping method for extracting bilin-
gual text pairs.
H.M. Meng, W.K Lo, B. Chen, and K. Tang. 2001.
Generating phonetic cognates to handle named enti-
ties in English-Chinese cross-languge spoken doc-
ument retrieval. In Proceedings of the Automatic
Speech Recognition and Understanding Workshop.
R. Rapp. 1995. Identifying word translations in non-
parallel texts. In Proceedings of ACL 1995, pages
320–322.
Fatiha Sadat, Masatoshi Yoshikawa, and Shunsuke Ue-
mura. 2003. Bilingual terminology acquisition from
comparable corpora and phrasal translation to cross-
language information retrieval. In ACL ’03, pages
141–144.
G. Salton and M. McGill. 1983. Introduction to Mod-
ern Information Retrieval. McGraw-Hill.
R. Sproat, C. Shih, W. Gale, and N. Chang. 1996. A
stochastic finite-state word-segmentation algorithm
for Chinese. CL, 22(3).
K. Tanaka and H. Iwasaki. 1996. Extraction of lexical
translation from non-aligned corpora. In Proceed-
ings of COLING 1996.
Tao Tao and ChengXiang Zhai. 2005. Mining compa-
rable bilingual text corpora for cross-language infor-
mation integration. In KDD’05, pages 691–696.
Tao Tao, Su-Youn Yoon, Andrew Fister, Richard
Sproat, and ChengXiang Zhai. 2006. Unsupervised
named entity transliteration using temporal and pho-
netic correlation. In EMNLP 2006, Sydney, July.
P. Taylor, A. Black, and R. Caley. 1998. The archi-
tecture of the Festival speech synthesis system. In
Proceedings of the Third ESCA Workshop on Speech
Synthesis, pages 147–151, Jenolan Caves, Australia.
Ying Zhang and Phil Vines. 2004. Using the web for
automated translation extraction in cross-language
information retrieval. In SIGIR ’04, pages 162–169.
</reference>
<figure confidence="0.995801909090909">
alpha=0.9, MI
alpha=0.9, CO
alpha=0.95, MI
alpha=0.95, CO
0.34
0.33
0.32
0.31
0.3
0.29
0.28
</figure>
<page confidence="0.903325">
80
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant confidence="0.429252" no="0">
<title confidence="0.999499">Named Entity Transliteration with Comparable Corpora</title>
<author confidence="0.999448">Richard Sproat</author>
<author confidence="0.999448">Tao Tao</author>
<author confidence="0.999448">ChengXiang Zhai</author>
<affiliation confidence="0.444584">University of Illinois at Urbana-Champaign, Urbana, IL, 61801</affiliation>
<abstract confidence="0.998340761904762">In this paper we investigate Chinesename transliteration using compacorpora where texts in the two languages deal in some of the same topics — and therefore share references to named entities — but are not translations of each other. We present two distinct methods for transliteration, one approach using phonetic transliteration, and the second using the temporal distribution of candidate pairs. Each of these approaches works quite well, but by combining the approaches one can achieve even better results. We then propose a novel score propagation method that utilizes the co-occurrence of transliteration pairs within document pairs. This propagation method achieves further improvement over the best results from the previous step.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Lisa Ballesteros</author>
<author>W Bruce Croft</author>
</authors>
<title>Resolving ambiguity for cross-language retrieval.</title>
<date>1998</date>
<booktitle>In Research and Development in Information Retrieval,</booktitle>
<pages>64--71</pages>
<contexts>
<context citStr="Ballesteros and Croft, 1998" endWordPosition="837" position="5214" startWordPosition="834">d-entity transliteration — e.g. (Meng et al., 2001; Gao et al., 2004), the problem has been cast as the problem of producing, for a given Chinese name, an English equivalent such as one might need in a machine translation system. For example, for the nameI-A*��wei wei-lian-mu-si, one would like to arrive at the English name V(enus) Williams. Common approaches include sourcechannel methods, following (Knight and Graehl, 1998) or maximum-entropy models. Comparable corpora have been studied extensively in the literature (e.g.,(Fung, 1995; Rapp, 1995; Tanaka and Iwasaki, 1996; Franz et al., 1998; Ballesteros and Croft, 1998; Masuichi et al., 2000; Sadat et al., 2003)), but transliteration in the context of comparable corpora has not been well addressed. The general idea of exploiting frequency correlations to acquire word translations from comparable corpora has been explored in several previous studies (e.g., (Fung, 1995; Rapp, 1995; Tanaka and Iwasaki, 1996)).Recently, a method based on Pearson correlation was proposed to mine word pairs from comparable corpora (Tao and Zhai, 2005), an idea similar to the method used in (Kay and Roscheisen, 1993) for sentence alignment. In our work, we adopt the method propose</context>
</contexts>
<marker>Ballesteros, Croft, 1998</marker>
<rawString>Lisa Ballesteros and W. Bruce Croft. 1998. Resolving ambiguity for cross-language retrieval. In Research and Development in Information Retrieval, pages 64–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergey Brin</author>
<author>Lawrence Page</author>
</authors>
<title>The anatomy of a large-scale hypertextual Web search engine.</title>
<date>1998</date>
<journal>Computer Networks and ISDN Systems,</journal>
<volume>30</volume>
<pages>117</pages>
<contexts>
<context citStr="Brin and Page, 1998" endWordPosition="2746" position="16612" startWordPosition="2743">ays: 1) The number of cooccurrences in the whole collection (Denote as CO). P(j|i) = C(i,j) where �j′ C(i,j′), C(i, j) is the cooccurrence count of (ei, ci) and (ej, cj); 2) A mutual information-based method (Denote as MI). P(j|i) = MI(i,j) where �j′ MI (i,j′), MI(i, j) is the mutual information of (ei, ci) and (ej, cj). As we will show, the CO method works better. Note that the transition probabilities between indirect neighbors are always 0. Thus propagation only happens between direct neighbors. This formulation is very similar to PageRank, a link-based ranking algorithm for Web retrieval (Brin and Page, 1998). However, our motivation is propagating scores to exploit cooccurrences, so we do not necessarily want the equation to converge. Indeed, our results show that although the initial iterations always help improve accuracy, too many iterations actually would decrease the performance. 4 Evaluation We use a comparable English-Chinese corpus to evaluate our methods for Chinese transliteration. We take one day’s worth of comparable news articles (234 Chinese stories and 322 English stories), generate about 600 English names with the entity recognizer (Li et al., 2004) as described above, and (e4, c4</context>
</contexts>
<marker>Brin, Page, 1998</marker>
<rawString>Sergey Brin and Lawrence Page. 1998. The anatomy of a large-scale hypertextual Web search engine. Computer Networks and ISDN Systems, 30:107– 117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Carlson</author>
<author>C Cumby</author>
<author>J Rosen</author>
<author>D Roth</author>
</authors>
<title>The SNoW learning architecture.</title>
<date>1999</date>
<tech>Technical Report UIUCDCS-R-99-2101, UIUC CS Dept.</tech>
<contexts>
<context citStr="Carlson et al., 1999" endWordPosition="1105" position="6870" startWordPosition="1102">with Comparable Corpora We assume that we have comparable corpora, consisting of newspaper articles in English and Chinese from the same day, or almost the same day. In our experiments we use data from the English and Chinese stories from the Xinhua News agency for about 6 months of 2001.2 We assume that we have identified names for persons and locations—two types that have a strong tendency to be transliterated wholly or mostly phonetically—in the English text; in this work we use the named-entity recognizer described in (Li et al., 2004), which is based on the SNoW machine learning toolkit (Carlson et al., 1999). To perform the transliteration task, we propose the following general three-step approach: 1. Given an English name, identify candidate Chinese character n-grams as possible transliterations. 2. Score each candidate based on how likely the candidate is to be a transliteration of the English name. We propose two different scoring methods. The first involves phonetic scoring, and the second uses the frequency profile of the candidate pair over time. We will show that each of these approaches works quite well, but by combining the approaches one can achieve even better results. 3. Propagate sco</context>
</contexts>
<marker>Carlson, Cumby, Rosen, Roth, 1999</marker>
<rawString>A. Carlson, C. Cumby, J. Rosen, and D. Roth. 1999. The SNoW learning architecture. Technical Report UIUCDCS-R-99-2101, UIUC CS Dept.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Franz</author>
<author>J Scott McCarley</author>
<author>Salim Roukos</author>
</authors>
<title>Ad hoc and multilingual information retrieval at IBM.</title>
<date>1998</date>
<booktitle>In Text REtrieval Conference,</booktitle>
<pages>104--115</pages>
<contexts>
<context citStr="Franz et al., 1998" endWordPosition="833" position="5185" startWordPosition="830">work on Chinese named-entity transliteration — e.g. (Meng et al., 2001; Gao et al., 2004), the problem has been cast as the problem of producing, for a given Chinese name, an English equivalent such as one might need in a machine translation system. For example, for the nameI-A*��wei wei-lian-mu-si, one would like to arrive at the English name V(enus) Williams. Common approaches include sourcechannel methods, following (Knight and Graehl, 1998) or maximum-entropy models. Comparable corpora have been studied extensively in the literature (e.g.,(Fung, 1995; Rapp, 1995; Tanaka and Iwasaki, 1996; Franz et al., 1998; Ballesteros and Croft, 1998; Masuichi et al., 2000; Sadat et al., 2003)), but transliteration in the context of comparable corpora has not been well addressed. The general idea of exploiting frequency correlations to acquire word translations from comparable corpora has been explored in several previous studies (e.g., (Fung, 1995; Rapp, 1995; Tanaka and Iwasaki, 1996)).Recently, a method based on Pearson correlation was proposed to mine word pairs from comparable corpora (Tao and Zhai, 2005), an idea similar to the method used in (Kay and Roscheisen, 1993) for sentence alignment. In our work</context>
</contexts>
<marker>Franz, McCarley, Roukos, 1998</marker>
<rawString>Martin Franz, J. Scott McCarley, and Salim Roukos. 1998. Ad hoc and multilingual information retrieval at IBM. In Text REtrieval Conference, pages 104– 115.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
</authors>
<title>A pattern matching method for finding noun and proper noun translations from noisy parallel corpora.</title>
<date>1995</date>
<booktitle>In Proceedings ofACL</booktitle>
<pages>236--243</pages>
<contexts>
<context citStr="Fung, 1995" endWordPosition="823" position="5127" startWordPosition="822">dminton championship. 2 Previous Work In previous work on Chinese named-entity transliteration — e.g. (Meng et al., 2001; Gao et al., 2004), the problem has been cast as the problem of producing, for a given Chinese name, an English equivalent such as one might need in a machine translation system. For example, for the nameI-A*��wei wei-lian-mu-si, one would like to arrive at the English name V(enus) Williams. Common approaches include sourcechannel methods, following (Knight and Graehl, 1998) or maximum-entropy models. Comparable corpora have been studied extensively in the literature (e.g.,(Fung, 1995; Rapp, 1995; Tanaka and Iwasaki, 1996; Franz et al., 1998; Ballesteros and Croft, 1998; Masuichi et al., 2000; Sadat et al., 2003)), but transliteration in the context of comparable corpora has not been well addressed. The general idea of exploiting frequency correlations to acquire word translations from comparable corpora has been explored in several previous studies (e.g., (Fung, 1995; Rapp, 1995; Tanaka and Iwasaki, 1996)).Recently, a method based on Pearson correlation was proposed to mine word pairs from comparable corpora (Tao and Zhai, 2005), an idea similar to the method used in (Kay</context>
</contexts>
<marker>Fung, 1995</marker>
<rawString>Pascale Fung. 1995. A pattern matching method for finding noun and proper noun translations from noisy parallel corpora. In Proceedings ofACL 1995, pages 236–243.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Gao</author>
<author>K-F Wong</author>
<author>W Lam</author>
</authors>
<title>Phonemebased transliteration of foreign names for OOV problem.</title>
<date>2004</date>
<booktitle>In IJCNLP,</booktitle>
<pages>374--381</pages>
<location>Sanya, Hainan.</location>
<contexts>
<context citStr="Gao et al., 2004" endWordPosition="752" position="4656" startWordPosition="749">Hong Kong, China 11-4, 11- 4, Zhang Ning defeat Judith Meulendijks of Netherlands 11- 2, 11-9 and third seed Gong Ruina took 21 minutes to eliminate Tine Rasmussen of Denmark 11-1, 11-1, enabling China to claim five quarterfinal places in the women’s singles. . . .������,�������¤4��Q�,�1. . . 417E*ÀQiOrpQt Ö4--l4V,4/�N, ������������11:1�����Ö ������,������11:2�11:9������ �������,������11:4�11:1�¤��Q ���Ö��� Figure 1: Sample from two stories about an international women’s badminton championship. 2 Previous Work In previous work on Chinese named-entity transliteration — e.g. (Meng et al., 2001; Gao et al., 2004), the problem has been cast as the problem of producing, for a given Chinese name, an English equivalent such as one might need in a machine translation system. For example, for the nameI-A*��wei wei-lian-mu-si, one would like to arrive at the English name V(enus) Williams. Common approaches include sourcechannel methods, following (Knight and Graehl, 1998) or maximum-entropy models. Comparable corpora have been studied extensively in the literature (e.g.,(Fung, 1995; Rapp, 1995; Tanaka and Iwasaki, 1996; Franz et al., 1998; Ballesteros and Croft, 1998; Masuichi et al., 2000; Sadat et al., 200</context>
</contexts>
<marker>Gao, Wong, Lam, 2004</marker>
<rawString>W. Gao, K.-F. Wong, and W. Lam. 2004. Phonemebased transliteration of foreign names for OOV problem. In IJCNLP, pages 374–381, Sanya, Hainan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Kantor</author>
<author>E Voorhees</author>
</authors>
<title>The TREC-5 confusion track: Comparing retrieval methods for scanned text. Information Retrieval,</title>
<date>2000</date>
<pages>2--165</pages>
<contexts>
<context citStr="Kantor and Voorhees, 2000" endWordPosition="2952" position="17888" startWordPosition="2948">, c5) wS (e7, c7) (eS, cS) n (w(k−1) ~ P(jj�)), E j j6=i,j=1 76 find potential Chinese transliterations also as previously described. We generated 627 Chinese candidates. In principle, all these 600 x 627 pairs are potential transliterations. We then apply the phonetic and time correlation methods to score and rank all the candidate Chinese-English correspondences. To evaluate the proposed transliteration methods quantitatively, we measure the accuracy of the ranked list by Mean Reciprocal Rank (MRR), a measure commonly used in information retrieval when there is precisely one correct answer (Kantor and Voorhees, 2000). The reciprocal rank is the reciprocal of the rank of the correct answer. For example, if the correct answer is ranked as the first, the reciprocal rank would be 1.0, whereas if it is ranked the second, it would be 0.5, and so forth. To evaluate the results for a set of English names, we take the mean of the reciprocal rank of each English name. We attempted to create a complete set of answers for all the English names in our test set, but a small number of English names do not seem to have any standard transliteration according to the resources that we consulted. We ended up with a list of a</context>
</contexts>
<marker>Kantor, Voorhees, 2000</marker>
<rawString>P. Kantor and E. Voorhees. 2000. The TREC-5 confusion track: Comparing retrieval methods for scanned text. Information Retrieval, 2:165–176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kay</author>
<author>M Roscheisen</author>
</authors>
<title>Text translation alignment.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<pages>102</pages>
<contexts>
<context citStr="Kay and Roscheisen, 1993" endWordPosition="921" position="5749" startWordPosition="918">995; Rapp, 1995; Tanaka and Iwasaki, 1996; Franz et al., 1998; Ballesteros and Croft, 1998; Masuichi et al., 2000; Sadat et al., 2003)), but transliteration in the context of comparable corpora has not been well addressed. The general idea of exploiting frequency correlations to acquire word translations from comparable corpora has been explored in several previous studies (e.g., (Fung, 1995; Rapp, 1995; Tanaka and Iwasaki, 1996)).Recently, a method based on Pearson correlation was proposed to mine word pairs from comparable corpora (Tao and Zhai, 2005), an idea similar to the method used in (Kay and Roscheisen, 1993) for sentence alignment. In our work, we adopt the method proposed in (Tao and Zhai, 2005) and apply it to the problem of transliteration. We also study several variations of the similarity measures. Mining transliterations from multilingual web pages was studied in (Zhang and Vines, 2004); Our work differs from this work in that we use comparable corpora (in particular, news data) and leverage the time correlation information naturally available in comparable corpora. 3 Chinese Transliteration with Comparable Corpora We assume that we have comparable corpora, consisting of newspaper articles </context>
</contexts>
<marker>Kay, Roscheisen, 1993</marker>
<rawString>M. Kay and M. Roscheisen. 1993. Text translation alignment. Computational Linguistics, 19(1):75– 102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>J Graehl</author>
</authors>
<date>1998</date>
<booktitle>Machine transliteration. CL,</booktitle>
<pages>24--4</pages>
<contexts>
<context citStr="Knight and Graehl, 1998" endWordPosition="808" position="5015" startWordPosition="805">������11:2�11:9������ �������,������11:4�11:1�¤��Q ���Ö��� Figure 1: Sample from two stories about an international women’s badminton championship. 2 Previous Work In previous work on Chinese named-entity transliteration — e.g. (Meng et al., 2001; Gao et al., 2004), the problem has been cast as the problem of producing, for a given Chinese name, an English equivalent such as one might need in a machine translation system. For example, for the nameI-A*��wei wei-lian-mu-si, one would like to arrive at the English name V(enus) Williams. Common approaches include sourcechannel methods, following (Knight and Graehl, 1998) or maximum-entropy models. Comparable corpora have been studied extensively in the literature (e.g.,(Fung, 1995; Rapp, 1995; Tanaka and Iwasaki, 1996; Franz et al., 1998; Ballesteros and Croft, 1998; Masuichi et al., 2000; Sadat et al., 2003)), but transliteration in the context of comparable corpora has not been well addressed. The general idea of exploiting frequency correlations to acquire word translations from comparable corpora has been explored in several previous studies (e.g., (Fung, 1995; Rapp, 1995; Tanaka and Iwasaki, 1996)).Recently, a method based on Pearson correlation was prop</context>
</contexts>
<marker>Knight, Graehl, 1998</marker>
<rawString>K. Knight and J. Graehl. 1998. Machine transliteration. CL, 24(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kruskal</author>
</authors>
<title>An overview of sequence comparison.</title>
<date>1999</date>
<booktitle>Time Warps, String Edits, and Macromolecules, chapter 1,</booktitle>
<pages>1--44</pages>
<editor>In D. Sankoff and J. Kruskal, editors,</editor>
<note>CSLI, 2nd edition.</note>
<contexts>
<context citStr="Kruskal, 1999" endWordPosition="1750" position="10857" startWordPosition="1749">ion attempts to match the syllablesized characters to equivalent sounding spans of the English language, we fix the c′i to be syllables, and let the e′i range over all possible subsequences of the English phone string. For training data we have a small list of 721 names in Roman script and their Chinese equivalent.3 Pronunciations for English words are obtained using the Festival text-tospeech system (Taylor et al., 1998); for Chinese, we use the standard pinyin transliteration of the characters. English-Chinese pairs in our training dictionary were aligned using the alignment algorithm from (Kruskal, 1999), and a hand-derived set of 21 rules-of-thumb: for example, we have rules that encode the fact that Chinese /l/ can correspond to English /r/, /n/ or /er/; and that Chinese /w/ may be used to represent /v/. Given that there are over 400 syllables in Mandarin (not counting tone) and each of these syllables can match a large number of potential English phone spans, this is clearly not enough training data to cover all the parameters, and so we use Good-Turing estimation to estimate probabilities for unseen correspondences. Since we would like to filter implausible transliteration pairs we are le</context>
</contexts>
<marker>Kruskal, 1999</marker>
<rawString>J. Kruskal. 1999. An overview of sequence comparison. In D. Sankoff and J. Kruskal, editors, Time Warps, String Edits, and Macromolecules, chapter 1, pages 1–44. CSLI, 2nd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Li</author>
<author>P Morie</author>
<author>D Roth</author>
</authors>
<title>Robust reading: Identification and tracing of ambiguous names.</title>
<date>2004</date>
<booktitle>In NAACL-2004.</booktitle>
<contexts>
<context citStr="Li et al., 2004" endWordPosition="1092" position="6794" startWordPosition="1089">n naturally available in comparable corpora. 3 Chinese Transliteration with Comparable Corpora We assume that we have comparable corpora, consisting of newspaper articles in English and Chinese from the same day, or almost the same day. In our experiments we use data from the English and Chinese stories from the Xinhua News agency for about 6 months of 2001.2 We assume that we have identified names for persons and locations—two types that have a strong tendency to be transliterated wholly or mostly phonetically—in the English text; in this work we use the named-entity recognizer described in (Li et al., 2004), which is based on the SNoW machine learning toolkit (Carlson et al., 1999). To perform the transliteration task, we propose the following general three-step approach: 1. Given an English name, identify candidate Chinese character n-grams as possible transliterations. 2. Score each candidate based on how likely the candidate is to be a transliteration of the English name. We propose two different scoring methods. The first involves phonetic scoring, and the second uses the frequency profile of the candidate pair over time. We will show that each of these approaches works quite well, but by co</context>
<context citStr="Li et al., 2004" endWordPosition="2833" position="17180" startWordPosition="2830">lgorithm for Web retrieval (Brin and Page, 1998). However, our motivation is propagating scores to exploit cooccurrences, so we do not necessarily want the equation to converge. Indeed, our results show that although the initial iterations always help improve accuracy, too many iterations actually would decrease the performance. 4 Evaluation We use a comparable English-Chinese corpus to evaluate our methods for Chinese transliteration. We take one day’s worth of comparable news articles (234 Chinese stories and 322 English stories), generate about 600 English names with the entity recognizer (Li et al., 2004) as described above, and (e4, c4) (e2, c2) w4 (e5, c5) w2 w1 w3 w7 (e3, c3) w5 (e5, c5) wS (e7, c7) (eS, cS) n (w(k−1) ~ P(jj�)), E j j6=i,j=1 76 find potential Chinese transliterations also as previously described. We generated 627 Chinese candidates. In principle, all these 600 x 627 pairs are potential transliterations. We then apply the phonetic and time correlation methods to score and rank all the candidate Chinese-English correspondences. To evaluate the proposed transliteration methods quantitatively, we measure the accuracy of the ranked list by Mean Reciprocal Rank (MRR), a measure c</context>
</contexts>
<marker>Li, Morie, Roth, 2004</marker>
<rawString>X. Li, P. Morie, and D. Roth. 2004. Robust reading: Identification and tracing of ambiguous names. In NAACL-2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lin</author>
</authors>
<title>Divergence measures based on the shannon entropy.</title>
<date>1991</date>
<journal>IEEE Transactions on Information Theory,</journal>
<volume>37</volume>
<issue>1</issue>
<contexts>
<context citStr="Lin, 1991" endWordPosition="2218" position="13631" startWordPosition="2217">s in a single day to form a large pseudo-document. Then, for each transliteration candidate (both Chinese and English), we compute its frequency in each of those pseudo-documents and obtain a raw frequency vector. We further normalize the raw frequency vector so that it becomes a frequency distribution over all the time points (days). In order to compute the similarity between two distribution vectors, The Pearson correlation coefficient was used in (Tao and Zhai, 2005); here we also considered two other commonly used measures – cosine (Salton and McGill, 1983), and Jensen-Shannon divergence (Lin, 1991), though our results show that Pearson correlation coefficient performs better than these two other methods. 3.4 Score Propagation In both scoring methods described above, scoring of each candidate transliteration pair is independent of the other. As we have noted, document pairs that contain lots of plausible transliteration pairs should be viewed as more plausible document pairs; at the same time, in such a situation we should also trust the putative transliteration pairs more. Thus these document pairs and transliteration pairs mutually “reinforce” each other, and this can be exploited to f</context>
</contexts>
<marker>Lin, 1991</marker>
<rawString>J. Lin. 1991. Divergence measures based on the shannon entropy. IEEE Transactions on Information Theory, 37(1):145–151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Masuichi</author>
<author>R Flournoy</author>
<author>S Kaufmann</author>
<author>S Peters</author>
</authors>
<title>A bootstrapping method for extracting bilingual text pairs.</title>
<date>2000</date>
<contexts>
<context citStr="Masuichi et al., 2000" endWordPosition="841" position="5237" startWordPosition="838">g. (Meng et al., 2001; Gao et al., 2004), the problem has been cast as the problem of producing, for a given Chinese name, an English equivalent such as one might need in a machine translation system. For example, for the nameI-A*��wei wei-lian-mu-si, one would like to arrive at the English name V(enus) Williams. Common approaches include sourcechannel methods, following (Knight and Graehl, 1998) or maximum-entropy models. Comparable corpora have been studied extensively in the literature (e.g.,(Fung, 1995; Rapp, 1995; Tanaka and Iwasaki, 1996; Franz et al., 1998; Ballesteros and Croft, 1998; Masuichi et al., 2000; Sadat et al., 2003)), but transliteration in the context of comparable corpora has not been well addressed. The general idea of exploiting frequency correlations to acquire word translations from comparable corpora has been explored in several previous studies (e.g., (Fung, 1995; Rapp, 1995; Tanaka and Iwasaki, 1996)).Recently, a method based on Pearson correlation was proposed to mine word pairs from comparable corpora (Tao and Zhai, 2005), an idea similar to the method used in (Kay and Roscheisen, 1993) for sentence alignment. In our work, we adopt the method proposed in (Tao and Zhai, 200</context>
</contexts>
<marker>Masuichi, Flournoy, Kaufmann, Peters, 2000</marker>
<rawString>H. Masuichi, R. Flournoy, S. Kaufmann, and S. Peters. 2000. A bootstrapping method for extracting bilingual text pairs.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H M Meng</author>
<author>W K Lo</author>
<author>B Chen</author>
<author>K Tang</author>
</authors>
<title>Generating phonetic cognates to handle named entities in English-Chinese cross-languge spoken document retrieval.</title>
<date>2001</date>
<booktitle>In Proceedings of the Automatic Speech Recognition and Understanding Workshop.</booktitle>
<contexts>
<context citStr="Meng et al., 2001" endWordPosition="748" position="4637" startWordPosition="745">d Ling Wan Ting of Hong Kong, China 11-4, 11- 4, Zhang Ning defeat Judith Meulendijks of Netherlands 11- 2, 11-9 and third seed Gong Ruina took 21 minutes to eliminate Tine Rasmussen of Denmark 11-1, 11-1, enabling China to claim five quarterfinal places in the women’s singles. . . .������,�������¤4��Q�,�1. . . 417E*ÀQiOrpQt Ö4--l4V,4/�N, ������������11:1�����Ö ������,������11:2�11:9������ �������,������11:4�11:1�¤��Q ���Ö��� Figure 1: Sample from two stories about an international women’s badminton championship. 2 Previous Work In previous work on Chinese named-entity transliteration — e.g. (Meng et al., 2001; Gao et al., 2004), the problem has been cast as the problem of producing, for a given Chinese name, an English equivalent such as one might need in a machine translation system. For example, for the nameI-A*��wei wei-lian-mu-si, one would like to arrive at the English name V(enus) Williams. Common approaches include sourcechannel methods, following (Knight and Graehl, 1998) or maximum-entropy models. Comparable corpora have been studied extensively in the literature (e.g.,(Fung, 1995; Rapp, 1995; Tanaka and Iwasaki, 1996; Franz et al., 1998; Ballesteros and Croft, 1998; Masuichi et al., 2000</context>
</contexts>
<marker>Meng, Lo, Chen, Tang, 2001</marker>
<rawString>H.M. Meng, W.K Lo, B. Chen, and K. Tang. 2001. Generating phonetic cognates to handle named entities in English-Chinese cross-languge spoken document retrieval. In Proceedings of the Automatic Speech Recognition and Understanding Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rapp</author>
</authors>
<title>Identifying word translations in nonparallel texts.</title>
<date>1995</date>
<booktitle>In Proceedings of ACL</booktitle>
<pages>320--322</pages>
<contexts>
<context citStr="Rapp, 1995" endWordPosition="825" position="5139" startWordPosition="824">pionship. 2 Previous Work In previous work on Chinese named-entity transliteration — e.g. (Meng et al., 2001; Gao et al., 2004), the problem has been cast as the problem of producing, for a given Chinese name, an English equivalent such as one might need in a machine translation system. For example, for the nameI-A*��wei wei-lian-mu-si, one would like to arrive at the English name V(enus) Williams. Common approaches include sourcechannel methods, following (Knight and Graehl, 1998) or maximum-entropy models. Comparable corpora have been studied extensively in the literature (e.g.,(Fung, 1995; Rapp, 1995; Tanaka and Iwasaki, 1996; Franz et al., 1998; Ballesteros and Croft, 1998; Masuichi et al., 2000; Sadat et al., 2003)), but transliteration in the context of comparable corpora has not been well addressed. The general idea of exploiting frequency correlations to acquire word translations from comparable corpora has been explored in several previous studies (e.g., (Fung, 1995; Rapp, 1995; Tanaka and Iwasaki, 1996)).Recently, a method based on Pearson correlation was proposed to mine word pairs from comparable corpora (Tao and Zhai, 2005), an idea similar to the method used in (Kay and Roschei</context>
</contexts>
<marker>Rapp, 1995</marker>
<rawString>R. Rapp. 1995. Identifying word translations in nonparallel texts. In Proceedings of ACL 1995, pages 320–322.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fatiha Sadat</author>
<author>Masatoshi Yoshikawa</author>
<author>Shunsuke Uemura</author>
</authors>
<title>Bilingual terminology acquisition from comparable corpora and phrasal translation to crosslanguage information retrieval.</title>
<date>2003</date>
<booktitle>In ACL ’03,</booktitle>
<pages>141--144</pages>
<contexts>
<context citStr="Sadat et al., 2003" endWordPosition="845" position="5258" startWordPosition="842">Gao et al., 2004), the problem has been cast as the problem of producing, for a given Chinese name, an English equivalent such as one might need in a machine translation system. For example, for the nameI-A*��wei wei-lian-mu-si, one would like to arrive at the English name V(enus) Williams. Common approaches include sourcechannel methods, following (Knight and Graehl, 1998) or maximum-entropy models. Comparable corpora have been studied extensively in the literature (e.g.,(Fung, 1995; Rapp, 1995; Tanaka and Iwasaki, 1996; Franz et al., 1998; Ballesteros and Croft, 1998; Masuichi et al., 2000; Sadat et al., 2003)), but transliteration in the context of comparable corpora has not been well addressed. The general idea of exploiting frequency correlations to acquire word translations from comparable corpora has been explored in several previous studies (e.g., (Fung, 1995; Rapp, 1995; Tanaka and Iwasaki, 1996)).Recently, a method based on Pearson correlation was proposed to mine word pairs from comparable corpora (Tao and Zhai, 2005), an idea similar to the method used in (Kay and Roscheisen, 1993) for sentence alignment. In our work, we adopt the method proposed in (Tao and Zhai, 2005) and apply it to th</context>
</contexts>
<marker>Sadat, Yoshikawa, Uemura, 2003</marker>
<rawString>Fatiha Sadat, Masatoshi Yoshikawa, and Shunsuke Uemura. 2003. Bilingual terminology acquisition from comparable corpora and phrasal translation to crosslanguage information retrieval. In ACL ’03, pages 141–144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
<author>M McGill</author>
</authors>
<title>Introduction to Modern Information Retrieval.</title>
<date>1983</date>
<publisher>McGraw-Hill.</publisher>
<contexts>
<context citStr="Salton and McGill, 1983" endWordPosition="2213" position="13588" startWordPosition="2210">sh and Chinese. 75 works as follows: We pool all documents in a single day to form a large pseudo-document. Then, for each transliteration candidate (both Chinese and English), we compute its frequency in each of those pseudo-documents and obtain a raw frequency vector. We further normalize the raw frequency vector so that it becomes a frequency distribution over all the time points (days). In order to compute the similarity between two distribution vectors, The Pearson correlation coefficient was used in (Tao and Zhai, 2005); here we also considered two other commonly used measures – cosine (Salton and McGill, 1983), and Jensen-Shannon divergence (Lin, 1991), though our results show that Pearson correlation coefficient performs better than these two other methods. 3.4 Score Propagation In both scoring methods described above, scoring of each candidate transliteration pair is independent of the other. As we have noted, document pairs that contain lots of plausible transliteration pairs should be viewed as more plausible document pairs; at the same time, in such a situation we should also trust the putative transliteration pairs more. Thus these document pairs and transliteration pairs mutually “reinforce”</context>
</contexts>
<marker>Salton, McGill, 1983</marker>
<rawString>G. Salton and M. McGill. 1983. Introduction to Modern Information Retrieval. McGraw-Hill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Sproat</author>
<author>C Shih</author>
<author>W Gale</author>
<author>N Chang</author>
</authors>
<title>A stochastic finite-state word-segmentation algorithm for Chinese.</title>
<date>1996</date>
<journal>CL,</journal>
<volume>22</volume>
<issue>3</issue>
<contexts>
<context citStr="Sproat et al., 1996" endWordPosition="1382" position="8662" startWordPosition="1379">C2003T05) and Chinese Gigaword (LDC2003T09) corpora. 74 scores to other co-occurring transliteration pairs. As we will show later, such a propagation strategy can generally further improve the transliteration accuracy; in particular, it can further improve the already high performance from combining the two scoring methods. 3.1 Candidate Selection The English named entity candidate selection process was already described above. Candidate Chinese transliterations are generated by consulting a list of characters that are frequently used for transliterating foreign names. As discussed elsewhere (Sproat et al., 1996), a subset of a few hundred characters (out of several thousand) tends to be used overwhelmingly for transliterating foreign names into Chinese. We use a list of 495 such characters, derived from various online dictionaries. A sequence of three or more characters from the list is taken as a possible name. If the character “�” occurs, which is frequently used to represent the space between parts of an English name, then at least one character to the left and right of this character will be collected, even if the character in question is not in the list of “foreign” characters. Armed with the En</context>
</contexts>
<marker>Sproat, Shih, Gale, Chang, 1996</marker>
<rawString>R. Sproat, C. Shih, W. Gale, and N. Chang. 1996. A stochastic finite-state word-segmentation algorithm for Chinese. CL, 22(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Tanaka</author>
<author>H Iwasaki</author>
</authors>
<title>Extraction of lexical translation from non-aligned corpora.</title>
<date>1996</date>
<booktitle>In Proceedings of COLING</booktitle>
<contexts>
<context citStr="Tanaka and Iwasaki, 1996" endWordPosition="829" position="5165" startWordPosition="826">Previous Work In previous work on Chinese named-entity transliteration — e.g. (Meng et al., 2001; Gao et al., 2004), the problem has been cast as the problem of producing, for a given Chinese name, an English equivalent such as one might need in a machine translation system. For example, for the nameI-A*��wei wei-lian-mu-si, one would like to arrive at the English name V(enus) Williams. Common approaches include sourcechannel methods, following (Knight and Graehl, 1998) or maximum-entropy models. Comparable corpora have been studied extensively in the literature (e.g.,(Fung, 1995; Rapp, 1995; Tanaka and Iwasaki, 1996; Franz et al., 1998; Ballesteros and Croft, 1998; Masuichi et al., 2000; Sadat et al., 2003)), but transliteration in the context of comparable corpora has not been well addressed. The general idea of exploiting frequency correlations to acquire word translations from comparable corpora has been explored in several previous studies (e.g., (Fung, 1995; Rapp, 1995; Tanaka and Iwasaki, 1996)).Recently, a method based on Pearson correlation was proposed to mine word pairs from comparable corpora (Tao and Zhai, 2005), an idea similar to the method used in (Kay and Roscheisen, 1993) for sentence al</context>
</contexts>
<marker>Tanaka, Iwasaki, 1996</marker>
<rawString>K. Tanaka and H. Iwasaki. 1996. Extraction of lexical translation from non-aligned corpora. In Proceedings of COLING 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tao Tao</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Mining comparable bilingual text corpora for cross-language information integration.</title>
<date>2005</date>
<booktitle>In KDD’05,</booktitle>
<pages>691--696</pages>
<contexts>
<context citStr="Tao and Zhai, 2005" endWordPosition="909" position="5683" startWordPosition="906">ve been studied extensively in the literature (e.g.,(Fung, 1995; Rapp, 1995; Tanaka and Iwasaki, 1996; Franz et al., 1998; Ballesteros and Croft, 1998; Masuichi et al., 2000; Sadat et al., 2003)), but transliteration in the context of comparable corpora has not been well addressed. The general idea of exploiting frequency correlations to acquire word translations from comparable corpora has been explored in several previous studies (e.g., (Fung, 1995; Rapp, 1995; Tanaka and Iwasaki, 1996)).Recently, a method based on Pearson correlation was proposed to mine word pairs from comparable corpora (Tao and Zhai, 2005), an idea similar to the method used in (Kay and Roscheisen, 1993) for sentence alignment. In our work, we adopt the method proposed in (Tao and Zhai, 2005) and apply it to the problem of transliteration. We also study several variations of the similarity measures. Mining transliterations from multilingual web pages was studied in (Zhang and Vines, 2004); Our work differs from this work in that we use comparable corpora (in particular, news data) and leverage the time correlation information naturally available in comparable corpora. 3 Chinese Transliteration with Comparable Corpora We assume </context>
<context citStr="Tao and Zhai, 2005" endWordPosition="2044" position="12591" startWordPosition="2041">netic correspondence model can then be used to score putative transliteration pairs. 3.3 Candidate Scoring based on Frequency Correlation Names of the same entity that occur in different languages often have correlated frequency patterns due to common triggers such as a major event. Thus if we have comparable news articles over a sufficiently long time period, it is possible to exploit such correlations to learn the associations of names in different languages. The idea of exploiting frequency correlation has been well studied. (See the previous work section.) We adopt the method proposed in (Tao and Zhai, 2005), which 3The LDC provides a much larger list of transliterated Chinese-English names, but we did not use this here for two reasons. First, we have found it it be quite noisy. Secondly, we were interested in seeing how well one could do with a limited resource ofjust a few hundred names, which is a more realistic scenario for languages that have fewer resources than English and Chinese. 75 works as follows: We pool all documents in a single day to form a large pseudo-document. Then, for each transliteration candidate (both Chinese and English), we compute its frequency in each of those pseudo-d</context>
</contexts>
<marker>Tao, Zhai, 2005</marker>
<rawString>Tao Tao and ChengXiang Zhai. 2005. Mining comparable bilingual text corpora for cross-language information integration. In KDD’05, pages 691–696.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tao Tao</author>
<author>Su-Youn Yoon</author>
<author>Andrew Fister</author>
<author>Richard Sproat</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Unsupervised named entity transliteration using temporal and phonetic correlation.</title>
<date>2006</date>
<booktitle>In EMNLP 2006,</booktitle>
<location>Sydney,</location>
<marker>Tao, Yoon, Fister, Sproat, Zhai, 2006</marker>
<rawString>Tao Tao, Su-Youn Yoon, Andrew Fister, Richard Sproat, and ChengXiang Zhai. 2006. Unsupervised named entity transliteration using temporal and phonetic correlation. In EMNLP 2006, Sydney, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Taylor</author>
<author>A Black</author>
<author>R Caley</author>
</authors>
<title>The architecture of the Festival speech synthesis system.</title>
<date>1998</date>
<booktitle>In Proceedings of the Third ESCA Workshop on Speech Synthesis,</booktitle>
<pages>147--151</pages>
<location>Jenolan Caves, Australia.</location>
<contexts>
<context citStr="Taylor et al., 1998" endWordPosition="1723" position="10668" startWordPosition="1720">mate of P(e′|c′) as P(e′|c′) _ Ili P(e′i|c′i). Here, e′i is the ith subsequence of the English phone string, and c′i is the ith subsequence of the Chinese phone string. Since Chinese transliteration attempts to match the syllablesized characters to equivalent sounding spans of the English language, we fix the c′i to be syllables, and let the e′i range over all possible subsequences of the English phone string. For training data we have a small list of 721 names in Roman script and their Chinese equivalent.3 Pronunciations for English words are obtained using the Festival text-tospeech system (Taylor et al., 1998); for Chinese, we use the standard pinyin transliteration of the characters. English-Chinese pairs in our training dictionary were aligned using the alignment algorithm from (Kruskal, 1999), and a hand-derived set of 21 rules-of-thumb: for example, we have rules that encode the fact that Chinese /l/ can correspond to English /r/, /n/ or /er/; and that Chinese /w/ may be used to represent /v/. Given that there are over 400 syllables in Mandarin (not counting tone) and each of these syllables can match a large number of potential English phone spans, this is clearly not enough training data to c</context>
</contexts>
<marker>Taylor, Black, Caley, 1998</marker>
<rawString>P. Taylor, A. Black, and R. Caley. 1998. The architecture of the Festival speech synthesis system. In Proceedings of the Third ESCA Workshop on Speech Synthesis, pages 147–151, Jenolan Caves, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ying Zhang</author>
<author>Phil Vines</author>
</authors>
<title>Using the web for automated translation extraction in cross-language information retrieval.</title>
<date>2004</date>
<booktitle>In SIGIR ’04,</booktitle>
<pages>162--169</pages>
<contexts>
<context citStr="Zhang and Vines, 2004" endWordPosition="967" position="6039" startWordPosition="964">translations from comparable corpora has been explored in several previous studies (e.g., (Fung, 1995; Rapp, 1995; Tanaka and Iwasaki, 1996)).Recently, a method based on Pearson correlation was proposed to mine word pairs from comparable corpora (Tao and Zhai, 2005), an idea similar to the method used in (Kay and Roscheisen, 1993) for sentence alignment. In our work, we adopt the method proposed in (Tao and Zhai, 2005) and apply it to the problem of transliteration. We also study several variations of the similarity measures. Mining transliterations from multilingual web pages was studied in (Zhang and Vines, 2004); Our work differs from this work in that we use comparable corpora (in particular, news data) and leverage the time correlation information naturally available in comparable corpora. 3 Chinese Transliteration with Comparable Corpora We assume that we have comparable corpora, consisting of newspaper articles in English and Chinese from the same day, or almost the same day. In our experiments we use data from the English and Chinese stories from the Xinhua News agency for about 6 months of 2001.2 We assume that we have identified names for persons and locations—two types that have a strong tend</context>
</contexts>
<marker>Zhang, Vines, 2004</marker>
<rawString>Ying Zhang and Phil Vines. 2004. Using the web for automated translation extraction in cross-language information retrieval. In SIGIR ’04, pages 162–169.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>