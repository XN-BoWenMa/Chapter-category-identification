<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant confidence="0.000035" no="0">
<title confidence="0.954637">
Statistical Modeling for Unit Selection in Speech Synthesis
</title>
<author confidence="0.546287">
Cyril Allauzen and Mehryar Mohri and Michael Riley∗
</author>
<affiliation confidence="0.304432">
AT&amp;T Labs – Research
</affiliation>
<address confidence="0.809722">
180 Park Avenue, Florham Park, NJ 07932, USA
</address>
<email confidence="0.967596">
{allauzen, mohri, riley}@research.att.com
</email>
<sectionHeader confidence="0.997277" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999932482758621">Traditional concatenative speech synthesis systems use a number of heuristics to define the target and concatenation costs, essential for the design of the unit selection component. In contrast to these approaches, we introduce a general statistical modeling framework for unit selection inspired by automatic speech recognition. Given appropriate data, techniques based on that framework can result in a more accurate unit selection, thereby improving the general quality of a speech synthesizer. They can also lead to a more modular and a substantially more efficient system. We present a new unit selection system based on statistical modeling. To overcome the original absence of data, we use an existing high-quality unit selection system to generate a corpus of unit sequences. We show that the concatenation cost can be accurately estimated from this corpus using a statistical n-gram language model over units. We used weighted automata and transducers for the representation of the components of the system and designed a new and more efficient composition algorithm making use of string potentials for their combination. The resulting statistical unit selection is shown to be about 2.6 times faster than the last release of the AT&amp;T Natural Voices Product while preserving the same quality, and offers much flexibility for the use and integration of new and more complex components.</bodyText>
<sectionHeader confidence="0.99406" genericHeader="introduction">
1 Motivation
</sectionHeader>
<bodyText confidence="0.987917872340426">A concatenative speech synthesis system (Hunt and Black, 1996; Beutnagel et al., 1999a) consists of three components. The first component, the textanalysis frontend, takes text as input and outputs a sequence of feature vectors that characterize the acoustic signal to synthesize. The first element of each of these vectors is the predicted phone or halfphone; other elements are features such as the phonetic context, acoustic features (e.g., pitch, duration), or prosodic features. ∗ This author’s new address is: Google, Inc, 1440 Broadway, New York, NY 10018, riley@google.com. The second component, unit selection, determines in a set of recorded acoustic units corresponding to phones (Hunt and Black, 1996) or halfphones (Beutnagel et al., 1999a) the sequence of units that is the closest to the sequence of feature vectors predicted by the text analysis frontend. The final component produces an acoustic signal from the unit sequence chosen by unit selection using simple concatenation or other methods such as PSOLA (Moulines and Charpentier, 1990) and HNM (Stylianou et al., 1997). Unit selection is performed by defining two cost functions: the target cost that estimates how the features of a recorded unit match the specified feature vector and the concatenation cost that estimates how well two units will be perceived to match when appended. Unit selection then consists of finding, given a specified sequence of feature vectors, the unit sequence that minimizes the sum of these two costs. The target and concatenation cost functions have traditionally been formed from a variety of heuristic or ad hoc quality measures based on features of the audio and text. In this paper, we follow a different approach: our goal is a system based purely on statistical modeling. The starting point is to assume that we have a training corpus of utterances labeled with the appropriate unit sequences. Specifically, for each training utterance, we assume available a sequence of feature vectors f = f i ... f,,, and the corresponding units u = ui ... u,,, that should be used to synthesize this utterance. We wish to estimate from this corpus two probability distributions, P(f|u) and P(u). Given these estimates, we can perform unit selection on a novel utterance using:</bodyText>
<equation confidence="0.999721">
P(u|f) (1)
(− log P(f|u) − log P(u)) (2)
</equation>
<bodyText confidence="0.998694833333333">Equation 1 states that the most likely unit sequence is selected given the probabilistic model used. Equation 2 follows from the definition of conditional probability and that P(f) is fixed for a given utterance. The two terms appearing in Equation 2 can be viewed as the statistical counterparts of the target and concatenation costs in traditional unit selection.</bodyText>
<equation confidence="0.96616625">
u = argmax
U
= argmin
U
</equation>
<bodyText confidence="0.998389">The statistical framework just outlined is similar to the one used in speech recognition (Jelinek, 1976). We also use several techniques that have been very successfully applied to speech recognition. For instance, in this paper, we show how −log P(u) (the concatenation cost) can be accurately estimated using a statistical n-gram language model over units.Two questions naturally arise.</bodyText>
<listItem confidence="0.5514299">(a) How can we collect a training corpus for building a statistical model? Ideally, the training corpus could be human-labeled, as in speech recognition and other natural language processing tasks. But this seemed impractical given the size of the unit inventory, the number of utterances needed for good statistical estimates, and our limited resources. Instead, we chose to use a training corpus generated by an existing high-quality unit selection system, that of the AT&amp;T Natural Voices Product. Of course, building a statistical model on that output can, at best, only match the quality of the original. But, it can serve as an exploratory trial to measure the quality of our statistical modeling. As we will see, it can also result in a synthesis system that is significantly faster and modular than the original since there are well-established algorithms for representing and optimizing statistical models of the type we will employ. To further simplify the problem, we will use the existing traditional target costs, providing statistical estimates only of the concatenation costs (− log P(u)). (b) What are the benefits of a statistical modeling approach? (1) High-quality cost functions. One issue with traditional unit selection systems is that their cost functions are the result of the following compromise: they need to be complex enough to have a perceptual meaning but simple enough to be computed efficiently. With our statistical modeling approach, the labeling phase could be performed offline by a highly accurate unit selection system, potentially slow and complex, while the run-time statistical system could still be fast.</listItem>
<bodyText confidence="0.983827714285714">Moreover, if we had audio available for our training corpus, we could exploit that in the initial labeling phase for the design of the unit selection system.</bodyText>
<listItem confidence="0.710534192307692">(2) Weighted finite-state transducer representation. In addition to the already mentioned synthesis speed and the opportunity of high-quality measures in the initial offline labeling phase, another benefit of this approach is that it leads to a natural representation by weighted transducers, and hence enables us to build a unit selection system using general and flexible representations and methods already in use for speech recognition, e.g., those found in the FSM (Mohri et al., 2000), GRM (Allauzen et al., 2004) and DCD (Allauzen et al., 2003) libraries. Other unit selection systems based on weighted transducers were also proposed in (Yi et al., 2000; Bulyko and Ostendorf, 2001). (3) Unit selection algorithms and speed-up. We present a new unit selection system based on statistical modeling. We used weighted automata and transducers for the representation of the components of the system and designed a new and efficient composition algorithm making use of string potentials for their combination. The resulting statistical unit selection is shown to be about 2.6 times faster than the last release of the AT&amp;T Natural Voices Product while preserving the same quality, and offers much flexibility for the use and integration of new and more complex components.</listItem>
<sectionHeader confidence="0.952601" genericHeader="method">
2 Unit Selection Methods
</sectionHeader>
<subsectionHeader confidence="0.997583">
2.1 Overview of a Traditional Unit Selection
System
</subsectionHeader>
<bodyText confidence="0.999963125">This section describes in detail the cost functions used in the AT&amp;T Natural Voices Product that we will use as the baseline in our experimental results, see (Beutnagel et al., 1999a) for more details about this system. In this system, unit selection is based on (Hunt and Black, 1996) but using units corresponding to halfphones instead of phones. Let U be the set of recorded units. Two cost functions are defined: the target cost Ct(fi, ui) is used to estimate the mismatch between the features of the feature vector fi and the unit ui; the concatenation cost Cc(ui, uj) is used to estimate the smoothness of the acoustic signal when concatenating the units ui and uj. Given a sequence f = f1 ... fn of feature vectors, unit selection can then be formulated as the problem of finding the sequence of units</bodyText>
<equation confidence="0.98857125">
u = u1 ... un that minimizes these two costs:
n n
u = argmin ( Ct(fi, ui) + Cc(ui−1, ui))
u∈Un i=1 i=2
</equation>
<bodyText confidence="0.995120375">In practice, not all unit sequences of a given length are considered. A preselection method such as the one proposed by (Conkie et al., 2000) is used. The computation of the target cost can be split in two parts: the context cost Cp that is the component of the target cost corresponding to the phonetic context, and the feature cost Cf that corresponds the other components of the target cost:</bodyText>
<equation confidence="0.972014">
Ct(fi, ui) = Cp(fi, ui) + Cf(fi, ui) (3)
</equation>
<bodyText confidence="0.993794888888889">For each phonetic context p of length 5, a list L(p) of the units that are the most frequently used in the phonetic context p is computed. For each feature vector fi in f, the candidate units for fi are computed in the following way. Let pi be the 5-phone context of fi in f. The context costs between fi and all the units in the preselection list of the phonetic context pi are computed and the M units with the best context cost are selected:</bodyText>
<equation confidence="0.996401">
Ui = M-best(Cp(fi,ui))
ui∈L(ρi)
</equation>
<bodyText confidence="0.998097666666667">The feature costs between fi and the units in Ui are then computed and the N units with the best target cost are selected:</bodyText>
<equation confidence="0.9720965">
U0i = N-best(Cp(fi, ui) + Cf (fi, ui))
ui∈Ui
The unit sequence u verifying:
n n
u = argmin ( Ct(fi, ui) + Cc(ui−1, ui))
u∈Ui···U;' i=1 i=2
</equation>
<bodyText confidence="0.999867">is determined using a classical Viterbi search. Thus, for each position i, the N2 concatenation costs between the units in U0 i and U0i+1 need to be computed. The caching method for concatenation costs proposed in (Beutnagel et al., 1999b) can be used to improve the efficiency of the system.</bodyText>
<subsectionHeader confidence="0.999401">
2.2 Statistical Modeling Approach
</subsectionHeader>
<bodyText confidence="0.999988647058824">Our statistical modeling approach was described in Section 1. As already mentioned, our general approach would consists of deriving both the target cost − log P(f|u) and the concatenation cost − log P(u) from appropriate training data using general statistical methods. To simplify the problem, we will use the existing target cost provided by the traditional unit selection system and concentrate on the problem of estimating the concatenation cost. We used the unit selection system presented in the previous section to generate a large corpus of more than 8M unit sequences, each unit corresponding to a unique recorded halfphone. This corpus was used to build an n-gram statistical language model using Katz backoff smoothing technique (Katz, 1987). This model provides us with a new cost function, the grammar cost Cg, defined by:</bodyText>
<equation confidence="0.994896">
Cg(uk|u1...uk−1) = −log(P(uk|u1...uk−1))
</equation>
<bodyText confidence="0.9999574">where P is the probability distribution estimated by our model. We used this new cost function to replace both the concatenation and context costs used in the traditional approach. Unit selection then consists of finding the unit sequence u such that:</bodyText>
<equation confidence="0.990615666666667">
n
u = argmin (Cf(fi, ui)+Cg(ui|ui−k ... ui−1))
u∈Un i=1
</equation>
<bodyText confidence="0.999917">In this approach, rather than using a preselection method such as that of (Conkie et al., 2000), we are using the statistical language model to restrict the candidate space (see Section 4.2).</bodyText>
<sectionHeader confidence="0.981609" genericHeader="method">
3 Representation by Weighted Finite-State
Transducers
</sectionHeader>
<bodyText confidence="0.999973166666667">An important advantage of the statistical framework we introduced for unit selection is that the resulting components can be naturally represented by weighted finite-state transducers. This casts unit selection into a familiar schema, that of a Viterbi decoder applied to a weighted transducer.</bodyText>
<subsectionHeader confidence="0.999229">
3.1 Weighted Finite-State Transducers
</subsectionHeader>
<bodyText confidence="0.999445105263158">We give a brief introduction to weighted finite-state transducers. We refer the reader to (Mohri, 2004; Mohri et al., 2000) for an extensive presentation of these devices and will use the definitions and notation introduced by these authors. A weightedfinite-state transducer T is an 8-tuple T = (Σ, Δ, Q, I, F, E, λ, p) where Σ is the finite input alphabet of the transducer, Δ is the finite output alphabet, Q is a finite set of states, I C_ Q the set of initial states, F C_ Q the set of final states, E C_ Q x (Σ U {E}) x (Δ U {E}) x R x Q a finite set of transitions, λ : I —* R the initial weight function, and p : F —* R the final weight function mapping F to R. In our statistical framework, the weights can be interpreted as log-likelihoods, thus there are added along a path. Since we use the standard Viterbi approximation, the weight associated by T to a pair of strings (x, y) E Σ∗ x Δ∗ is given by:</bodyText>
<equation confidence="0.994935">
[T ](x, y) = min
π∈R(I,x,y,F)
</equation>
<bodyText confidence="0.999616875">where R(I, x, y, F) denotes the set of paths from an initial state p E I to a final state q E F with input label x and output label y, w[7r] the weight of the path 7r, λ[p[7r]] the initial weight of the origin state of 7r, and p[n[7r]] the final weight of its destination. A Weighted automaton A = (Σ, Q, I, F, E, λ, p) is defined in a similar way by simply omitting the output (or input) labels. We denote by Π2(T) the weighted automaton obtained from T by removing its input labels.</bodyText>
<equation confidence="0.579528">
λ[p[7r]] + w[7r] + p[n[7r]]
</equation>
<figureCaption confidence="0.888889333333333">
Figure 1: (a) Weighted automaton T1. (b) Weighted
transducer T2. (c) T1 o T2, the result of the compo-
sition of T1 and T2.
</figureCaption>
<bodyText confidence="0.948267888888889">A general composition operation similar to the composition of relations can be defined for weighted finite-state transducers (Eilenberg, 1974; Berstel, 1979; Salomaa and Soittola, 1978; Kuich and Salomaa, 1986). The composition of two transducers T1 and T2 is a weighted transducer denoted by T1 o T2 and defined by:</bodyText>
<equation confidence="0.621029">
[T1 o T2](x, y) = min {[T1](x, z) + [T2](z, y)}
z∈Δ∗
</equation>
<bodyText confidence="0.9985647">There exists a simple algorithm for constructing T = T1 o T2 from T1 and T2 (Pereira and Riley, 1997; Mohri et al., 1996). The states of T are identified as pairs of a state of T1 and a state of T2. A state (q1, q2) in T1oT2 is an initial (final) state if and only if q1 is an initial (resp. final) state of T1 and q2 is an initial (resp. final) state of T2. The transitions of T are the result of matching a transition of T1 and a transition of T2 as follows: (q1, a, b, w1, qi) and (q2, b, c, w2, q2) produce the transition in T. The efficiency of this algorithm was critical to that of our unit selection system.</bodyText>
<equation confidence="0.997862">
((q1,q2),a,c,w1 + w2,(qi,q2)) (4)
</equation>
<bodyText confidence="0.9957954">Thus, we designed an improved composition that we will describe later. Figure 1(c) gives the resulting of the composition of the weighted transducers given figure 2(a) and (b).</bodyText>
<subsectionHeader confidence="0.944544">
3.2 Language Model Weighted Transducer
</subsectionHeader>
<bodyText confidence="0.999902">The n-gram statistical language model we construct for unit sequences can be represented by a weighted automaton G which assigns to each sequence u its according to our probability estimate P. Since a unit sequence u uniquely determines the corresponding halfphone sequence x, the n-gram statistical model equivalently defines a model of the joint distribution of P(x, u).</bodyText>
<equation confidence="0.9880895">
log-likelihood:
[G](u) = −log(P(u)). (5)
</equation>
<bodyText confidence="0.987279">G can be augmented to define a weighted transducer Gˆ assigning to pairs (x, u) their log-likelihoods. For any halfphone sequence x and unit sequence u, we define Gˆ by:</bodyText>
<equation confidence="0.997894">
[ ˆG](x, u) = −log P(u) (6)
</equation>
<bodyText confidence="0.999869181818182">The weighted transducer Gˆ can be used to generate all the unit sequences corresponding to a specific halfphone sequence given by a finite automaton p, using composition: p o ˆG. In our case, we also wish to use the language model transducer Gˆ to limit the number of candidate unit sequences considered. We will do that by giving a strong precedence to ngrams of units that occurred in the training corpus (see Section 4.2). Example Figure 2(a) shows the bigram model G estimated from the following corpus:</bodyText>
<equation confidence="0.814029666666667">
&lt;s&gt; u1 u2 u1 u2 &lt;/s&gt;
&lt;s&gt; u1 u3 &lt;/s&gt;
&lt;s&gt; u1 u3 u1 u2 &lt;/s&gt;
</equation>
<bodyText confidence="0.999979833333333">where (s) and Qs� are the symbols marking the start and the end of an utterance. When the unit u1 is associated to the halfphone p1 and both units u1 and u2 are associated to the halfphone p2, the corresponding weighted halfphone-to-unit transducer Gˆ is the one shown in Figure 2(b).</bodyText>
<subsectionHeader confidence="0.936541">
3.3 Unit Selection with Weighted Finite-State
Transducers
</subsectionHeader>
<bodyText confidence="0.99997875">From each sequence f = f1 ... fn of feature vectors specified by the text analysis frontend, we can straightforwardly derive the halfphone sequence to be synthesized and represent it by a finite automaton p, since the first component of each feature vector fi is the corresponding halfphone. Let W be the weighted automaton obtained by composition of p with Gˆ and projection on the output:</bodyText>
<equation confidence="0.990904">
W = Π2(p o ˆG) (7)
</equation>
<bodyText confidence="0.98548375">W represents the set of candidate unit sequences with their respective grammar costs. We can then use a speech recognition decoder to search for the best sequence u since W can be thought of as the counterpart of a speech recognition transducer, f the equivalent of the acoustic features and Cf the analogue of the acoustic cost.</bodyText>
<figure confidence="0.999909434782609">
a b c d
0 1 2 3 4
(a)
b:y
1
a:x
c:z d:t
2 3 4
0
a:u
b:v
5
c:w
6 a:s
7 8
(b)
a:x
1
b:y
3
c:z
5
d:t
7
0
a:u
2
b:v
4
c:w
6
(c)
&lt;s&gt;
u3 x/3.647 u1/0.955 u1
u3/1.871
x/5.216
.
&lt;/s&gt;/1.466
&lt;/s&gt;/0.703
u1/0.003
u1/0.703
u3/0.921
u2/1.466
x/4.053
x/5.034
u2
u2/0.514
&lt;/s&gt;/0.410
u1/1.108
&lt;/s&gt;
&lt;s&gt;
u3 x:x/3.647 p1:u1/0.955 u1
p2:u3/1.871
x:x/5.216
.
x:&lt;/s&gt;/1.466
x:&lt;/s&gt;/0.703
p1:u1/0.003
p1:u1/0.703
p2:u3/0.921
p2:u2/1.466
x:x/4.053
x:x/5.034
p2:u2/0.514
u2
x:&lt;/s&gt;/0.410
p1:u1/1.108
&lt;/s&gt;
(a) (b)
</figure>
<figureCaption confidence="0.9974725">
Figure 2: (a) n-gram language model G for unit sequences. (b) Corresponding halfphone-to-unit weighted
transducer ˆG.
</figureCaption>
<bodyText confidence="0.906375818181818">Our decoder uses a standard beam search of W to determine the best path by computing on-the-fly the feature cost between each unit and its corresponding feature vector. Composition constitutes the most costly operation in this framework. Section 4 presents several of the techniques that we used to speed up that algorithm in the context of unit selection.</bodyText>
<sectionHeader confidence="0.999744" genericHeader="method">
4 Algorithms
</sectionHeader>
<subsectionHeader confidence="0.999912">
4.1 Composition with String Potentials
</subsectionHeader>
<bodyText confidence="0.977356625">In general, composition may create noncoaccessible states, i.e., states that do not admit a path to a final state. These states can be removed after composition using a standard connection (or trimming) algorithm that removes unnecessary states. However, our purpose here is to avoid the creation of such states to save computational time. To that end, we introduce the notion of string potential at each state. Let i[π] (o[π]) be the input (resp. output) label of a path π, and denote by x n y the longest common prefix of two strings x and y. Let q be a state in a weighted transducer. The input (output) string potential of q is defined as the longest common prefix of the input (resp. output) labels of all the paths in T from q to a final state:</bodyText>
<equation confidence="0.986657333333333">
�
pi(q) =
π∈Π(q,F)
�
po(q) =
π∈Π(q,F)
</equation>
<bodyText confidence="0.999837782608696">The string potentials of the states of T can be computed using the generic shortest-distance algorithm of (Mohri, 2002) over the string semiring. They can be used in composition in the following way. We will say that two strings x and y are comparable if x is a prefix of y or y is a prefix of x. Let (q1, q2) be a state in T = T1 o T2. Note that (q1, q2) is a coaccessible state only if the output string potential of q1 in T1 and the input string potential of q2 in T2 are comparable, i.e., po(q1) is a prefix of pi(q2) or pi(q2) is a prefix of po(q1). Hence, composition can be modified to create only those states for which the string potentials are compatible. As an example, state 2 = (1, 5) of the transducer T = T1 o T2 in Figure 1 needs not be created since po(1) = bcd and pi(5) = bca are not comparable strings. The notion of string potentials can be extended to further reduce the number of non-coaccessible states created by composition. The extended input string potential of q in T, is denoted by ¯pi(q) and is the set of strings defined by:</bodyText>
<equation confidence="0.986283666666667">
¯pi(q) = pi(q) · ζi(q) (8)
i[π]
o[π]
</equation>
<bodyText confidence="0.9977455">where ζi(q) C E and is such that for every σ E ζi(q), there exist a path π from q to a final state such that pi(q)σ is a prefix of the input label of π. The extended output string potential of q, ¯po(q), is defined similarly. A state (q1, q2) in T1 o T2 is coaccessible only if</bodyText>
<equation confidence="0.969826">
(¯po(q1) · E*) n (¯pi(q2) · E*) =� 0 (9)
</equation>
<bodyText confidence="0.997097">Using string potentials helped us substantially improve the efficiency of composition in unit selection.</bodyText>
<subsectionHeader confidence="0.957887">
4.2 Language Model Transducer – Backoff
</subsectionHeader>
<bodyText confidence="0.999650205882353">As mentioned before, the transducer Gˆ represents an n-gram backoff model for the joint probability distribution P(x, u). Thus, backoff transitions are used in a standard fashion when Gˆ is viewed as an automaton over paired sequences (x, u). Since we use Gˆ as a transducer mapping halfphone sequences to unit sequences to determine the most likely unit sequence u given a halfphone sequence x 1we need to clarify the use of the backoff transitions in the composition p o ˆG. Denote by O(V ) the set of output labels of a set of transitions V . Then, the correct use derived from the definition of the backoff transitions in the joint model is as follows. At a given state s of Gˆ and for a given input halfphone a, the outgoing transitions with input a are the transitions V of s with input label a, and for each b E� O(V ), the transition of the first backoff state of s with input label a and output b. For the purpose of our unit selection system, we had to resort to an approximation. This is because in general, the backoff use just outlined leads to examining, for a given halfphone, the set of all units possible at each state, which is typically quite large.2 Instead, we restricted the inspection of the backoff states in the following way within the composition p o ˆG. A state s1 in p corresponds in the composed transducer p o Gˆ to a set of states (s1, s2), s2 E S2, where S2 is a subset of the states of ˆG. When computing the outgoing transitions of the states in (s1, s2) with input label a, the backoff transitions of a state s2 are inspected if and only if none of the states in S2 has an outgoing transition with input label a.</bodyText>
<footnote confidence="0.992706">
1This corresponds to the conditional probability P(uIx) =
P(x, u)/P(x).
2Note that more generally the vocabulary size of our statis-
tical language models, about 400,000, is quite large compared
to the usual word-based models.
</footnote>
<subsectionHeader confidence="0.92496">
4.3 Language Model Transducer – Shrinking
</subsectionHeader>
<bodyText confidence="0.999957363636364">A classical algorithm for reducing the size of an n-gram language model is shrinking using the entropy-based method of (Stolcke, 1998) or the weighted difference method (Seymore and Rosenfeld, 1996), both quite similar in practice. In our experiments, we used a modified version of the weighted difference method. Let w be a unit and let h be its conditioning history within the n-gram model. For a given shrink factor γ, the transition corresponding to the n-gram hw is removed from the weighted automaton if:</bodyText>
<equation confidence="0.992119">
log( Pe(w|h)) − log(αh Pe(w|h')) &lt; γ c(hw) (10)
</equation>
<bodyText confidence="0.998674866666667">where h' is the backoff sequence associated with h. Thus, a higher-order n-gram hw is pruned when it does not provide a probability estimate significantly different from the corresponding lower-order n-gram sequence h'w. This standard shrinking method needs to be modified to be used in the case of our halfphone-to-unit weighted transducer model with the restriction on the traversal of the backoff transitions described in the previous section. The shrinking methods must take into account all the transitions sharing the same input label at the state identified with h and its backoff state h'. Thus, at each state identified with h in ˆG, a transition with input label x is pruned when the following condition holds:</bodyText>
<equation confidence="0.947984">
Pe(w|h')) &lt; γ
c(hw)
</equation>
<bodyText confidence="0.99986725">where h' is the backoff sequence associate with h and Xxk is the set of output labels of all the outgoing transitions with input label x of the state identified with k.</bodyText>
<sectionHeader confidence="0.988926" genericHeader="evaluation and result">
5 Experimental results
</sectionHeader>
<bodyText confidence="0.999977857142857">We used the AT&amp;T Natural Voices Product speech synthesis system to synthesize 107,987 AP news articles, generating a large corpus of 8,731,662 unit sequences representing a total of 415,227,388 units. We used this corpus to build several n-gram Katz backoff language models with n = 2 or 3. Table 1 gives the size of the resulting language model weighted automata. These language models were built using the GRM Library (Allauzen et al., 2004). We evaluated these models by using them to synthesize an AP news article of 1,000 words, corresponding to 8250 units or 6 minutes of synthesized speech. Table 2 gives the unit selection time (in seconds) taken by our new system to synthesize this AP</bodyText>
<table confidence="0.985454727272727">
X log( X log(αh
w∈Xx Pe (w|h)) −
w∈Xxh�
Model No. of states No. of transitions
2-gram, unshrunken 293,935 5,003,336
3-gram, unshrunken 4,709,404 19,027,244
3-gram, y = −4 2,967,472 14,223,284
3-gram, y = −1 2,060,031 12,133,965
3-gram, y = 0 1,681,233 10,217,164
3-gram, y = 1 1,370,220 9,146,797
3-gram, y = 4 934,914 7,844,250
</table>
<tableCaption confidence="0.9638915">
Table 1: Size of the stochastic language models for
different n-gram order and shrinking factor.
</tableCaption>
<table confidence="0.826278111111111">
Model composition search total time
baseline system - - 4.5s
2-gram, unshrunken 2.9s 1.0s 3.9s
3-gram, unshrunken 1.2s 0.5s 1.7s
3-gram, y = −4 1.3s 0.5s 1.8s
3-gram, y = −1 1.5s 0.5s 2.0s
3-gram, y = 0 1.7s 0.5s 2.2s
3-gram, y = 1 2.1s 0.6s 2.7s
3-gram, y = 4 2.7s 0.9s 3.6s
</table>
<tableCaption confidence="0.868434">
Table 2: Computation time for each unit selection
system when used to synthesize the same AP news article.news article.</tableCaption>
<bodyText confidence="0.981094344827586">Experiments were run on a 1GHz Pentium III processor with 256KB of cache and 2GB of memory. The baseline system mentioned in this table is the AT&amp;T Natural Voices Product which was also used to generate our training corpus using the concatenation cost caching method from (Beutnagel et al., 1999b). For the new system, both the computation times due to composition and to the search are displayed. Note that the AT&amp;T Natural Voices Product system was highly optimized for speed. In our new systems, the standard research software libraries already mentioned were used. The search was performed using the standard speech recognition Viterbi decoder from the DCD library (Allauzen et al., 2003). With a trigram language model, our new statistical unit selection system was about 2.6 times faster than the baseline system. A formal test using the standard mean of opinion score (MOS) was used to compare the quality of the high-quality AT&amp;T Natural Voices Product synthesizer and that of the synthesizers based on our new unit selection system with shrunken and unshrunken trigram language models. In such tests, several listeners are asked to rank the quality of each utterance from 1(worst score) to 5 (best). The MOS results of the three systems with 60 utterances tested by 21 listeners are reported in Table 3 with their correspond-</bodyText>
<table confidence="0.976847">
Model raw score normalized score
baseline system 3.54 ± .20 3.09 ± .22
3-gram, unshrunken 3.45 ± .20 2.98 ± .21
3-gram, y = −1 3.40 ± .20 2.93 ± .22
</table>
<tableCaption confidence="0.995501">
Table 3: Quality testing results: we report for each
system, the mean and standard error of the raw and the listener-normalized scores.ing standard error.</tableCaption>
<bodyText confidence="0.97107472">The difference of scores between the three systems is not statistically significant (first column), in particular, the absolute difference between the two best systems is less than .1. Different listeners may rank utterances in different ways. Some may choose the full range of scores (1–5) to rank each utterance, others may select a smaller range near 5, near 3, or some other range. To factor out such possible discrepancies in ranking, we also computed the listener-normalized scores (second column of the table). This was done for each listener by removing the average score over the full set of utterances, dividing it by the standard deviation, and by centering it around 3. The results show that the difference between the normalized scores of the three systems is not significantly different. Thus, the MOS results show that the three systems have the same quality. We also measured the similarity of the two best systems by comparing the number of common units they produce for each utterance. On the AP news article already mentioned, more than 75% of the units were common.</bodyText>
<sectionHeader confidence="0.999541" genericHeader="conclusion">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999980846153846">We introduced a statistical modeling approach to unit selection in speech synthesis. This approach is likely to lead to more accurate unit selection systems based on principled learning algorithms and techniques that radically depart from the heuristic methods used in the traditional systems. Our preliminary experiments using a training corpus generated by the AT&amp;T Natural Voices Product demonstrates that statistical modeling techniques can be used to build a high-quality unit selection system. It also shows other important benefits of this approach: a substantial increase of efficiency and a greater modularity and flexibility.</bodyText>
<sectionHeader confidence="0.999252" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99989775">We thank Mark Beutnagel for helping us clarify some of the details of the unit selection system in the AT&amp;T Natural Voices Product speech synthesizer. Mark also generated the training corpora and set up the listening test used in our experiments. We also acknowledge discussions with Brian Roark about various statistical language modeling topics in the context of unit selection.</bodyText>
<sectionHeader confidence="0.996122" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998422297029703">
Cyril Allauzen, Mehryar Mohri, and Michael
Riley. 2003. DCD Library - Decoder Li-
brary, software collection for decoding and re-
lated functions. In AT&amp;T Labs - Research.
http://www.research.att.com/sw/tools/dcd.
Cyril Allauzen, Mehryar Mohri, and Brian
Roark. 2004. A General Weighted Gram-
mar Library. In Proceedings of the Ninth
International Conference on Automata (CIAA
2004), Kingston, Ontario, Canada, July.
http://www.research.att.com/sw/tools/grm.
Jean Berstel. 1979. Transductions and Context-
Free Languages. Teubner Studienbucher:
Stuttgart.
Mark Beutnagel, Alistair Conkie, Juergen
Schroeter, and Yannis Stylianou. 1999a.
The AT&amp;T Next-Gen system. In Proceedings of
the Joint Meeting ofASA, EAA and DAGA, pages
18–24, Berlin, Germany.
Mark Beutnagel, Mehryar Mohri, and Michael Ri-
ley. 1999b. Rapid unit selection from a large
speech corpus for concatenative speech synthesis.
In Proceedings of Eurospeech, volume 2, pages
607–610.
Ivan Bulyko and Mari Ostendorf. 2001. Unit selec-
tion for speech synthesis using splicing costs with
weighted finite-state trasnducers. In Proceedings
ofEurospeech, volume 2, pages 987–990.
Alistair Conkie, Mark Beutnagel, Ann Syrdal, and
Philip Brown. 2000. Preselection of candidate
units in a unit selection-based text-to-speech syn-
thesis system. In Proceedings of ICSLP, vol-
ume 3, pages 314–317.
Samuel Eilenberg. 1974. Automata, Languages
and Machines, volume A. Academic Press.
Andrew Hunt and Alan Black. 1996. Unit selec-
tion in a concatenative speech synthesis system.
In Proceedings of ICASSP’96, volume 1, pages
373–376, Atlanta, GA.
Frederick Jelinek. 1976. Continuous speech recog-
nition by statistical methods. IEEE Proceedings,
64(4):532–556.
Slava M. Katz. 1987. Estimation of probabilities
from sparse data for the language model com-
ponent of a speech recogniser. IEEE Transac-
tions on Acoustic, Speech, and Signal Processing,
35(3):400–401.
Werner Kuich and Arto Salomaa. 1986. Semir-
ings, Automata, Languages. Number 5 in EATCS
Monographs on Theoretical Computer Science.
Springer-Verlag, Berlin, Germany.
Mehryar Mohri, Fernando C. N. Pereira, and
Michael Riley. 1996. Weighted automata in text
and speech processing. In Proceedings of the
12th European Conference on Artificial Intelli-
gence (ECAI 1996), Workshop on Extended fi-
nite state models of language, Budapest, Hun-
gary. John Wiley and Sons, Chichester.
Mehryar Mohri, Fernando C. N. Pereira, and
Michael Riley. 2000. The Design Principles
of a Weighted Finite-State Transducer Library.
Theoretical Computer Science, 231(1):17–32.
http://www.research.att.com/sw/tools/fsm.
Mehryar Mohri. 2002. Semiring Frameworks
and Algorithms for Shortest-Distance Problems.
Journal of Automata, Languages and Combina-
torics, 7(3):321–350.
Mehryar Mohri. 2004. Weighted Finite-State
Transducer Algorithms: An Overview. In Car-
los Martin-Vide, Victor Mitrana, and Gheorghe
Paun, editors, Formal Languages and Applica-
tions, volume 148, VIII, 620 p. Springer, Berlin.
Eric Moulines and Francis Charpentier. 1990.
Pitch-synchronous waveform processing tech-
niques for text-to-speech synthesis using di-
phones. Speech Communication, 9(5-6):453–
467.
Fernando C. N. Pereira and Michael D. Riley. 1997.
Speech Recognition by Composition of Weighted
Finite Automata. In Finite-State Language Pro-
cessing, pages 431–453. MIT Press.
Arto Salomaa and Matti Soittola. 1978. Automata-
Theoretic Aspects of Formal Power Series.
Springer-Verlag: New York.
Kristie Seymore and Ronald Rosenfeld. 1996.
Scalable backoff language models. In Pro-
ceedings of ICSLP, volume 1, pages 232–235,
Philadelphia, Pennsylvania.
Andreas Stolcke. 1998. Entropy-based pruning
of backoff language models. In Proc. DARPA
Broadcast News Transcription and Understand-
ing Workshop, pages 270–274.
Yannis Stylianou, Thierry Dutoit, and Juergen
Schroeter. 1997. Diphone conactenation using
a harmonic plus noise model of speech. In Pro-
ceedings ofEurospeech.
Jon Yi, James Glass, and Lee Hetherington. 2000.
A flexible scalable finite-state transducer archi-
tecture for corpus-based concatenative speech
synthesis. In Proceedings of ICSLP, volume 3,
pages 322–325.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant confidence="0.162850" no="0">
<title confidence="0.999564">Statistical Modeling for Unit Selection in Speech Synthesis</title>
<author confidence="0.996397">Allauzen Mohri</author>
<affiliation confidence="0.999709">AT&amp;T Labs – Research</affiliation>
<address confidence="0.999864">180 Park Avenue, Florham Park, NJ 07932, USA</address>
<email confidence="0.993722">mohri,</email>
<abstract confidence="0.999932">Traditional concatenative speech synthesis systems use a number of heuristics to define the target and concatenation costs, essential for the design of the unit selection component. In contrast to these approaches, we introduce a general statistical modeling framework for unit selection inspired by automatic speech recognition. Given appropriate data, techniques based on that framework can result in a more accurate unit selection, thereby improving the general quality of a speech synthesizer. They can also lead to a more modular and a substantially more efficient system. We present a new unit selection system based on statistical modeling. To overcome the original absence of data, we use an existing high-quality unit selection system to generate a corpus of unit sequences. We show that the concatenation cost can be accurately estimated from this corpus using a stalanguage model over units. We used weighted automata and transducers for the representation of the components of the system and designed a new and more efficient composition algomaking use of potentials their combination. The resulting statistical unit selection is to be about faster than the last release of the AT&amp;T Natural Voices Product while preserving the same quality, and offers much flexibility for the use and integration of new and more complex components.</abstract>
<intro confidence="0.615809">1 Motivation</intro>
<note confidence="0.759233">A concatenative speech synthesis system (Hunt and Black, 1996; Beutnagel et al., 1999a) consists of</note>
<abstract confidence="0.983294222222222">components. The first component, the texttakes text as input and outputs a sequence of feature vectors that characterize the acoustic signal to synthesize. The first element of each of these vectors is the predicted phone or halfphone; other elements are features such as the phonetic context, acoustic features (e.g., pitch, duration), or prosodic features. author’s new address is: Google, Inc, 1440 Broadway,</abstract>
<address confidence="0.578388">York, NY 10018,</address>
<abstract confidence="0.997173435406698">second component, determines in a set of recorded acoustic units corresponding to phones (Hunt and Black, 1996) or halfphones (Beutnagel et al., 1999a) the sequence of that is the the sequence of feature vectors predicted by the text analysis frontend. The final component produces an acoustic signal from the unit sequence chosen by unit selection using simple concatenation or other methods such as PSOLA (Moulines and Charpentier, 1990) and HNM (Stylianou et al., 1997). Unit selection is performed by defining two cost the cost estimates how the features of a recorded unit match the specified feavector and the cost estimates how well two units will be perceived to match when appended. Unit selection then consists of finding, given a specified sequence of feature vectors, the unit sequence that minimizes the sum of these two costs. The target and concatenation cost functions have traditionally been formed from a variety of heurisor hoc measures based on features of the audio and text. In this paper, we follow a different approach: our goal is a system based purely on statistical modeling. The starting point is to assume that we have a training corpus of utterances labeled with the appropriate unit sequences. Specifically, for each training utterance, we assume available a of feature vectors the units should be used to synthesize this utterance. We wish to estimate from this corpus two probability distributions, Given these estimates, we can perform unit selection on a novel utterance using: Equation 1 states that the most likely unit sequence is selected given the probabilistic model used. Equation 2 follows from the definition of probability and that fixed for a given utterance. The two terms appearing in Equation 2 can be viewed as the statistical counterparts argmax U = argmin U of the target and concatenation costs in traditional unit selection. The statistical framework just outlined is similar to the one used in speech recognition (Jelinek, 1976). We also use several techniques that have been very successfully applied to speech recognition. For instance, in this paper, we show how concatenation cost) can be accuestimated using a statistical language model over units. Two questions naturally arise. (a) How can we collect a training corpus for builda statistical model? the training corpus could be human-labeled, as in speech recognition and other natural language processing tasks. But this seemed impractical given the size of the unit inventory, the number of utterances needed for good statistical estimates, and our limited resources. Instead, we chose to use a training corpus generated by an existing high-quality unit selection system, that of the AT&amp;T Natural Voices Product. Of course, building a statistical model on that output can, at best, only match the quality of the original. But, it can serve as an exploratory trial to measure the quality of our statistical modeling. As we will see, it can also result in a synthesis system that is significantly faster and modular than the original since there are well-established algorithms for representing and optimizing statistical models of the type we will employ. To further simplify the problem, we will use the existing traditional target costs, providing statistical estimates only of the concatecosts (b) What are the benefits of a statistical modeling approach? High-quality cost One issue with traditional unit selection systems is that their cost functions are the result of the following compromise: they need to be complex enough to have a perceptual meaning but simple enough to be computed efficiently. With our statistical modeling approach, the labeling phase could be performed offline by a highly accurate unit selection system, potentially slow and complex, while the run-time statistical system could still be fast. Moreover, if we had audio available for our training corpus, we could exploit that in the initial labeling phase for the design of the unit selection system. (2) Weighted finite-state transducer representa- In addition to the already mentioned synthesis speed and the opportunity of high-quality measures in the initial offline labeling phase, another benefit this approach is that it leads to a natural representation by weighted transducers, and hence enables us to build a unit selection system using general and flexible representations and methods already in use for speech recognition, e.g., those found in the FSM (Mohri et al., 2000), GRM (Allauzen et al., 2004) and DCD (Allauzen et al., 2003) libraries. Other unit selection systems based on weighted transducers were also proposed in (Yi et al., 2000; Bulyko and Ostendorf, 2001). Unit selection algorithms and We present a new unit selection system based on statistical modeling. We used weighted automata and transducers for the representation of the components of the system and designed a new and efficient algorithm making use of potentheir combination. The resulting statistical selection is shown to be about faster than the last release of the AT&amp;T Natural Voices Product while preserving the same quality, and offers much flexibility for the use and integration of new and more complex components. 2 Unit Selection Methods 2.1 Overview of a Traditional Unit Selection System This section describes in detail the cost functions used in the AT&amp;T Natural Voices Product that we will use as the baseline in our experimental results, see (Beutnagel et al., 1999a) for more details about this system. In this system, unit selection is based on (Hunt and Black, 1996) but using units correto halfphones instead of phones. Let be the set of recorded units. Two cost functions defined: the cost used to estimate the mismatch between the features of the vector the unit the concatenacost used to estimate the smoothness of the acoustic signal when concatenating the Given a sequence of feature vectors, unit selection can then be formulated as the problem of finding the sequence of units that minimizes these two costs: n n argmin ( + In practice, not all unit sequences of a given length are considered. A preselection method such as the one proposed by (Conkie et al., 2000) is used. The computation of the target cost can be split in two the context cost that is the component of the target cost corresponding to the phonetic conand the feature cost corresponds the other components of the target cost: = + each phonetic context length 5, a list of the units that are the most frequently used in the context computed. For each feature the candidate units for comin the following way. Let the 5-phone of The context costs between all the units in the preselection list of the phonetic computed and the with the best context cost are selected: feature costs between the units in computed and the with the best target cost are selected: + unit sequence n n argmin ( + is determined using a classical Viterbi search. Thus, each position the costs bethe units in to be computed. The caching method for concatenation costs proposed in (Beutnagel et al., 1999b) can be used to improve the efficiency of the system. 2.2 Statistical Modeling Approach Our statistical modeling approach was described in Section 1. As already mentioned, our general approach would consists of deriving both the tarcost the concatenation cost appropriate training data using general statistical methods. To simplify the problem, we will use the existing target cost provided by the traditional unit selection system and concentrate on the problem of estimating the concatenation cost. We used the unit selection system presented in the previous section to generate a large corpus of more than 8M unit sequences, each unit corresponding to a unique recorded halfphone. This corpus was used build an statistical language model using Katz backoff smoothing technique (Katz, 1987). This model provides us with a new cost function, the cost defined by: = the probability distribution estimated by our model. We used this new cost function to replace both the concatenation and context costs used in the traditional approach. Unit selection then conof finding the unit sequence that: n u argmin In this approach, rather than using a preselection method such as that of (Conkie et al., 2000), we are using the statistical language model to restrict the candidate space (see Section 4.2). 3 Representation by Weighted Finite-State Transducers An important advantage of the statistical framework we introduced for unit selection is that the resulting components can be naturally represented by weighted finite-state transducers. This casts unit selection into a familiar schema, that of a Viterbi decoder applied to a weighted transducer.</abstract>
<intro confidence="0.977741">3.1 Weighted Finite-State Transducers</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Cyril Allauzen</author>
<author>Mehryar Mohri</author>
<author>Michael Riley</author>
</authors>
<title>DCD Library - Decoder Library, software collection for decoding and related functions.</title>
<date>2003</date>
<booktitle>In AT&amp;T Labs - Research. http://www.research.att.com/sw/tools/dcd.</booktitle>
<contexts>
<context citStr="Allauzen et al., 2003" endWordPosition="1154" position="7089" startWordPosition="1151">he initial labeling phase for the design of the unit selection system. (2) Weighted finite-state transducer representation. In addition to the already mentioned synthesis speed and the opportunity of high-quality measures in the initial offline labeling phase, another benefit of this approach is that it leads to a natural representation by weighted transducers, and hence enables us to build a unit selection system using general and flexible representations and methods already in use for speech recognition, e.g., those found in the FSM (Mohri et al., 2000), GRM (Allauzen et al., 2004) and DCD (Allauzen et al., 2003) libraries. Other unit selection systems based on weighted transducers were also proposed in (Yi et al., 2000; Bulyko and Ostendorf, 2001). (3) Unit selection algorithms and speed-up. We present a new unit selection system based on statistical modeling. We used weighted automata and transducers for the representation of the components of the system and designed a new and efficient composition algorithm making use of string potentials for their combination. The resulting statistical unit selection is shown to be about 2.6 times faster than the last release of the AT&amp;T Natural Voices Product whi</context>
<context citStr="Allauzen et al., 2003" endWordPosition="4567" position="26118" startWordPosition="4563">he and 2GB of memory. The baseline system mentioned in this table is the AT&amp;T Natural Voices Product which was also used to generate our training corpus using the concatenation cost caching method from (Beutnagel et al., 1999b). For the new system, both the computation times due to composition and to the search are displayed. Note that the AT&amp;T Natural Voices Product system was highly optimized for speed. In our new systems, the standard research software libraries already mentioned were used. The search was performed using the standard speech recognition Viterbi decoder from the DCD library (Allauzen et al., 2003). With a trigram language model, our new statistical unit selection system was about 2.6 times faster than the baseline system. A formal test using the standard mean of opinion score (MOS) was used to compare the quality of the high-quality AT&amp;T Natural Voices Product synthesizer and that of the synthesizers based on our new unit selection system with shrunken and unshrunken trigram language models. In such tests, several listeners are asked to rank the quality of each utterance from 1(worst score) to 5 (best). The MOS results of the three systems with 60 utterances tested by 21 listeners are </context>
</contexts>
<marker>Allauzen, Mohri, Riley, 2003</marker>
<rawString>Cyril Allauzen, Mehryar Mohri, and Michael Riley. 2003. DCD Library - Decoder Library, software collection for decoding and related functions. In AT&amp;T Labs - Research. http://www.research.att.com/sw/tools/dcd.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cyril Allauzen</author>
<author>Mehryar Mohri</author>
<author>Brian Roark</author>
</authors>
<title>A General Weighted Grammar Library.</title>
<date>2004</date>
<booktitle>In Proceedings of the Ninth International Conference on Automata (CIAA 2004),</booktitle>
<location>Kingston, Ontario, Canada,</location>
<note>http://www.research.att.com/sw/tools/grm.</note>
<contexts>
<context citStr="Allauzen et al., 2004" endWordPosition="1148" position="7057" startWordPosition="1145">rpus, we could exploit that in the initial labeling phase for the design of the unit selection system. (2) Weighted finite-state transducer representation. In addition to the already mentioned synthesis speed and the opportunity of high-quality measures in the initial offline labeling phase, another benefit of this approach is that it leads to a natural representation by weighted transducers, and hence enables us to build a unit selection system using general and flexible representations and methods already in use for speech recognition, e.g., those found in the FSM (Mohri et al., 2000), GRM (Allauzen et al., 2004) and DCD (Allauzen et al., 2003) libraries. Other unit selection systems based on weighted transducers were also proposed in (Yi et al., 2000; Bulyko and Ostendorf, 2001). (3) Unit selection algorithms and speed-up. We present a new unit selection system based on statistical modeling. We used weighted automata and transducers for the representation of the components of the system and designed a new and efficient composition algorithm making use of string potentials for their combination. The resulting statistical unit selection is shown to be about 2.6 times faster than the last release of the</context>
<context citStr="Allauzen et al., 2004" endWordPosition="4258" position="24351" startWordPosition="4255">he backoff sequence associate with h and Xxk is the set of output labels of all the outgoing transitions with input label x of the state identified with k. 5 Experimental results We used the AT&amp;T Natural Voices Product speech synthesis system to synthesize 107,987 AP news articles, generating a large corpus of 8,731,662 unit sequences representing a total of 415,227,388 units. We used this corpus to build several n-gram Katz backoff language models with n = 2 or 3. Table 1 gives the size of the resulting language model weighted automata. These language models were built using the GRM Library (Allauzen et al., 2004). We evaluated these models by using them to synthesize an AP news article of 1,000 words, corresponding to 8250 units or 6 minutes of synthesized speech. Table 2 gives the unit selection time (in seconds) taken by our new system to synthesize this AP X log( X log(αh w∈Xx Pe (w|h)) − w∈Xxh� Model No. of states No. of transitions 2-gram, unshrunken 293,935 5,003,336 3-gram, unshrunken 4,709,404 19,027,244 3-gram, y = −4 2,967,472 14,223,284 3-gram, y = −1 2,060,031 12,133,965 3-gram, y = 0 1,681,233 10,217,164 3-gram, y = 1 1,370,220 9,146,797 3-gram, y = 4 934,914 7,844,250 Table 1: Size of th</context>
</contexts>
<marker>Allauzen, Mohri, Roark, 2004</marker>
<rawString>Cyril Allauzen, Mehryar Mohri, and Brian Roark. 2004. A General Weighted Grammar Library. In Proceedings of the Ninth International Conference on Automata (CIAA 2004), Kingston, Ontario, Canada, July. http://www.research.att.com/sw/tools/grm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean Berstel</author>
</authors>
<title>Transductions and ContextFree Languages. Teubner Studienbucher:</title>
<date>1979</date>
<location>Stuttgart.</location>
<contexts>
<context citStr="Berstel, 1979" endWordPosition="2350" position="13802" startWordPosition="2349">he initial weight of the origin state of 7r, and p[n[7r]] the final weight of its destination. A Weighted automaton A = (Σ, Q, I, F, E, λ, p) is defined in a similar way by simply omitting the output (or input) labels. We denote by Π2(T) the λ[p[7r]] + w[7r] + p[n[7r]] Figure 1: (a) Weighted automaton T1. (b) Weighted transducer T2. (c) T1 o T2, the result of the composition of T1 and T2. weighted automaton obtained from T by removing its input labels. A general composition operation similar to the composition of relations can be defined for weighted finite-state transducers (Eilenberg, 1974; Berstel, 1979; Salomaa and Soittola, 1978; Kuich and Salomaa, 1986). The composition of two transducers T1 and T2 is a weighted transducer denoted by T1 o T2 and defined by: [T1 o T2](x, y) = min {[T1](x, z) + [T2](z, y)} z∈Δ∗ There exists a simple algorithm for constructing T = T1 o T2 from T1 and T2 (Pereira and Riley, 1997; Mohri et al., 1996). The states of T are identified as pairs of a state of T1 and a state of T2. A state (q1, q2) in T1oT2 is an initial (final) state if and only if q1 is an initial (resp. final) state of T1 and q2 is an initial (resp. final) state of T2. The transitions of T are th</context>
</contexts>
<marker>Berstel, 1979</marker>
<rawString>Jean Berstel. 1979. Transductions and ContextFree Languages. Teubner Studienbucher: Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Beutnagel</author>
<author>Alistair Conkie</author>
<author>Juergen Schroeter</author>
<author>Yannis Stylianou</author>
</authors>
<date>1999</date>
<contexts>
<context citStr="Beutnagel et al., 1999" endWordPosition="272" position="1721" startWordPosition="269"> a statistical n-gram language model over units. We used weighted automata and transducers for the representation of the components of the system and designed a new and more efficient composition algorithm making use of string potentials for their combination. The resulting statistical unit selection is shown to be about 2.6 times faster than the last release of the AT&amp;T Natural Voices Product while preserving the same quality, and offers much flexibility for the use and integration of new and more complex components. 1 Motivation A concatenative speech synthesis system (Hunt and Black, 1996; Beutnagel et al., 1999a) consists of three components. The first component, the textanalysis frontend, takes text as input and outputs a sequence of feature vectors that characterize the acoustic signal to synthesize. The first element of each of these vectors is the predicted phone or halfphone; other elements are features such as the phonetic context, acoustic features (e.g., pitch, duration), or prosodic features. ∗ This author’s new address is: Google, Inc, 1440 Broadway, New York, NY 10018, riley@google.com. The second component, unit selection, determines in a set of recorded acoustic units corresponding to p</context>
<context citStr="Beutnagel et al., 1999" endWordPosition="1313" position="8071" startWordPosition="1310">ned a new and efficient composition algorithm making use of string potentials for their combination. The resulting statistical unit selection is shown to be about 2.6 times faster than the last release of the AT&amp;T Natural Voices Product while preserving the same quality, and offers much flexibility for the use and integration of new and more complex components. 2 Unit Selection Methods 2.1 Overview of a Traditional Unit Selection System This section describes in detail the cost functions used in the AT&amp;T Natural Voices Product that we will use as the baseline in our experimental results, see (Beutnagel et al., 1999a) for more details about this system. In this system, unit selection is based on (Hunt and Black, 1996) but using units corresponding to halfphones instead of phones. Let U be the set of recorded units. Two cost functions are defined: the target cost Ct(fi, ui) is used to estimate the mismatch between the features of the feature vector fi and the unit ui; the concatenation cost Cc(ui, uj) is used to estimate the smoothness of the acoustic signal when concatenating the units ui and uj. Given a sequence f = f1 ... fn of feature vectors, unit selection can then be formulated as the problem of fi</context>
<context citStr="Beutnagel et al., 1999" endWordPosition="1717" position="10214" startWordPosition="1714"> phonetic context pi are computed and the M units with the best context cost are selected: Ui = M-best(Cp(fi,ui)) ui∈L(ρi) The feature costs between fi and the units in Ui are then computed and the N units with the best target cost are selected: U0i = N-best(Cp(fi, ui) + Cf (fi, ui)) ui∈Ui The unit sequence u verifying: n n u = argmin ( Ct(fi, ui) + Cc(ui−1, ui)) u∈Ui···U;' i=1 i=2 is determined using a classical Viterbi search. Thus, for each position i, the N2 concatenation costs between the units in U0 i and U0i+1 need to be computed. The caching method for concatenation costs proposed in (Beutnagel et al., 1999b) can be used to improve the efficiency of the system. 2.2 Statistical Modeling Approach Our statistical modeling approach was described in Section 1. As already mentioned, our general approach would consists of deriving both the target cost − log P(f|u) and the concatenation cost − log P(u) from appropriate training data using general statistical methods. To simplify the problem, we will use the existing target cost provided by the traditional unit selection system and concentrate on the problem of estimating the concatenation cost. We used the unit selection system presented in the previous</context>
<context citStr="Beutnagel et al., 1999" endWordPosition="4501" position="25721" startWordPosition="4498">nshrunken 2.9s 1.0s 3.9s 3-gram, unshrunken 1.2s 0.5s 1.7s 3-gram, y = −4 1.3s 0.5s 1.8s 3-gram, y = −1 1.5s 0.5s 2.0s 3-gram, y = 0 1.7s 0.5s 2.2s 3-gram, y = 1 2.1s 0.6s 2.7s 3-gram, y = 4 2.7s 0.9s 3.6s Table 2: Computation time for each unit selection system when used to synthesize the same AP news article. news article. Experiments were run on a 1GHz Pentium III processor with 256KB of cache and 2GB of memory. The baseline system mentioned in this table is the AT&amp;T Natural Voices Product which was also used to generate our training corpus using the concatenation cost caching method from (Beutnagel et al., 1999b). For the new system, both the computation times due to composition and to the search are displayed. Note that the AT&amp;T Natural Voices Product system was highly optimized for speed. In our new systems, the standard research software libraries already mentioned were used. The search was performed using the standard speech recognition Viterbi decoder from the DCD library (Allauzen et al., 2003). With a trigram language model, our new statistical unit selection system was about 2.6 times faster than the baseline system. A formal test using the standard mean of opinion score (MOS) was used to co</context>
</contexts>
<marker>Beutnagel, Conkie, Schroeter, Stylianou, 1999</marker>
<rawString>Mark Beutnagel, Alistair Conkie, Juergen Schroeter, and Yannis Stylianou. 1999a.</rawString>
</citation>
<citation valid="false">
<title>The AT&amp;T Next-Gen system.</title>
<booktitle>In Proceedings of the Joint Meeting ofASA, EAA and DAGA,</booktitle>
<pages>18--24</pages>
<location>Berlin, Germany.</location>
<marker/>
<rawString>The AT&amp;T Next-Gen system. In Proceedings of the Joint Meeting ofASA, EAA and DAGA, pages 18–24, Berlin, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Beutnagel</author>
<author>Mehryar Mohri</author>
<author>Michael Riley</author>
</authors>
<title>Rapid unit selection from a large speech corpus for concatenative speech synthesis.</title>
<date>1999</date>
<booktitle>In Proceedings of Eurospeech,</booktitle>
<volume>2</volume>
<pages>607--610</pages>
<contexts>
<context citStr="Beutnagel et al., 1999" endWordPosition="272" position="1721" startWordPosition="269"> a statistical n-gram language model over units. We used weighted automata and transducers for the representation of the components of the system and designed a new and more efficient composition algorithm making use of string potentials for their combination. The resulting statistical unit selection is shown to be about 2.6 times faster than the last release of the AT&amp;T Natural Voices Product while preserving the same quality, and offers much flexibility for the use and integration of new and more complex components. 1 Motivation A concatenative speech synthesis system (Hunt and Black, 1996; Beutnagel et al., 1999a) consists of three components. The first component, the textanalysis frontend, takes text as input and outputs a sequence of feature vectors that characterize the acoustic signal to synthesize. The first element of each of these vectors is the predicted phone or halfphone; other elements are features such as the phonetic context, acoustic features (e.g., pitch, duration), or prosodic features. ∗ This author’s new address is: Google, Inc, 1440 Broadway, New York, NY 10018, riley@google.com. The second component, unit selection, determines in a set of recorded acoustic units corresponding to p</context>
<context citStr="Beutnagel et al., 1999" endWordPosition="1313" position="8071" startWordPosition="1310">ned a new and efficient composition algorithm making use of string potentials for their combination. The resulting statistical unit selection is shown to be about 2.6 times faster than the last release of the AT&amp;T Natural Voices Product while preserving the same quality, and offers much flexibility for the use and integration of new and more complex components. 2 Unit Selection Methods 2.1 Overview of a Traditional Unit Selection System This section describes in detail the cost functions used in the AT&amp;T Natural Voices Product that we will use as the baseline in our experimental results, see (Beutnagel et al., 1999a) for more details about this system. In this system, unit selection is based on (Hunt and Black, 1996) but using units corresponding to halfphones instead of phones. Let U be the set of recorded units. Two cost functions are defined: the target cost Ct(fi, ui) is used to estimate the mismatch between the features of the feature vector fi and the unit ui; the concatenation cost Cc(ui, uj) is used to estimate the smoothness of the acoustic signal when concatenating the units ui and uj. Given a sequence f = f1 ... fn of feature vectors, unit selection can then be formulated as the problem of fi</context>
<context citStr="Beutnagel et al., 1999" endWordPosition="1717" position="10214" startWordPosition="1714"> phonetic context pi are computed and the M units with the best context cost are selected: Ui = M-best(Cp(fi,ui)) ui∈L(ρi) The feature costs between fi and the units in Ui are then computed and the N units with the best target cost are selected: U0i = N-best(Cp(fi, ui) + Cf (fi, ui)) ui∈Ui The unit sequence u verifying: n n u = argmin ( Ct(fi, ui) + Cc(ui−1, ui)) u∈Ui···U;' i=1 i=2 is determined using a classical Viterbi search. Thus, for each position i, the N2 concatenation costs between the units in U0 i and U0i+1 need to be computed. The caching method for concatenation costs proposed in (Beutnagel et al., 1999b) can be used to improve the efficiency of the system. 2.2 Statistical Modeling Approach Our statistical modeling approach was described in Section 1. As already mentioned, our general approach would consists of deriving both the target cost − log P(f|u) and the concatenation cost − log P(u) from appropriate training data using general statistical methods. To simplify the problem, we will use the existing target cost provided by the traditional unit selection system and concentrate on the problem of estimating the concatenation cost. We used the unit selection system presented in the previous</context>
<context citStr="Beutnagel et al., 1999" endWordPosition="4501" position="25721" startWordPosition="4498">nshrunken 2.9s 1.0s 3.9s 3-gram, unshrunken 1.2s 0.5s 1.7s 3-gram, y = −4 1.3s 0.5s 1.8s 3-gram, y = −1 1.5s 0.5s 2.0s 3-gram, y = 0 1.7s 0.5s 2.2s 3-gram, y = 1 2.1s 0.6s 2.7s 3-gram, y = 4 2.7s 0.9s 3.6s Table 2: Computation time for each unit selection system when used to synthesize the same AP news article. news article. Experiments were run on a 1GHz Pentium III processor with 256KB of cache and 2GB of memory. The baseline system mentioned in this table is the AT&amp;T Natural Voices Product which was also used to generate our training corpus using the concatenation cost caching method from (Beutnagel et al., 1999b). For the new system, both the computation times due to composition and to the search are displayed. Note that the AT&amp;T Natural Voices Product system was highly optimized for speed. In our new systems, the standard research software libraries already mentioned were used. The search was performed using the standard speech recognition Viterbi decoder from the DCD library (Allauzen et al., 2003). With a trigram language model, our new statistical unit selection system was about 2.6 times faster than the baseline system. A formal test using the standard mean of opinion score (MOS) was used to co</context>
</contexts>
<marker>Beutnagel, Mohri, Riley, 1999</marker>
<rawString>Mark Beutnagel, Mehryar Mohri, and Michael Riley. 1999b. Rapid unit selection from a large speech corpus for concatenative speech synthesis. In Proceedings of Eurospeech, volume 2, pages 607–610.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Bulyko</author>
<author>Mari Ostendorf</author>
</authors>
<title>Unit selection for speech synthesis using splicing costs with weighted finite-state trasnducers.</title>
<date>2001</date>
<booktitle>In Proceedings ofEurospeech,</booktitle>
<volume>2</volume>
<pages>987--990</pages>
<contexts>
<context citStr="Bulyko and Ostendorf, 2001" endWordPosition="1175" position="7227" startWordPosition="1172">on to the already mentioned synthesis speed and the opportunity of high-quality measures in the initial offline labeling phase, another benefit of this approach is that it leads to a natural representation by weighted transducers, and hence enables us to build a unit selection system using general and flexible representations and methods already in use for speech recognition, e.g., those found in the FSM (Mohri et al., 2000), GRM (Allauzen et al., 2004) and DCD (Allauzen et al., 2003) libraries. Other unit selection systems based on weighted transducers were also proposed in (Yi et al., 2000; Bulyko and Ostendorf, 2001). (3) Unit selection algorithms and speed-up. We present a new unit selection system based on statistical modeling. We used weighted automata and transducers for the representation of the components of the system and designed a new and efficient composition algorithm making use of string potentials for their combination. The resulting statistical unit selection is shown to be about 2.6 times faster than the last release of the AT&amp;T Natural Voices Product while preserving the same quality, and offers much flexibility for the use and integration of new and more complex components. 2 Unit Selecti</context>
</contexts>
<marker>Bulyko, Ostendorf, 2001</marker>
<rawString>Ivan Bulyko and Mari Ostendorf. 2001. Unit selection for speech synthesis using splicing costs with weighted finite-state trasnducers. In Proceedings ofEurospeech, volume 2, pages 987–990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alistair Conkie</author>
<author>Mark Beutnagel</author>
<author>Ann Syrdal</author>
<author>Philip Brown</author>
</authors>
<title>Preselection of candidate units in a unit selection-based text-to-speech synthesis system.</title>
<date>2000</date>
<booktitle>In Proceedings of ICSLP,</booktitle>
<volume>3</volume>
<pages>314--317</pages>
<contexts>
<context citStr="Conkie et al., 2000" endWordPosition="1477" position="8943" startWordPosition="1474">Ct(fi, ui) is used to estimate the mismatch between the features of the feature vector fi and the unit ui; the concatenation cost Cc(ui, uj) is used to estimate the smoothness of the acoustic signal when concatenating the units ui and uj. Given a sequence f = f1 ... fn of feature vectors, unit selection can then be formulated as the problem of finding the sequence of units u = u1 ... un that minimizes these two costs: n n u = argmin ( Ct(fi, ui) + Cc(ui−1, ui)) u∈Un i=1 i=2 In practice, not all unit sequences of a given length are considered. A preselection method such as the one proposed by (Conkie et al., 2000) is used. The computation of the target cost can be split in two parts: the context cost Cp that is the component of the target cost corresponding to the phonetic context, and the feature cost Cf that corresponds the other components of the target cost: Ct(fi, ui) = Cp(fi, ui) + Cf(fi, ui) (3) For each phonetic context p of length 5, a list L(p) of the units that are the most frequently used in the phonetic context p is computed. For each feature vector fi in f, the candidate units for fi are computed in the following way. Let pi be the 5-phone context of fi in f. The context costs between fi </context>
<context citStr="Conkie et al., 2000" endWordPosition="1939" position="11584" startWordPosition="1936">ild an n-gram statistical language model using Katz backoff smoothing technique (Katz, 1987). This model provides us with a new cost function, the grammar cost Cg, defined by: Cg(uk|u1...uk−1) = −log(P(uk|u1...uk−1)) where P is the probability distribution estimated by our model. We used this new cost function to replace both the concatenation and context costs used in the traditional approach. Unit selection then consists of finding the unit sequence u such that: n u = argmin (Cf(fi, ui)+Cg(ui|ui−k ... ui−1)) u∈Un i=1 In this approach, rather than using a preselection method such as that of (Conkie et al., 2000), we are using the statistical language model to restrict the candidate space (see Section 4.2). 3 Representation by Weighted Finite-State Transducers An important advantage of the statistical framework we introduced for unit selection is that the resulting components can be naturally represented by weighted finite-state transducers. This casts unit selection into a familiar schema, that of a Viterbi decoder applied to a weighted transducer. 3.1 Weighted Finite-State Transducers We give a brief introduction to weighted finite-state transducers. We refer the reader to (Mohri, 2004; Mohri et al.</context>
</contexts>
<marker>Conkie, Beutnagel, Syrdal, Brown, 2000</marker>
<rawString>Alistair Conkie, Mark Beutnagel, Ann Syrdal, and Philip Brown. 2000. Preselection of candidate units in a unit selection-based text-to-speech synthesis system. In Proceedings of ICSLP, volume 3, pages 314–317.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel Eilenberg</author>
</authors>
<date>1974</date>
<journal>Automata, Languages and Machines,</journal>
<volume>volume</volume>
<publisher>A. Academic Press.</publisher>
<contexts>
<context citStr="Eilenberg, 1974" endWordPosition="2348" position="13787" startWordPosition="2347">th 7r, λ[p[7r]] the initial weight of the origin state of 7r, and p[n[7r]] the final weight of its destination. A Weighted automaton A = (Σ, Q, I, F, E, λ, p) is defined in a similar way by simply omitting the output (or input) labels. We denote by Π2(T) the λ[p[7r]] + w[7r] + p[n[7r]] Figure 1: (a) Weighted automaton T1. (b) Weighted transducer T2. (c) T1 o T2, the result of the composition of T1 and T2. weighted automaton obtained from T by removing its input labels. A general composition operation similar to the composition of relations can be defined for weighted finite-state transducers (Eilenberg, 1974; Berstel, 1979; Salomaa and Soittola, 1978; Kuich and Salomaa, 1986). The composition of two transducers T1 and T2 is a weighted transducer denoted by T1 o T2 and defined by: [T1 o T2](x, y) = min {[T1](x, z) + [T2](z, y)} z∈Δ∗ There exists a simple algorithm for constructing T = T1 o T2 from T1 and T2 (Pereira and Riley, 1997; Mohri et al., 1996). The states of T are identified as pairs of a state of T1 and a state of T2. A state (q1, q2) in T1oT2 is an initial (final) state if and only if q1 is an initial (resp. final) state of T1 and q2 is an initial (resp. final) state of T2. The transiti</context>
</contexts>
<marker>Eilenberg, 1974</marker>
<rawString>Samuel Eilenberg. 1974. Automata, Languages and Machines, volume A. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Hunt</author>
<author>Alan Black</author>
</authors>
<title>Unit selection in a concatenative speech synthesis system.</title>
<date>1996</date>
<booktitle>In Proceedings of ICASSP’96,</booktitle>
<volume>1</volume>
<pages>373--376</pages>
<location>Atlanta, GA.</location>
<contexts>
<context citStr="Hunt and Black, 1996" endWordPosition="268" position="1697" startWordPosition="265">from this corpus using a statistical n-gram language model over units. We used weighted automata and transducers for the representation of the components of the system and designed a new and more efficient composition algorithm making use of string potentials for their combination. The resulting statistical unit selection is shown to be about 2.6 times faster than the last release of the AT&amp;T Natural Voices Product while preserving the same quality, and offers much flexibility for the use and integration of new and more complex components. 1 Motivation A concatenative speech synthesis system (Hunt and Black, 1996; Beutnagel et al., 1999a) consists of three components. The first component, the textanalysis frontend, takes text as input and outputs a sequence of feature vectors that characterize the acoustic signal to synthesize. The first element of each of these vectors is the predicted phone or halfphone; other elements are features such as the phonetic context, acoustic features (e.g., pitch, duration), or prosodic features. ∗ This author’s new address is: Google, Inc, 1440 Broadway, New York, NY 10018, riley@google.com. The second component, unit selection, determines in a set of recorded acoustic </context>
<context citStr="Hunt and Black, 1996" endWordPosition="1331" position="8175" startWordPosition="1328">resulting statistical unit selection is shown to be about 2.6 times faster than the last release of the AT&amp;T Natural Voices Product while preserving the same quality, and offers much flexibility for the use and integration of new and more complex components. 2 Unit Selection Methods 2.1 Overview of a Traditional Unit Selection System This section describes in detail the cost functions used in the AT&amp;T Natural Voices Product that we will use as the baseline in our experimental results, see (Beutnagel et al., 1999a) for more details about this system. In this system, unit selection is based on (Hunt and Black, 1996) but using units corresponding to halfphones instead of phones. Let U be the set of recorded units. Two cost functions are defined: the target cost Ct(fi, ui) is used to estimate the mismatch between the features of the feature vector fi and the unit ui; the concatenation cost Cc(ui, uj) is used to estimate the smoothness of the acoustic signal when concatenating the units ui and uj. Given a sequence f = f1 ... fn of feature vectors, unit selection can then be formulated as the problem of finding the sequence of units u = u1 ... un that minimizes these two costs: n n u = argmin ( Ct(fi, ui) + </context>
</contexts>
<marker>Hunt, Black, 1996</marker>
<rawString>Andrew Hunt and Alan Black. 1996. Unit selection in a concatenative speech synthesis system. In Proceedings of ICASSP’96, volume 1, pages 373–376, Atlanta, GA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frederick Jelinek</author>
</authors>
<title>Continuous speech recognition by statistical methods.</title>
<date>1976</date>
<journal>IEEE Proceedings,</journal>
<volume>64</volume>
<issue>4</issue>
<contexts>
<context citStr="Jelinek, 1976" endWordPosition="726" position="4447" startWordPosition="725">ven these estimates, we can perform unit selection on a novel utterance using: P(u|f) (1) (− log P(f|u) − log P(u)) (2) Equation 1 states that the most likely unit sequence is selected given the probabilistic model used. Equation 2 follows from the definition of conditional probability and that P(f) is fixed for a given utterance. The two terms appearing in Equation 2 can be viewed as the statistical counterparts u = argmax U = argmin U of the target and concatenation costs in traditional unit selection. The statistical framework just outlined is similar to the one used in speech recognition (Jelinek, 1976). We also use several techniques that have been very successfully applied to speech recognition. For instance, in this paper, we show how −log P(u) (the concatenation cost) can be accurately estimated using a statistical n-gram language model over units. Two questions naturally arise. (a) How can we collect a training corpus for building a statistical model? Ideally, the training corpus could be human-labeled, as in speech recognition and other natural language processing tasks. But this seemed impractical given the size of the unit inventory, the number of utterances needed for good statistic</context>
</contexts>
<marker>Jelinek, 1976</marker>
<rawString>Frederick Jelinek. 1976. Continuous speech recognition by statistical methods. IEEE Proceedings, 64(4):532–556.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slava M Katz</author>
</authors>
<title>Estimation of probabilities from sparse data for the language model component of a speech recogniser.</title>
<date>1987</date>
<journal>IEEE Transactions on Acoustic, Speech, and Signal Processing,</journal>
<volume>35</volume>
<issue>3</issue>
<contexts>
<context citStr="Katz, 1987" endWordPosition="1851" position="11056" startWordPosition="1850">target cost − log P(f|u) and the concatenation cost − log P(u) from appropriate training data using general statistical methods. To simplify the problem, we will use the existing target cost provided by the traditional unit selection system and concentrate on the problem of estimating the concatenation cost. We used the unit selection system presented in the previous section to generate a large corpus of more than 8M unit sequences, each unit corresponding to a unique recorded halfphone. This corpus was used to build an n-gram statistical language model using Katz backoff smoothing technique (Katz, 1987). This model provides us with a new cost function, the grammar cost Cg, defined by: Cg(uk|u1...uk−1) = −log(P(uk|u1...uk−1)) where P is the probability distribution estimated by our model. We used this new cost function to replace both the concatenation and context costs used in the traditional approach. Unit selection then consists of finding the unit sequence u such that: n u = argmin (Cf(fi, ui)+Cg(ui|ui−k ... ui−1)) u∈Un i=1 In this approach, rather than using a preselection method such as that of (Conkie et al., 2000), we are using the statistical language model to restrict the candidate </context>
</contexts>
<marker>Katz, 1987</marker>
<rawString>Slava M. Katz. 1987. Estimation of probabilities from sparse data for the language model component of a speech recogniser. IEEE Transactions on Acoustic, Speech, and Signal Processing, 35(3):400–401.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Werner Kuich</author>
<author>Arto Salomaa</author>
</authors>
<date>1986</date>
<journal>Semirings, Automata, Languages. Number</journal>
<booktitle>in EATCS Monographs on Theoretical Computer Science.</booktitle>
<volume>5</volume>
<publisher>Springer-Verlag,</publisher>
<location>Berlin, Germany.</location>
<contexts>
<context citStr="Kuich and Salomaa, 1986" endWordPosition="2358" position="13856" startWordPosition="2355">, and p[n[7r]] the final weight of its destination. A Weighted automaton A = (Σ, Q, I, F, E, λ, p) is defined in a similar way by simply omitting the output (or input) labels. We denote by Π2(T) the λ[p[7r]] + w[7r] + p[n[7r]] Figure 1: (a) Weighted automaton T1. (b) Weighted transducer T2. (c) T1 o T2, the result of the composition of T1 and T2. weighted automaton obtained from T by removing its input labels. A general composition operation similar to the composition of relations can be defined for weighted finite-state transducers (Eilenberg, 1974; Berstel, 1979; Salomaa and Soittola, 1978; Kuich and Salomaa, 1986). The composition of two transducers T1 and T2 is a weighted transducer denoted by T1 o T2 and defined by: [T1 o T2](x, y) = min {[T1](x, z) + [T2](z, y)} z∈Δ∗ There exists a simple algorithm for constructing T = T1 o T2 from T1 and T2 (Pereira and Riley, 1997; Mohri et al., 1996). The states of T are identified as pairs of a state of T1 and a state of T2. A state (q1, q2) in T1oT2 is an initial (final) state if and only if q1 is an initial (resp. final) state of T1 and q2 is an initial (resp. final) state of T2. The transitions of T are the result of matching a transition of T1 and a transiti</context>
</contexts>
<marker>Kuich, Salomaa, 1986</marker>
<rawString>Werner Kuich and Arto Salomaa. 1986. Semirings, Automata, Languages. Number 5 in EATCS Monographs on Theoretical Computer Science. Springer-Verlag, Berlin, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
<author>Fernando C N Pereira</author>
<author>Michael Riley</author>
</authors>
<title>Weighted automata in text and speech processing.</title>
<date>1996</date>
<booktitle>In Proceedings of the 12th European Conference on Artificial Intelligence (ECAI 1996), Workshop on Extended finite state models of language,</booktitle>
<publisher>John Wiley and Sons,</publisher>
<location>Budapest, Hungary.</location>
<contexts>
<context citStr="Mohri et al., 1996" endWordPosition="2415" position="14137" startWordPosition="2412">r T2. (c) T1 o T2, the result of the composition of T1 and T2. weighted automaton obtained from T by removing its input labels. A general composition operation similar to the composition of relations can be defined for weighted finite-state transducers (Eilenberg, 1974; Berstel, 1979; Salomaa and Soittola, 1978; Kuich and Salomaa, 1986). The composition of two transducers T1 and T2 is a weighted transducer denoted by T1 o T2 and defined by: [T1 o T2](x, y) = min {[T1](x, z) + [T2](z, y)} z∈Δ∗ There exists a simple algorithm for constructing T = T1 o T2 from T1 and T2 (Pereira and Riley, 1997; Mohri et al., 1996). The states of T are identified as pairs of a state of T1 and a state of T2. A state (q1, q2) in T1oT2 is an initial (final) state if and only if q1 is an initial (resp. final) state of T1 and q2 is an initial (resp. final) state of T2. The transitions of T are the result of matching a transition of T1 and a transition of T2 as follows: (q1, a, b, w1, qi) and (q2, b, c, w2, q2) produce the transition ((q1,q2),a,c,w1 + w2,(qi,q2)) (4) in T. The efficiency of this algorithm was critical to that of our unit selection system. Thus, we designed an improved composition that we will describe later. </context>
</contexts>
<marker>Mohri, Pereira, Riley, 1996</marker>
<rawString>Mehryar Mohri, Fernando C. N. Pereira, and Michael Riley. 1996. Weighted automata in text and speech processing. In Proceedings of the 12th European Conference on Artificial Intelligence (ECAI 1996), Workshop on Extended finite state models of language, Budapest, Hungary. John Wiley and Sons, Chichester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
<author>Fernando C N Pereira</author>
<author>Michael Riley</author>
</authors>
<title>The Design Principles of a Weighted Finite-State Transducer Library.</title>
<date>2000</date>
<journal>Theoretical Computer Science,</journal>
<volume>231</volume>
<issue>1</issue>
<pages>http://www.research.att.com/sw/tools/fsm.</pages>
<contexts>
<context citStr="Mohri et al., 2000" endWordPosition="1143" position="7028" startWordPosition="1140">ilable for our training corpus, we could exploit that in the initial labeling phase for the design of the unit selection system. (2) Weighted finite-state transducer representation. In addition to the already mentioned synthesis speed and the opportunity of high-quality measures in the initial offline labeling phase, another benefit of this approach is that it leads to a natural representation by weighted transducers, and hence enables us to build a unit selection system using general and flexible representations and methods already in use for speech recognition, e.g., those found in the FSM (Mohri et al., 2000), GRM (Allauzen et al., 2004) and DCD (Allauzen et al., 2003) libraries. Other unit selection systems based on weighted transducers were also proposed in (Yi et al., 2000; Bulyko and Ostendorf, 2001). (3) Unit selection algorithms and speed-up. We present a new unit selection system based on statistical modeling. We used weighted automata and transducers for the representation of the components of the system and designed a new and efficient composition algorithm making use of string potentials for their combination. The resulting statistical unit selection is shown to be about 2.6 times faster</context>
<context citStr="Mohri et al., 2000" endWordPosition="2031" position="12191" startWordPosition="2028">t al., 2000), we are using the statistical language model to restrict the candidate space (see Section 4.2). 3 Representation by Weighted Finite-State Transducers An important advantage of the statistical framework we introduced for unit selection is that the resulting components can be naturally represented by weighted finite-state transducers. This casts unit selection into a familiar schema, that of a Viterbi decoder applied to a weighted transducer. 3.1 Weighted Finite-State Transducers We give a brief introduction to weighted finite-state transducers. We refer the reader to (Mohri, 2004; Mohri et al., 2000) for an extensive presentation of these devices and will use the definitions and notation introduced by these authors. A weightedfinite-state transducer T is an 8-tuple T = (Σ, Δ, Q, I, F, E, λ, p) where Σ is the finite input alphabet of the transducer, Δ is the finite output alphabet, Q is a finite set of states, I C_ Q the set of initial states, F C_ Q the set of final states, E C_ Q x (Σ U {E}) x (Δ U {E}) x R x Q a finite set of transitions, λ : I —* R the initial weight function, and p : F —* R the final weight function mapping F to R. In our statistical framework, the weights can be inte</context>
</contexts>
<marker>Mohri, Pereira, Riley, 2000</marker>
<rawString>Mehryar Mohri, Fernando C. N. Pereira, and Michael Riley. 2000. The Design Principles of a Weighted Finite-State Transducer Library. Theoretical Computer Science, 231(1):17–32. http://www.research.att.com/sw/tools/fsm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
</authors>
<title>Semiring Frameworks and Algorithms for Shortest-Distance Problems.</title>
<date>2002</date>
<journal>Journal of Automata, Languages and Combinatorics,</journal>
<volume>7</volume>
<issue>3</issue>
<contexts>
<context citStr="Mohri, 2002" endWordPosition="3292" position="19061" startWordPosition="3291"> of such states to save computational time. To that end, we introduce the notion of string potential at each state. Let i[π] (o[π]) be the input (resp. output) label of a path π, and denote by x n y the longest common prefix of two strings x and y. Let q be a state in a weighted transducer. The input (output) string potential of q is defined as the longest common prefix of the input (resp. output) labels of all the paths in T from q to a final state: � pi(q) = π∈Π(q,F) � po(q) = π∈Π(q,F) The string potentials of the states of T can be computed using the generic shortest-distance algorithm of (Mohri, 2002) over the string semiring. They can be used in composition in the following way. We will say that two strings x and y are comparable if x is a prefix of y or y is a prefix of x. Let (q1, q2) be a state in T = T1 o T2. Note that (q1, q2) is a coaccessible state only if the output string potential of q1 in T1 and the input string potential of q2 in T2 are comparable, i.e., po(q1) is a prefix of pi(q2) or pi(q2) is a prefix of po(q1). Hence, composition can be modified to create only those states for which the string potentials are compatible. As an example, state 2 = (1, 5) of the transducer T =</context>
</contexts>
<marker>Mohri, 2002</marker>
<rawString>Mehryar Mohri. 2002. Semiring Frameworks and Algorithms for Shortest-Distance Problems. Journal of Automata, Languages and Combinatorics, 7(3):321–350.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
</authors>
<title>Weighted Finite-State Transducer Algorithms: An Overview.</title>
<date>2004</date>
<booktitle>Formal Languages and Applications,</booktitle>
<volume>148</volume>
<pages>p.</pages>
<editor>In Carlos Martin-Vide, Victor Mitrana, and Gheorghe Paun, editors,</editor>
<publisher>Springer,</publisher>
<location>Berlin.</location>
<contexts>
<context citStr="Mohri, 2004" endWordPosition="2027" position="12170" startWordPosition="2026"> of (Conkie et al., 2000), we are using the statistical language model to restrict the candidate space (see Section 4.2). 3 Representation by Weighted Finite-State Transducers An important advantage of the statistical framework we introduced for unit selection is that the resulting components can be naturally represented by weighted finite-state transducers. This casts unit selection into a familiar schema, that of a Viterbi decoder applied to a weighted transducer. 3.1 Weighted Finite-State Transducers We give a brief introduction to weighted finite-state transducers. We refer the reader to (Mohri, 2004; Mohri et al., 2000) for an extensive presentation of these devices and will use the definitions and notation introduced by these authors. A weightedfinite-state transducer T is an 8-tuple T = (Σ, Δ, Q, I, F, E, λ, p) where Σ is the finite input alphabet of the transducer, Δ is the finite output alphabet, Q is a finite set of states, I C_ Q the set of initial states, F C_ Q the set of final states, E C_ Q x (Σ U {E}) x (Δ U {E}) x R x Q a finite set of transitions, λ : I —* R the initial weight function, and p : F —* R the final weight function mapping F to R. In our statistical framework, th</context>
</contexts>
<marker>Mohri, 2004</marker>
<rawString>Mehryar Mohri. 2004. Weighted Finite-State Transducer Algorithms: An Overview. In Carlos Martin-Vide, Victor Mitrana, and Gheorghe Paun, editors, Formal Languages and Applications, volume 148, VIII, 620 p. Springer, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Moulines</author>
<author>Francis Charpentier</author>
</authors>
<title>Pitch-synchronous waveform processing techniques for text-to-speech synthesis using diphones. Speech Communication,</title>
<date>1990</date>
<pages>9--5</pages>
<contexts>
<context citStr="Moulines and Charpentier, 1990" endWordPosition="428" position="2694" startWordPosition="425"> features (e.g., pitch, duration), or prosodic features. ∗ This author’s new address is: Google, Inc, 1440 Broadway, New York, NY 10018, riley@google.com. The second component, unit selection, determines in a set of recorded acoustic units corresponding to phones (Hunt and Black, 1996) or halfphones (Beutnagel et al., 1999a) the sequence of units that is the closest to the sequence of feature vectors predicted by the text analysis frontend. The final component produces an acoustic signal from the unit sequence chosen by unit selection using simple concatenation or other methods such as PSOLA (Moulines and Charpentier, 1990) and HNM (Stylianou et al., 1997). Unit selection is performed by defining two cost functions: the target cost that estimates how the features of a recorded unit match the specified feature vector and the concatenation cost that estimates how well two units will be perceived to match when appended. Unit selection then consists of finding, given a specified sequence of feature vectors, the unit sequence that minimizes the sum of these two costs. The target and concatenation cost functions have traditionally been formed from a variety of heuristic or ad hoc quality measures based on features of </context>
</contexts>
<marker>Moulines, Charpentier, 1990</marker>
<rawString>Eric Moulines and Francis Charpentier. 1990. Pitch-synchronous waveform processing techniques for text-to-speech synthesis using diphones. Speech Communication, 9(5-6):453– 467.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando C N Pereira</author>
<author>Michael D Riley</author>
</authors>
<title>Speech Recognition by Composition of Weighted Finite Automata.</title>
<date>1997</date>
<booktitle>In Finite-State Language Processing,</booktitle>
<pages>431--453</pages>
<publisher>MIT Press.</publisher>
<contexts>
<context citStr="Pereira and Riley, 1997" endWordPosition="2411" position="14116" startWordPosition="2408">1. (b) Weighted transducer T2. (c) T1 o T2, the result of the composition of T1 and T2. weighted automaton obtained from T by removing its input labels. A general composition operation similar to the composition of relations can be defined for weighted finite-state transducers (Eilenberg, 1974; Berstel, 1979; Salomaa and Soittola, 1978; Kuich and Salomaa, 1986). The composition of two transducers T1 and T2 is a weighted transducer denoted by T1 o T2 and defined by: [T1 o T2](x, y) = min {[T1](x, z) + [T2](z, y)} z∈Δ∗ There exists a simple algorithm for constructing T = T1 o T2 from T1 and T2 (Pereira and Riley, 1997; Mohri et al., 1996). The states of T are identified as pairs of a state of T1 and a state of T2. A state (q1, q2) in T1oT2 is an initial (final) state if and only if q1 is an initial (resp. final) state of T1 and q2 is an initial (resp. final) state of T2. The transitions of T are the result of matching a transition of T1 and a transition of T2 as follows: (q1, a, b, w1, qi) and (q2, b, c, w2, q2) produce the transition ((q1,q2),a,c,w1 + w2,(qi,q2)) (4) in T. The efficiency of this algorithm was critical to that of our unit selection system. Thus, we designed an improved composition that we </context>
</contexts>
<marker>Pereira, Riley, 1997</marker>
<rawString>Fernando C. N. Pereira and Michael D. Riley. 1997. Speech Recognition by Composition of Weighted Finite Automata. In Finite-State Language Processing, pages 431–453. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arto Salomaa</author>
<author>Matti Soittola</author>
</authors>
<title>AutomataTheoretic Aspects of Formal Power Series.</title>
<date>1978</date>
<publisher>Springer-Verlag:</publisher>
<location>New York.</location>
<contexts>
<context citStr="Salomaa and Soittola, 1978" endWordPosition="2354" position="13830" startWordPosition="2351">ht of the origin state of 7r, and p[n[7r]] the final weight of its destination. A Weighted automaton A = (Σ, Q, I, F, E, λ, p) is defined in a similar way by simply omitting the output (or input) labels. We denote by Π2(T) the λ[p[7r]] + w[7r] + p[n[7r]] Figure 1: (a) Weighted automaton T1. (b) Weighted transducer T2. (c) T1 o T2, the result of the composition of T1 and T2. weighted automaton obtained from T by removing its input labels. A general composition operation similar to the composition of relations can be defined for weighted finite-state transducers (Eilenberg, 1974; Berstel, 1979; Salomaa and Soittola, 1978; Kuich and Salomaa, 1986). The composition of two transducers T1 and T2 is a weighted transducer denoted by T1 o T2 and defined by: [T1 o T2](x, y) = min {[T1](x, z) + [T2](z, y)} z∈Δ∗ There exists a simple algorithm for constructing T = T1 o T2 from T1 and T2 (Pereira and Riley, 1997; Mohri et al., 1996). The states of T are identified as pairs of a state of T1 and a state of T2. A state (q1, q2) in T1oT2 is an initial (final) state if and only if q1 is an initial (resp. final) state of T1 and q2 is an initial (resp. final) state of T2. The transitions of T are the result of matching a trans</context>
</contexts>
<marker>Salomaa, Soittola, 1978</marker>
<rawString>Arto Salomaa and Matti Soittola. 1978. AutomataTheoretic Aspects of Formal Power Series. Springer-Verlag: New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristie Seymore</author>
<author>Ronald Rosenfeld</author>
</authors>
<title>Scalable backoff language models.</title>
<date>1996</date>
<booktitle>In Proceedings of ICSLP,</booktitle>
<volume>1</volume>
<pages>232--235</pages>
<location>Philadelphia, Pennsylvania.</location>
<contexts>
<context citStr="Seymore and Rosenfeld, 1996" endWordPosition="3962" position="22614" startWordPosition="3958">s2) with input label a, the backoff transitions of a state s2 are inspected if and only if none of the states in S2 has an outgoing transition with input label a. 1This corresponds to the conditional probability P(uIx) = P(x, u)/P(x). 2Note that more generally the vocabulary size of our statistical language models, about 400,000, is quite large compared to the usual word-based models. 4.3 Language Model Transducer – Shrinking A classical algorithm for reducing the size of an n-gram language model is shrinking using the entropy-based method of (Stolcke, 1998) or the weighted difference method (Seymore and Rosenfeld, 1996), both quite similar in practice. In our experiments, we used a modified version of the weighted difference method. Let w be a unit and let h be its conditioning history within the n-gram model. For a given shrink factor γ, the transition corresponding to the n-gram hw is removed from the weighted automaton if: log( Pe(w|h)) − log(αh Pe(w|h')) &lt; γ c(hw) (10) where h' is the backoff sequence associated with h. Thus, a higher-order n-gram hw is pruned when it does not provide a probability estimate significantly different from the corresponding lower-order n-gram sequence h'w. This standard shri</context>
</contexts>
<marker>Seymore, Rosenfeld, 1996</marker>
<rawString>Kristie Seymore and Ronald Rosenfeld. 1996. Scalable backoff language models. In Proceedings of ICSLP, volume 1, pages 232–235, Philadelphia, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>Entropy-based pruning of backoff language models.</title>
<date>1998</date>
<booktitle>In Proc. DARPA Broadcast News Transcription and Understanding Workshop,</booktitle>
<pages>270--274</pages>
<contexts>
<context citStr="Stolcke, 1998" endWordPosition="3952" position="22550" startWordPosition="3951">ng the outgoing transitions of the states in (s1, s2) with input label a, the backoff transitions of a state s2 are inspected if and only if none of the states in S2 has an outgoing transition with input label a. 1This corresponds to the conditional probability P(uIx) = P(x, u)/P(x). 2Note that more generally the vocabulary size of our statistical language models, about 400,000, is quite large compared to the usual word-based models. 4.3 Language Model Transducer – Shrinking A classical algorithm for reducing the size of an n-gram language model is shrinking using the entropy-based method of (Stolcke, 1998) or the weighted difference method (Seymore and Rosenfeld, 1996), both quite similar in practice. In our experiments, we used a modified version of the weighted difference method. Let w be a unit and let h be its conditioning history within the n-gram model. For a given shrink factor γ, the transition corresponding to the n-gram hw is removed from the weighted automaton if: log( Pe(w|h)) − log(αh Pe(w|h')) &lt; γ c(hw) (10) where h' is the backoff sequence associated with h. Thus, a higher-order n-gram hw is pruned when it does not provide a probability estimate significantly different from the c</context>
</contexts>
<marker>Stolcke, 1998</marker>
<rawString>Andreas Stolcke. 1998. Entropy-based pruning of backoff language models. In Proc. DARPA Broadcast News Transcription and Understanding Workshop, pages 270–274.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yannis Stylianou</author>
<author>Thierry Dutoit</author>
<author>Juergen Schroeter</author>
</authors>
<title>Diphone conactenation using a harmonic plus noise model of speech.</title>
<date>1997</date>
<booktitle>In Proceedings ofEurospeech.</booktitle>
<contexts>
<context citStr="Stylianou et al., 1997" endWordPosition="434" position="2727" startWordPosition="431">sodic features. ∗ This author’s new address is: Google, Inc, 1440 Broadway, New York, NY 10018, riley@google.com. The second component, unit selection, determines in a set of recorded acoustic units corresponding to phones (Hunt and Black, 1996) or halfphones (Beutnagel et al., 1999a) the sequence of units that is the closest to the sequence of feature vectors predicted by the text analysis frontend. The final component produces an acoustic signal from the unit sequence chosen by unit selection using simple concatenation or other methods such as PSOLA (Moulines and Charpentier, 1990) and HNM (Stylianou et al., 1997). Unit selection is performed by defining two cost functions: the target cost that estimates how the features of a recorded unit match the specified feature vector and the concatenation cost that estimates how well two units will be perceived to match when appended. Unit selection then consists of finding, given a specified sequence of feature vectors, the unit sequence that minimizes the sum of these two costs. The target and concatenation cost functions have traditionally been formed from a variety of heuristic or ad hoc quality measures based on features of the audio and text. In this paper</context>
</contexts>
<marker>Stylianou, Dutoit, Schroeter, 1997</marker>
<rawString>Yannis Stylianou, Thierry Dutoit, and Juergen Schroeter. 1997. Diphone conactenation using a harmonic plus noise model of speech. In Proceedings ofEurospeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon Yi</author>
<author>James Glass</author>
<author>Lee Hetherington</author>
</authors>
<title>A flexible scalable finite-state transducer architecture for corpus-based concatenative speech synthesis.</title>
<date>2000</date>
<booktitle>In Proceedings of ICSLP,</booktitle>
<volume>3</volume>
<pages>322--325</pages>
<contexts>
<context citStr="Yi et al., 2000" endWordPosition="1171" position="7198" startWordPosition="1168">tation. In addition to the already mentioned synthesis speed and the opportunity of high-quality measures in the initial offline labeling phase, another benefit of this approach is that it leads to a natural representation by weighted transducers, and hence enables us to build a unit selection system using general and flexible representations and methods already in use for speech recognition, e.g., those found in the FSM (Mohri et al., 2000), GRM (Allauzen et al., 2004) and DCD (Allauzen et al., 2003) libraries. Other unit selection systems based on weighted transducers were also proposed in (Yi et al., 2000; Bulyko and Ostendorf, 2001). (3) Unit selection algorithms and speed-up. We present a new unit selection system based on statistical modeling. We used weighted automata and transducers for the representation of the components of the system and designed a new and efficient composition algorithm making use of string potentials for their combination. The resulting statistical unit selection is shown to be about 2.6 times faster than the last release of the AT&amp;T Natural Voices Product while preserving the same quality, and offers much flexibility for the use and integration of new and more compl</context>
</contexts>
<marker>Yi, Glass, Hetherington, 2000</marker>
<rawString>Jon Yi, James Glass, and Lee Hetherington. 2000. A flexible scalable finite-state transducer architecture for corpus-based concatenative speech synthesis. In Proceedings of ICSLP, volume 3, pages 322–325.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>