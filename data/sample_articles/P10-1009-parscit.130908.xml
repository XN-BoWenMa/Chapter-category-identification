<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant confidence="0.000107" no="0">
<title confidence="0.9587675">
A Risk Minimization Framework for Extractive
Speech Summarization
</title>
<author confidence="0.992219">
Shih-Hsiang Lin and Berlin Chen
</author>
<affiliation confidence="0.836422">
National Taiwan Normal University
Taipei, Taiwan
</affiliation>
<email confidence="0.996541">
{shlin, berlin}@csie.ntnu.edu.tw
</email>
<sectionHeader confidence="0.994684" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999901">In this paper, we formulate extractive summarization as a risk minimization problem and propose a unified probabilistic framework that naturally combines supervised and unsupervised summarization models to inherit their individual merits as well as to overcome their inherent limitations. In addition, the introduction of various loss functions also provides the summarization framework with a flexible but systematic way to render the redundancy and coherence relationships among sentences and between sentences and the whole document, respectively. Experiments on speech summarization show that the methods deduced from our framework are very competitive with existing summarization approaches.</bodyText>
<sectionHeader confidence="0.998784" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99985940909091">Automated summarization systems which enable user to quickly digest the important information conveyed by either a single or a cluster of documents are indispensible for managing the rapidly growing amount of textual information and multimedia content (Mani and Maybury, 1999). On the other hand, due to the maturity of text summarization, the research paradigm has been extended to speech summarization over the years (Furui et al., 2004; McKeown et al., 2005). Speech summarization is expected to distill important information and remove redundant and incorrect information caused by recognition errors from spoken documents, enabling user to efficiently review spoken documents and understand the associated topics quickly. It would also be useful for improving the efficiency of a number of potential applications like retrieval and mining of large volumes of spoken documents. A summary can be either abstractive or extractive. In abstractive summarization, a fluent and concise abstract that reflects the key concepts of a document is generated, whereas in extractive summarization, the summary is usually formed by selecting salient sentences from the original document (Mani and Maybury, 1999). The former requires highly sophisticated natural language processing techniques, including semantic representation and inference, as well as natural language generation, while this would make abstractive approaches difficult to replicate or extend from constrained domains to more general domains. In addition to being extractive or abstractive, a summary may also be generated by considering several other aspects like being generic or query-oriented summarization, singledocument or multi-document summarization, and so forth. The readers may refer to (Mani and Maybury, 1999) for a comprehensive overview of automatic text summarization. In this paper, we focus exclusively on generic, singledocument extractive summarization which forms the building block for many other summarization tasks. Aside from traditional ad-hoc extractive summarization methods (Mani and Maybury, 1999), machine-learning approaches with either supervised or unsupervised learning strategies have gained much attention and been applied with empirical success to many summarization tasks (Kupiec et al., 1999; Lin et al., 2009). For supervised learning strategies, the summarization task is usually cast as a two-class (summary and nonsummary) sentence-classification problem: A sentence with a set of indicative features is input to the classifier (or summarizer) and a decision is then returned from it on the basis of these features. In general, they usually require a training set, comprised of several documents and their corresponding handcrafted summaries (or labeled data), to train the classifiers. However, manual labeling is expensive in terms of time and personnel. The other potential problem is the socalled “bag-of-sentences” assumption implicitly made by most of these summarizers. That is, sentences are classified independently of each other, without leveraging the dependence relationships among the sentences or the global structure of the document (Shen et al., 2007).</bodyText>
<page confidence="0.985661">
79
</page>
<note confidence="0.9431875">
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 79–87,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999969282608696">Another line of thought attempts to conduct document summarization using unsupervised machine-learning approaches, getting around the need for manually labeled training data. Most previous studies conducted along this line have their roots in the concept of sentence centrality (Gong and Liu, 2001; Erkan and Radev, 2004; Radev et al., 2004; Mihalcea and Tarau, 2005). Put simply, sentences more similar to others are deemed more salient to the main theme of the document; such sentences thus will be selected as part of the summary. Even though the performance of unsupervised summarizers is usually worse than that of supervised summarizers, their domain-independent and easy-to-implement properties still make them attractive. Building on these observations, we expect that researches conducted along the above-mentioned two directions could complement each other, and it might be possible to inherit their individual merits to overcome their inherent limitations. In this paper, we present a probabilistic summarization framework stemming from Bayes decision theory (Berger, 1985) for speech summarization. This framework can not only naturally integrate the above-mentioned two modeling paradigms but also provide a flexible yet systematic way to render the redundancy and coherence relationships among sentences and between sentences and the whole document, respectively. Moreover, we also illustrate how the proposed framework can unify several existing summarization models. The remainder of this paper is structured as follows. We start by reviewing related work on extractive summarization. In Section 3 we formulate the extractive summarization task as a risk minimization problem, followed by a detailed elucidation of the proposed methods in Section 4. Then, the experimental setup and a series of experiments and associated discussions are presented in Sections 5 and 6, respectively. Finally, Section 7 concludes our presentation and discusses avenues for future work.</bodyText>
<sectionHeader confidence="0.983829" genericHeader="related work">
2 Background
</sectionHeader>
<bodyText confidence="0.999728142857143">Speech summarization can be conducted using either supervised or unsupervised methods (Furui et al., 2004, McKeown et al., 2005, Lin et al., 2008). In the following, we briefly review a few celebrated methods that have been applied to extractive speech summarization tasks with good success.</bodyText>
<subsectionHeader confidence="0.995944">
2.1 Supervised summarizers
</subsectionHeader>
<bodyText confidence="0.999938953488372">Extractive speech summarization can be treated as a two-class (positive/negative) classification problem. A spoken sentence Si is characterized by set of T indicative features Xi  xi 1 , , x iT  , and they may include lexical features (Koumpis and Renals, 2000), structural features (Maskey and Hirschberg, 2003), acoustic features (Inoue et al., 2004), discourse features (Zhang et al., 2007) and relevance features (Lin et al., 2009). Then, the corresponding feature vector Xi of Si is taken as the input to the classifier. If the output (classification) score belongs to the positive class, Si will be selected as part of the summary; otherwise, it will be excluded (Kupiec et al., 1999). Specifically, the problem can be formulated as follows: Construct a sentence ranking model that assigns a classification score (or a posterior probability) of being in the summary class to each sentence of a spoken document to be summarized; important sentences are subsequently ranked and selected according to these scores. To this end, several popular machine-learning methods could be utilized, like Bayesian classifier (BC) (Kupiec et al., 1999), Gaussian mixture model (GMM) (Fattah and Ren, 2009) , hidden Markov model (HMM) (Conroy and O'leary, 2001), support vector machine (SVM) (Kolcz et al., 2001), maximum entropy (ME) (Ferrier, 2001), conditional random field (CRF) (Galley, 2006; Shen et al., 2007), to name a few. Although such supervised summarizers are effective, most of them (except CRF) usually implicitly assume that sentences are independent of each other (the so-called “bag-of-sentences” assumption) and classify each sentence individually without leveraging the relationship among the sentences (Shen et al., 2007). Another major shortcoming of these summarizers is that a set of handcrafted document-reference summary exemplars are required for training the summarizers; however, such summarizers tend to limit their generalization capability and might not be readily applicable for new tasks or domains.</bodyText>
<subsectionHeader confidence="0.999312">
2.2 Unsupervised summarizers
</subsectionHeader>
<bodyText confidence="0.9999338">The related work conducted along this direction usually relies on some heuristic rules or statistical evidences between each sentence and the document, avoiding the need of manually labeled training data. For example, the vector space model (VSM) approach represents each sentence of a document and the document itself in vector space (Gong and Liu, 2001), and computes the relevance score between each sentence and the document (e.g., the cosine measure of the similarity between two vectors).</bodyText>
<page confidence="0.994375">
80
</page>
<bodyText confidence="0.999985892857143">Then, the sentences with the highest relevance scores are included in the summary. A natural extension is to represent each document or each sentence vector in a latent semantic space (Gong and Liu, 2001), instead of simply using the literal term information as that done by VSM. On the other hand, the graph-based methods, such as TextRank (Mihalcea and Tarau, 2005) and LexRank (Erkan and Radev, 2004), conceptualize the document to be summarized as a network of sentences, where each node represents a sentence and the associated weight of each link represents the lexical or topical similarity relationship between a pair of nodes. Document summarization thus relies on the global structural information conveyed by such conceptualized network, rather than merely considering the local features of each node (sentence). However, due to the lack of documentsummary reference pairs, the performance of the unsupervised summarizers is usually worse than that of the supervised summarizers. Moreover, most of the unsupervised summarizers are constructed solely on the basis of the lexical information without considering other sources of information cues like discourse features, acoustic features, and so forth.</bodyText>
<sectionHeader confidence="0.86793" genericHeader="method">
3 A risk minimization framework for
extractive summarization
</sectionHeader>
<bodyText confidence="0.999530409090909">Extractive summarization can be viewed as a decision making process in which the summarizer attempts to select a representative subset of sentences or paragraphs from the original documents. Among the several analytical methods that can be employed for the decision process, the Bayes decision theory, which quantifies the tradeoff between various decisions and the potential cost that accompanies each decision, is perhaps the most suited one that can be used to guide the summarizer in choosing a course of action in the face of some uncertainties underlying the decision process (Berger, 1985). Stated formally, a decision problem may consist of four basic elements: 1) an observation O from a random variable O , 2) a set of possible decisions (or actions) a  Α , 3) the state of nature   Θ , and 4) a loss function Lai ,  which specifies the cost associated with a chosen decision ai given that  is the true state of nature. The expected risk (or conditional risk) associated with taking decision ai is given by where p O |O is the posterior probability of the state of nature being  given the observation O. Bayes decision theory states that the optimum decision can be made by contemplating each action ai , and then choosing the action for which the expected risk is minimum:</bodyText>
<equation confidence="0.953934">
Rai|O OLai, OpO|OdO, (1)
</equation>
<equation confidence="0.933282333333333">
a* arg min R  a i  |O .

ai
</equation>
<bodyText confidence="0.999981884615385">The notion of minimizing the Bayes risk has gained much attention and been applied with success to many natural language processing (NLP) tasks, such as automatic speech recognition (Goel and Byrne, 2000), statistical machine translation (Kumar and Byrne, 2004) and statistical information retrieval (Zhai and Lafferty, 2006). Following the same spirit, we formulate the extractive summarization task as a Bayes risk minimization problem. Without loss of generality, let us denote   Π as one of possible selection strategies (or state of nature) which comprises a set of indicators used to address the importance of each sentence Si in a document D to be summarized. A feasible selection strategy can be fairly arbitrary according to the underlying principle. For example, it could be a set of binary indicators denoting whether a sentence should be selected as part of summary or not. On the contrary, it may also be a ranked list used to address the significance of each individual sentence. Moreover, we refer to the k -th action ak as choosing the k -th selection strategy k , and the observation O as the document D to be summarized. As a result, the expected risk of a certain selection strategy k is given by</bodyText>
<equation confidence="0.9972445">
R  k D  L  k  p  D d
  |  ,    | . (3)
</equation>
<bodyText confidence="0.9999606">Consequently, the ultimate goal of extractive summarization could be stated as the search of the best selection strategy from the space of all possible selection strategies that minimizes the expected risk defined as follows:</bodyText>
<equation confidence="0.986868428571429">
k  |D
k
L ,    | .
  
p D d 
k
k
</equation>
<bodyText confidence="0.9999796">Although we have described a general formulation for the extractive summarization problem on the grounds of the Bayes decision theory, we consider hereafter a special case of it where the selection strategy is represented by a binary decision vector, of which each element corresponds to a specific sentence Si in the document D and designates whether it should be selected as part of the summary or not, as the first such attempt. More concretely, we assume that the summary sentences of a given document can be iteratively chosen (i.e., one at each iteration) from the document until the aggregated summary reaches a predefined target summarization ratio.</bodyText>
<figure confidence="0.626550833333333">
(2)
R
* 
arg min
 arg min 
(4)
</figure>
<page confidence="0.981818">
81
</page>
<bodyText confidence="0.999820181818182">It turns out that the binary vector for each possible action will have just one element equal to 1 and all others equal to zero (or the so-called “one-of-n” coding). For ease of notation, we denote the binary vector by Si when the i -th element has a value of 1. Therefore, the risk minimization framework can be reduced to denotes the remaining sentences that have not been selected into the summary yet (i.e., the “residual” document); P  S j D ~  |is the posterior probability of a sentence Sj given D~ .According,</bodyText>
<equation confidence="0.890724">
S&amp;quot;  arg min R
~
~
</equation>
<equation confidence="0.7537234">
c-
cordin to th Bayes’ rule, we can further ex-
press PSj  |b� as (Chen et al., 2009)
PS  |DPD  |SjPSj  ~  ,(6)
P D
</equation>
<bodyText confidence="0.9997364">where PD  |Sj  ~ is the sentence generative probability, i.e., the likelihood of D ~ being generated by Sj ; PSj  is the prior probability of Sj being important; and the evidence P  ~ D is the marginal probability of D~ , which can be approximated by</bodyText>
<equation confidence="0.975822">
PD AD|SmPSJ (7)
Sm D
</equation>
<bodyText confidence="0.966959">By substituting (6) and (7) into (5), we obtain the following final selection strategy for extractive summarization: A remarkable feature of this framework lies in that a sentence to be considered as part of the summary is actually evaluated by three different fundamental factors: (1) PSj  is the sentence prior probability that addresses the importance of sentence Sj itself; (2) P  D |Sj  ~ is the sentence generative probability that captures the degree of relevance of Sj to the residual document D; and (3) LSi,Sj is the loss function that characterizes the relationship between sentence Si and any other sentence Sj . As we will soon see, such a framework can be regarded as a generalization of several existing summarization methods. A detailed account on the construction of these three component models in the framework will be given in the following section.</bodyText>
<sectionHeader confidence="0.999097" genericHeader="method">
4 Proposed Methods
</sectionHeader>
<bodyText confidence="0.997895375">There are many ways to construct the above mentioned three component models, i.e., the sentence generative model PD  |Sj  ~ , the sentence prior model PSj  , and the loss function LSi , Sj . In what follows, we will shed light on one possible attempt that can accomplish this goal elegantly.</bodyText>
<subsectionHeader confidence="0.99745">
4.1 Sentence generative model
</subsectionHeader>
<bodyText confidence="0.998798">In order to estimate the sentence generative probability, we explore the language modeling (LM) approach, which has been introduced to a wide spectrum of IR tasks and demonstrated with good empirical success, to predict the sentence generative probability. In the LM approach, each sentence in a document can be simply regarded as a probabilistic generative model consisting of a unigram distribution (the so-called “bag-ofwords” assumption) for generating the document (Chen et al., 2009):</bodyText>
<equation confidence="0.965758333333333">
PO Sj  ~ Pw Sj Yw`,
w D

</equation>
<bodyText confidence="0.973696">where cw ~ D , is the number of times that index term (or word) w occurs in D ~ , reflecting that w</bodyText>
<equation confidence="0.5248635">
Sj
.
</equation>
<bodyText confidence="0.999700294117647">Note that the sentence model Pw Sj is simply estimated on the basis of the frequency of index term w occurring in the sentence Sj with the maximum likelihood (ML) criterion. In a sense, (9) belongs to a kind of literal term matching strategy (Chen, 2009) and may suffer the problem of unreliable model estimation owing particularly to only a few sampled index terms present in the sentence (Zhai, 2008). To mitigate this potential defect, a unigram probability estimated from a general collection, which models the general distribution of words in the target language, is often used to smooth the sentence model. Interested readers may refer to (Zhai, 2008; Chen et al., 2009) for a thorough discussion on various ways to construct the sentence generative model.</bodyText>
<subsectionHeader confidence="0.991171">
4.2 Sentence prior model
</subsectionHeader>
<bodyText confidence="0.999982636363636">The sentence prior probability PSj  can be regarded as the likelihood of a sentence being important without seeing the whole document. It could be assumed uniformly distributed over sentences or estimated from a wide variety of factors, such as the lexical information, the structural information or the inherent prosodic properties of a spoken sentence. A straightforward way is to assume that the sentence prior probability PSj  is in proportion to the posterior probability of a sentence Sj being included in the summary class when observing a set of indicative features Xj of Sj derived from such factors or other sentence importance measures (Kupiec et al., 1999).</bodyText>
<figure confidence="0.98701624">
S D
i
arg min LSi,Sj+j |5,
~ ~
S D
j

S D
i
(5)
S PS j 
S&amp;quot;  argmin  LS„ Sj ~ D .
~P (8)
D
SiD Sj � Sm kSm )
~
S D
m
eD
Si |b
where D
(9)
will contribute more in the calculation of
PD
if it occurs more frequently in D
</figure>
<page confidence="0.988993">
82
</page>
<bodyText confidence="0.998798222222222">These features can be integrated in a systematic way into the proposed framework by taking the advantage of the learning capability of the supervised machine-learning methods. Specifically, the prior probability P Sj  can be approximated by:</bodyText>
<equation confidence="0.982625">
PSj P j|SSS+S X  |SP S, j (10)
</equation>
<bodyText confidence="0.999665">where PXj  |S and PXj  |S  are the likelihoods that a sentence Sj with features Xj are generated by the summary class S and the nonsummary class S , respectively; the prior probability PS and P  S  are set to be equal in this research. To estimate PX .  |S and PXj  |S  , several popular supervised classifiers (or summarizers), like BC or SVM, can be leveraged for this purpose.</bodyText>
<subsectionHeader confidence="0.99586">
4.3 Loss function
</subsectionHeader>
<bodyText confidence="0.983558918918919">The loss function introduced in the proposed summarization framework is to measure the relationship between any pair of sentences. Intuitively, when a given sentence is more dissimilar from most of the other sentences, it may incur higher loss as it is taken as the representative sentence (or summary sentence) to represent the main theme embedded in the other ones. Consequently, the loss function can be built on the notion of the similarity measure. In this research, we adopt the cosine measure (Gong and Liu, 2001) to fulfill this goal. We first represent each sentence Si in vector form where each dimension specifies the weighted statistic zt,i , e.g., the product of the term frequency (TF) and inverse document frequency (IDF) scores, associated with an index term wt in sentence Si . Then, the cosine similarity between any given two sentences Si , Sj is The loss function is thus defined by LSi, Sj1 SimSi, S j. (11) Once the sentence generative model PD  |Sj  ~ , the sentence prior model PSj  and the loss function LSi, Sj have been properly estimated, the summary sentences can be selected iteratively by (8) according to a predefined target summarization ratio. However, as can be seen from (8), a new summary sentence is selected without considering the redundant information that is also contained in the already selected summary sentences. To alleviate this problem, the concept of maximum marginal relevance (MMR) (Carbonell and Goldstein, 1998), which performs sentence selection iteratively by striking the balance between topic relevance and coverage, can be incorporated into the loss function:</bodyText>
<equation confidence="0.992851363636364">
  SimSi , Sj 
L S S
 
,  
1 
i j     ,

  
 1  Sim S S
max i, ' 
 S'  Summ 
</equation>
<bodyText confidence="0.999934">where Summ represents the set of sentences that have already been included into the summary and the novelty factor  is used to trade off between relevance and redundancy.</bodyText>
<subsectionHeader confidence="0.993419">
4.4 Relation to other summarization models
</subsectionHeader>
<bodyText confidence="0.999714375">In this subsection, we briefly illustrate the relationship between our proposed summarization framework and a few existing summarization approaches. We start by considering a special case where a 0-1 loss function is used in (8), namely, the loss function will take value 0 if the two sentences are identical, and 1 otherwise. Then, (8) can be alternatively represented by which actually provides a natural integration of the supervised and unsupervised summarizers (Lin et al., 2009), as mentioned previously.</bodyText>
<equation confidence="0.999375">
P D S P S
   
~  |j j
PD  |Sm)Sm 
S D
m
 ~ PP  |SmPSm 
S D
m 
</equation>
<bodyText confidence="0.985951333333333">If we further assume the prior probability PSj  is uniformly distributed, the important (or summary) sentence selection problem has now been reduced to the problem of measuring the document-likelihood PD |Sj  ~ , or the relevance between the document and the sentence. Alone a similar vein, the important sentences of a document can be selected (or ranked) solely based on the prior probability PSj  with the assumption of an equal document-likelihood P  D |Sj ~ .</bodyText>
<sectionHeader confidence="0.866876" genericHeader="evaluation">
5 Experimental setup
5.1 Data
</sectionHeader>
<bodyText confidence="0.999944">The summarization dataset used in this research is a widely used broadcast news corpus collected by the Academia Sinica and the Public Television Service Foundation of Taiwan between November 2001 and April 2003 (Wang et al., 2005). Each story contains the speech of one studio anchor, as well as several field reporters and interviewees. A subset of 205 broadcast news documents compiled between November 2001 and August 2002 was reserved for the summarization experiments.</bodyText>
<equation confidence="0.996417923076923">
 
T
t t i t j
 1 ,
z z ,
Sim S S
 ,  
i j
. (10)
T

T 2
 t1zt,j
</equation>
<page confidence="0.440494">
2
</page>
<figure confidence="0.950823941176471">
t1 zt,i
(12)
S
* 
~ 
min
arg
~
S D
i
Sj D,Sj Si
 arg max
~
S D
i
�D  |Si kSi 
(13)
</figure>
<page confidence="0.821006">
83
</page>
<table confidence="0.425858">
Kappa ROGUE-1 ROUGE-2 ROUGE-L
0.400 0.600 0.532 0.527
</table>
<tableCaption confidence="0.88832">
Table 1: The agreement among the subjects for impor-
tant sentence ranking for the evaluation set.
</tableCaption>
<figureCaption confidence="0.6996678">
Structural 1.Duration of the current sentence
features 2.Position of the current sentence
3.Length of the current sentence
Lexical 1.Number of named entities
Features 2.Number of stop words
</figureCaption>
<table confidence="0.947407111111111">
3.Bigram language model scores
4.Normalized bigram scores
Acoustic 1.The 1st formant
Features 2.The 2nd formant
3.The pitch value
4.The peak normalized cross-
correlation of pitch
Relevance 1.VSM score
Feature
</table>
<tableCaption confidence="0.999564">
Table 2: Basic sentence features used by BC.
</tableCaption>
<bodyText confidence="0.999988958333333">Three subjects were asked to create summaries of the 205 spoken documents for the summarization experiments as references (the gold standard) for evaluation. The summaries were generated by ranking the sentences in the reference transcript of a spoken document by importance without assigning a score to each sentence. The average Chinese character error rate (CER) obtained for the 205 spoken documents was about 35%. Since broadcast news stories often follow a relatively regular structure as compared to other speech materials like conversations, the positional information would play an important (dominant) role in extractive summarization of broadcast news stories; we, hence, chose 20 documents for which the generation of reference summaries is less correlated with the positional information (or the position of sentences) as the held-out test set to evaluate the general performance of the proposed summarization framework, and 100 documents as the development set.</bodyText>
<subsectionHeader confidence="0.998635">
5.2 Performance evaluation
</subsectionHeader>
<bodyText confidence="0.999945882352941">For the assessment of summarization performance, we adopted the widely used ROUGE measure (Lin, 2004) because of its higher correlation with human judgments. It evaluates the quality of the summarization by counting the number of overlapping units, such as N-grams, longest common subsequences or skip-bigram, between the automatic summary and a set of reference summaries. Three variants of the ROGUE measure were used to quantify the utility of the proposed method. They are, respectively, the ROUGE-1 (unigram) measure, the ROUGE-2 (bigram) measure and the ROUGE-L (longest common subsequence) measure (Lin, 2004). The summarization ratio, defined as the ratio of the number of words in the automatic (or manual) summary to that in the reference transcript of a spoken document, was set to 10% in this research. Since increasing the summary length tends to increase the chance of getting higher scores in the recall rate of the various ROUGE measures and might not always select the right number of informative words in the automatic summary as compared to the reference summary, all the experimental results reported hereafter are obtained by calculating the F-scores of these ROUGE measures, respectively (Lin, 2004). Table 1 shows the levels of agreement (the Kappa statistic and ROUGE measures) between the three subjects for important sentence ranking. They seem to reflect the fact that people may not always agree with each other in selecting the important sentences for representing a given document.</bodyText>
<subsectionHeader confidence="0.80671">
5.3 Features for supervised summarizers
</subsectionHeader>
<bodyText confidence="0.9999616">We take BC as the representative supervised summarizer to study in this paper. The input to BC consists of a set of 28 indicative features used to characterize a spoken sentence, including the structural features, the lexical features, the acoustic features and the relevance feature. For each kind of acoustic features, the minimum, maximum, mean, difference value and mean difference value of a spoken sentence are extracted. The difference value is defined as the difference between the minimum and maximum values of the spoken sentence, while the mean difference value is defined as the mean difference between a sentence and its previous sentence. Finally, the relevance feature (VSM score) is use to measure the degree of relevance for a sentence to the whole document (Gong and Liu, 2001). These features are outlined in Table 2, where each of them was further normalized to zero mean and unit variance.</bodyText>
<sectionHeader confidence="0.841317" genericHeader="result">
6 Experimental results and discussions
</sectionHeader>
<subsectionHeader confidence="0.922216">
6.1 Baseline experiments
</subsectionHeader>
<bodyText confidence="0.999982">In the first set of experiments, we evaluate the baseline performance of the LM and BC summarizers (cf. Sections 4.1 and 4.2), respectively. The corresponding results are detailed in Table 3, where the values in the parentheses are the associated 95% confidence intervals.</bodyText>
<page confidence="0.997947">
84
</page>
<table confidence="0.996231428571429">
Text Document (TD) Spoken Document (SD)
ROGUE-1 ROUGE-2 ROUGE-L ROGUE-1 ROUGE-2 ROUGE-L
BC 0.445 0.346 0.404 0.369 0.241 0.321
(0.390 - 0.504) (0.201 - 0.415) (0.348 - 0.468) (0.316 - 0.426) (0.183 - 0.302) (0.268 - 0.378)
LM 0.387 0.264 0.334 0.319 0.164 0.253
(0.302 - 0.474) (0.168 - 0.366) (0.251 - 0.415) (0.274 - 0.367) (0.115 - 0.224) (0.215 - 0.301)
Table 3: The results achieved by the BC and LM summarizers, respectively.
Text Document (TD) Spoken Document (SD)
Prior Loss ROGUE-1 ROUGE-2 ROUGE-L ROGUE-1 ROUGE-2 ROUGE-L
BC 0-1 0.501 0.401 0.459 0.417 0.281 0.356
SIM 0.524 0.425 0.473 0.475 0.351 0.420
MMR 0.529 0.426 0.479 0.475 0.351 0.420
Uniform SIM 0.405 0.281 0.348 0.365 0.209 0.305
MMR 0.417 0.282 0.359 0.391 0.236 0.338
</table>
<tableCaption confidence="0.999873">
Table 4: The results achieved by several methods derived from the proposed summarization framework.
</tableCaption>
<bodyText confidence="0.999992321428572">It is also worth mentioning that TD denotes the summarization results obtained based on manual transcripts of the spoken documents while SD denotes the results using the speech recognition transcripts which may contain speech recognition errors and sentence boundary detection errors. In this research, sentence boundaries were determined by speech pauses. For the TD case, the acoustic features were obtained by aligning the manual transcripts to their spoken documents counterpart by performing word-level forced alignment. Furthermore, the ROGUE measures, in essence, are evaluated by counting the number of overlapping units between the automatic summary and the reference summary; the corresponding evaluation results, therefore, would be severely affected by speech recognition errors when applying the various ROUGE measures to quantify the performance of speech summarization. In order to get rid of the cofounding effect of this factor, it is assumed that the selected summary sentences can also be presented in speech form (besides text form) such that users can directly listen to the audio segments of the summary sentences to bypass the problem caused by speech recognition errors. Consequently, we can align the ASR transcripts of the summary sentences to their respective audio segments to obtain the correct (manual) transcripts for the summarization performance evaluation (i.e., for the SD case). Observing Table 3 we notice two particularities. First, there are significant performance gaps between summarization using the manual transcripts and the erroneous speech recognition transcripts. The relative performance degradations are about 15%, 34% and 23%, respectively, for ROUGE-1, ROUGE2 and ROUGE-L measures. One possible explanation is that the erroneous speech recognition transcripts of spoken sentences would probably carry wrong information and thus deviate somewhat from representing the true theme of the spoken document. Second, the supervised summarizer (i.e., BC) outperforms the unsupervised summarizer (i.e., LM). The better performance of BC can be further explained by two reasons. One is that BC is trained with the handcrafted document-summary sentence labels in the development set while LM is instead conducted in a purely unsupervised manner. Another is that BC utilizes a rich set of features to characterize a given spoken sentence while LM is constructed solely on the basis of the lexical (unigram) information.</bodyText>
<subsectionHeader confidence="0.996465">
6.2 Experiments on the proposed methods
</subsectionHeader>
<bodyText confidence="0.9999950625">We then turn our attention to investigate the utility of several methods deduced from our proposed summarization framework. We first consider the case when a 0-1 loss function is used (cf. (13)), which just show a simple combination of BC and LM. As can be seen from the first row of Table 4, such a combination can give about 4% to 5% absolute improvements as compared to the results of BC illustrated in Table 3. It in some sense confirms the feasibility of combining the supervised and unsupervised summarizers. Moreover, we consider the use of the loss functions defined in (11) (denoted by SIM) and (12) (denoted by MMR), and the corresponding results are shown in the second and the third rows of Table 4, respectively. It can be found that</bodyText>
<page confidence="0.999187">
85
</page>
<bodyText confidence="0.999967157894737">MMR delivers higher summarization performance than SIM (especially for the SD case), which in turn verifies the merit of incorporating the MMR concept into the proposed framework for extractive summarization. If we further compare the results achieved by MMR with those of BC and LM as shown in Table 3, we can find significant improvements both for the TD and SD cases. By and large, for the TD case, the proposed summarization method offers relative performance improvements of about 19%, 23% and 19%, respectively, in the ROUGE-1, ROUGE-2 and ROUGE-L measures as compared to the BC baseline; while the relative improvements are 29%, 46% and 31%, respectively, in the same measurements for the SD case. On the other hand, the performance gap between the TD and SD cases are reduced to a good extent by using the proposed summarization framework. In the next set of experiments, we simpl assume the sentence prior probability PS j � defined in (8) is uniformly distributed, namely, we do not use any supervised information cue but use the lexical information only. The importance of a given sentence is thus considered from two angles: 1) the relationship between a sentence and the whole document, and 2) the relationship between the sentence and the other individual sentences. The corresponding results are illustrated in the lower part of Table 4 (denoted by Uniform). We can see that the additional consideration of the sentence-sentence relationship appears to be beneficial as compared to that only considering the document-sentence relevance information (cf. the second row of Table 3). It also gives competitive results as compared to the performance of BC (cf. the first row of Table 3) for the SD case.</bodyText>
<subsectionHeader confidence="0.9816255">
6.3 Comparison with conventional summa-
rization methods
</subsectionHeader>
<bodyText confidence="0.9999613125">In the final set of experiments, we compare our proposed summarization methods with a few existing summarization methods that have been widely used in various summarization tasks, including LEAD, VSM, LexRank and CRF; the corresponding results are shown in Table 5. It should be noted that the LEAD-based method simply extracts the first few sentences in a document as the summary. To our surprise, CRF does not provide superior results as compared to the other summarization methods. One possible explanation is that the structural evidence of the spoken documents in the test set is not strong enough for CRF to show its advantage of modeling the local structural information among sentences. On the other hand, LexRank gives a very promising performance in spite that it only utilizes lexical information in an unsupervised manner.</bodyText>
<table confidence="0.99934175">
ROGUE-1 ROUGE-2 ROUGE-L
LEAD TD 0.320 0.197 0.283
SD
0.312 0.168 0.251
VSM TD 0.345 0.220 0.287
SD
0.337 0.189 0.277
LexRank TD 0.435 0.314 0.377
SD
0.348 0.204 0.294
CRF TD 0.431 0.315 0.383
SD 0.358 0.220 0.291
</table>
<tableCaption confidence="0.998266">
Table 5: The results achieved by four conventional
summarization methods.
</tableCaption>
<bodyText confidence="0.9984977">This somewhat reflects the importance of capturing the global relationship for the sentences in the spoken document to be summarized. As compared to the results shown in the “BC” part of Table 4, we can see that our proposed methods significantly outperform all the conventional summarization methods compared in this paper, especially for the SD case.</bodyText>
<sectionHeader confidence="0.988558" genericHeader="conclusion">
7 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.9999518">We have proposed a risk minimization framework for extractive speech summarization, which enjoys several advantages. We have also presented a simple yet effective implementation that selects the summary sentences in an iterative manner. Experimental results demonstrate that the methods deduced from such a framework can yield substantial improvements over several popular summarization methods compared in this paper. We list below some possible future extensions: 1) integrating different selection strategies, e.g., the listwise strategy that defines the loss function on all the sentences associated with a document to be summarized, into this framework, 2) exploring different modeling approaches for this framework, 3) investigating discriminative training criteria for training the component models in this framework, and 4) extending and applying the proposed framework to multidocument summarization tasks.</bodyText>
<sectionHeader confidence="0.997877" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9968567">
James O. Berger Statistical decision theory and
Bayesian analysis. Springer-Verlap, 1985.
Berlin Chen. 2009. Word topic models for spoken
document retrieval and transcription. ACM
Transactions on Asian Language Information
Processing, 8, (1): 2:1 - 2:27.
Jaime Carbonell and Jade Goldstein. 1998. The use of
mmr, diversity-based reranking for reordering
documents and producing summaries. In Proc. of
Annual International ACM SIGIR Conference on
</reference>
<page confidence="0.971156">
86
</page>
<reference confidence="0.999135349206349">
Research and Development in Information
Retrieval: 335 - 336.
Yi-Ting Chen, Berlin Chen and Hsin-Min Wang.
2009. A probabilistic generative framework for
extractive broadcast news speech summarization.
IEEE Transactions on Audio, Speech and
Language Processing, 17, (1): 95 - 106.
John M. Conroy and Dianne P. O’Leary. 2001. Text
summarization via hidden Markov models. In
Proc. of Annual International ACM SIGIR
Conference on Research and Development in
Information Retrieval: 406 - 407.
Güneş Erkan and Dragomir R. Radev. 2004. LexRank:
graph-based lexical centrality as salience in text
summarization. Journal or Artificial Intelligence
Research, 22: 457 - 479.
Mohamed Abdel Fattah and Fuji Ren. 2009. GA, MR,
FFNN, PNN and GMM based models for
automatic text summarization. Computer Speech
and Language, 23, (1): 126 - 144.
Louisa Ferrier A maximum entropy approach to text
summarization. School of Artificial Intelligence,
University of Edinburgh, 2001.
Sadaoki Furui, Tomonori Kikuchi, Yousuke Shinnaka
and Chiori Hori. 2004. Speech-to-text and speech-
to-speech summarization of spontaneous speech.
IEEE Transactions on Speech and Audio
Processing, 12, (4): 401 - 408.
Michel Galley. 2006. A skip-chain conditional
random field for ranking meeting utterances by
importance. In Proc. of Conference on Empirical
Methods in Natural Language Processing: 364 -
372.
Vaibhava Goel and William Byrne. 2000. Minimum
Bayes-risk automatic speech recognition.
Computer Speech and Language, 14, (2): 115 -
135.
Yihong Gong and Xin Liu. 2001. Generic text
summarization using relevance measure and latent
semantic analysis. In Proc. of Annual
International ACM SIGIR Conference on
Research and Development in Information
Retrieval: 19 - 25.
Akira Inoue, Takayoshi Mikami and Yoichi
Yamashita. 2004. Improvement of speech
summarization using prosodic information, In
Proc. of Speech Prosody: 599 - 602.
Shankar Kumar and William Byrne. 2004. Minimum
Bayes-risk decoding for statistical machine
translation. In Proc. of Human Language
Technology conference / North American chapter
of the Association for Computational Linguistics
annual meeting: 169 - 176.
Aleksander Kolcz, Vidya Prabakarmurthi and Jugal
Kalita. 2001. Summarization as feature selection
for text categorization. In Proc. of Conference on
Information and Knowledge Management: 365 -
370.
Julian Kupiec, Jan Pedersen and Francine Chen. 1999.
A trainable document summarizer. In Proc. of
Annual International ACM SIGIR Conference on
Research and Development in Information
Retrieval: 68 - 73.
Konstantinos Koumpis and Steve Renals. 2000.
Transcription And Summarization Of Voicemail
Speech. In Proc. of International Conference on
Spoken Language Processing: 688 - 691.
Chin-Yew Lin. 2004. ROUGE: a Package for
Automatic Evaluation of Summaries. In Proc. of
Workshop on Text Summarization Branches Out.
Shih-Hsiang Lin, Berlin Chen and Hsin-Min Wang.
2009. A comparative study of probabilistic
ranking models for Chinese spoken document
summarization. ACM Transactions on Asian
Language Information Processing, 8, (1): 3:1 -
3:23.
Shih-Hsiang Lin, Yueng-Tien Lo, Yao-Ming Yeh and
Berlin Chen. 2009. Hybrids of supervised and
unsupervised models for extractive speech
summarization. In Proc. of Annual Conference of
the International Speech Communication
Association: 1507 - 1510.
Inderjeet Mani and Mark T. Maybury Advances in
automatic text summarization. MIT Press,
Cambridge, 1999.
Sameer R. Maskey and Julia Hirschberg. 2003.
Automatic Summarization of Broadcast News
using Structural Features. In Proc. of the Euro-
pean Conf. Speech Communication and Technolo-
gy: 1173 - 1176.
Kathleen McKeown, Julia Hirschberg, Michel Galley
and Sameer Maskey. 2005. From text to speech
summarization. In Proc. of IEEE International
Conference on Acoustics, Speech, and Signal
Processing: 997 - 1000.
Rada Mihalcea and Paul Tarau. 2005. TextRank:
bringing order into texts. In Proc. of Conference
on Empirical Methods in Natural Language
Processing: 404 - 411.
Dragomir R. Radev, Hongyan Jing, Małgorzata Stys
and Daniel Tam. 2004. Centroid-based
summarization of multiple documents.
Information Processing and Management, 40: 919
- 938.
Dou Shen, Jian-Tao Sun, Hua Li, Qiang Yang and
Zheng Chen. 2007. Document summarization
using conditional random fields. In Proc. of
International Joint Conference on Artificial
Intelligence: 2862 - 2867.
Hsin-Min Wang, Berlin Chen, Jen-Wei Kuo and Shih-
Sian Cheng. 2005. MATBN: A Mandarin Chinese
broadcast news corpus. International Journal of
Computational Linguistics and Chinese Language
Processing, 10, (2): 219 - 236.
ChengXiang Zhai and John Lafferty. 2006. A risk
minimization framework for information retrieval.
Information Processing &amp; Management, 42, (1):
31 - 55.
ChengXiang Zhai. Statistical language models for
information retrieval. Morgan &amp; Claypool
Publishers, 2008.
Justin Jian Zhang, Ho Yin Chan and Pascale Fung.
2007. Improving Lecture Speech Summarization
Using Rhetorical Information. In Proc. of Workshop
of Automatic Speech Recognition Understanding:
195 - 200.
</reference>
<page confidence="0.999458">
87
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant confidence="0.814969" no="0">
<title confidence="0.9972705">A Risk Minimization Framework for Extractive Speech Summarization</title>
<author confidence="0.999126">Shih-Hsiang Lin</author>
<author confidence="0.999126">Berlin Chen</author>
<affiliation confidence="0.999996">National Taiwan Normal University</affiliation>
<address confidence="0.98632">Taipei, Taiwan</address>
<email confidence="0.983563">shlin@csie.ntnu.edu.tw</email>
<email confidence="0.983563">berlin@csie.ntnu.edu.tw</email>
<abstract confidence="0.97936625">In this paper, we formulate extractive summarization as a risk minimization problem and propose a unified probabilistic framework that naturally combines supervised and unsupervised summarization models to inherit their individual merits as well as to overcome their inherent limita-</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>O James</author>
</authors>
<title>Berger Statistical decision theory and Bayesian analysis.</title>
<date>1985</date>
<publisher>Springer-Verlap,</publisher>
<marker>James, 1985</marker>
<rawString>James O. Berger Statistical decision theory and Bayesian analysis. Springer-Verlap, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Berlin Chen</author>
</authors>
<title>Word topic models for spoken document retrieval and transcription.</title>
<date>2009</date>
<journal>ACM Transactions on Asian Language Information Processing,</journal>
<volume>8</volume>
<pages>2--1</pages>
<contexts>
<context citStr="Chen, 2009" endWordPosition="2771" position="17049" startWordPosition="2770">h, each sentence in a document can be simply regarded as a probabilistic generative model consisting of a unigram distribution (the so-called “bag-ofwords” assumption) for generating the document (Chen et al., 2009): PO Sj  ~ Pw Sj Yw`, w D  where cw ~ D , is the number of times that index term (or word) w occurs in D ~ , reflecting that w Sj . Note that the sentence model Pw Sj is simply estimated on the basis of the frequency of index term w occurring in the sentence Sj with the maximum likelihood (ML) criterion. In a sense, (9) belongs to a kind of literal term matching strategy (Chen, 2009) and may suffer the problem of unreliable model estimation owing particularly to only a few sampled index terms present in the sentence (Zhai, 2008). To mitigate this potential defect, a unigram probability estimated from a general collection, which models the general distribution of words in the target language, is often used to smooth the sentence model. Interested readers may refer to (Zhai, 2008; Chen et al., 2009) for a thorough discussion on various ways to construct the sentence generative model. 4.2 Sentence prior model The sentence prior probability PSj  can be regarded as the likel</context>
</contexts>
<marker>Chen, 2009</marker>
<rawString>Berlin Chen. 2009. Word topic models for spoken document retrieval and transcription. ACM Transactions on Asian Language Information Processing, 8, (1): 2:1 - 2:27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaime Carbonell</author>
<author>Jade Goldstein</author>
</authors>
<title>The use of mmr, diversity-based reranking for reordering documents and producing summaries.</title>
<date>1998</date>
<booktitle>In Proc. of Annual International ACM SIGIR Conference on Research and Development in Information Retrieval: 335 -</booktitle>
<pages>336</pages>
<contexts>
<context citStr="Carbonell and Goldstein, 1998" endWordPosition="3416" position="20664" startWordPosition="3413">tences Si , Sj is The loss function is thus defined by LSi, Sj1 SimSi, S j. (11) Once the sentence generative model PD |Sj  ~ , the sentence prior model PSj  and the loss function LSi, Sj have been properly estimated, the summary sentences can be selected iteratively by (8) according to a predefined target summarization ratio. However, as can be seen from (8), a new summary sentence is selected without considering the redundant information that is also contained in the already selected summary sentences. To alleviate this problem, the concept of maximum marginal relevance (MMR) (Carbonell and Goldstein, 1998), which performs sentence selection iteratively by striking the balance between topic relevance and coverage, can be incorporated into the loss function:   SimSi , Sj  L S S   ,   1  i j     ,      1  Sim S S max i, '   S'  Summ  where Summ represents the set of sentences that have already been included into the summary and the novelty factor  is used to trade off between relevance and redundancy. 4.4 Relation to other summarization models In this subsection, we briefly illustrate the relationship between our proposed summarization framework and a few existing summari</context>
</contexts>
<marker>Carbonell, Goldstein, 1998</marker>
<rawString>Jaime Carbonell and Jade Goldstein. 1998. The use of mmr, diversity-based reranking for reordering documents and producing summaries. In Proc. of Annual International ACM SIGIR Conference on Research and Development in Information Retrieval: 335 - 336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi-Ting Chen</author>
<author>Berlin Chen</author>
<author>Hsin-Min Wang</author>
</authors>
<title>A probabilistic generative framework for extractive broadcast news speech summarization.</title>
<date>2009</date>
<journal>IEEE Transactions on Audio, Speech and Language Processing,</journal>
<volume>17</volume>
<pages>95--106</pages>
<contexts>
<context citStr="Chen et al., 2009" endWordPosition="2336" position="14620" startWordPosition="2333">t turns out that the binary vector for each possible action will have just one element equal to 1 and all others equal to zero (or the so-called “one-of-n” coding). For ease of notation, we denote the binary vector by Si when the i -th element has a value of 1. Therefore, the risk minimization framework can be reduced to S&amp;quot;  arg min R ~ ~ denotes the remaining sentences that have not been selected into the summary yet (i.e., the “residual” document); P  S j D ~ |is the posterior probability of a sentence Sj given D~ . According, ccordin to th Bayes’ rule, we can further express PSj |b� as (Chen et al., 2009) PS |DPD |SjPSj  ~  ,(6) P D where PD |Sj  ~ is the sentence generative probability, i.e., the likelihood of D ~ being generated by Sj ; PSj  is the prior probability of Sj being important; and the evidence P  ~ D is the marginal probability of D~ , which can be approximated by PD AD|SmPSJ (7) Sm D By substituting (6) and (7) into (5), we obtain the following final selection strategy for extractive summarization: A remarkable feature of this framework lies in that a sentence to be considered as part of the summary is actually evaluated by three different fundamental facto</context>
<context citStr="Chen et al., 2009" endWordPosition="2688" position="16653" startWordPosition="2685"> what follows, we will shed light on one possible attempt that can accomplish this goal elegantly. 4.1 Sentence generative model In order to estimate the sentence generative probability, we explore the language modeling (LM) approach, which has been introduced to a wide spectrum of IR tasks and demonstrated with good empirical success, to predict the sentence generative probability. In the LM approach, each sentence in a document can be simply regarded as a probabilistic generative model consisting of a unigram distribution (the so-called “bag-ofwords” assumption) for generating the document (Chen et al., 2009): PO Sj  ~ Pw Sj Yw`, w D  where cw ~ D , is the number of times that index term (or word) w occurs in D ~ , reflecting that w Sj . Note that the sentence model Pw Sj is simply estimated on the basis of the frequency of index term w occurring in the sentence Sj with the maximum likelihood (ML) criterion. In a sense, (9) belongs to a kind of literal term matching strategy (Chen, 2009) and may suffer the problem of unreliable model estimation owing particularly to only a few sampled index terms present in the sentence (Zhai, 2008). To mitigate this potential defect, a unigram probabili</context>
</contexts>
<marker>Chen, Chen, Wang, 2009</marker>
<rawString>Yi-Ting Chen, Berlin Chen and Hsin-Min Wang. 2009. A probabilistic generative framework for extractive broadcast news speech summarization. IEEE Transactions on Audio, Speech and Language Processing, 17, (1): 95 - 106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John M Conroy</author>
<author>Dianne P O’Leary</author>
</authors>
<title>Text summarization via hidden Markov models.</title>
<date>2001</date>
<booktitle>In Proc. of Annual International ACM SIGIR Conference on Research and Development in Information Retrieval: 406 -</booktitle>
<pages>407</pages>
<marker>Conroy, O’Leary, 2001</marker>
<rawString>John M. Conroy and Dianne P. O’Leary. 2001. Text summarization via hidden Markov models. In Proc. of Annual International ACM SIGIR Conference on Research and Development in Information Retrieval: 406 - 407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Güneş Erkan</author>
<author>Dragomir R Radev</author>
</authors>
<title>LexRank: graph-based lexical centrality as salience in text summarization.</title>
<date>2004</date>
<journal>Journal or Artificial Intelligence Research,</journal>
<volume>22</volume>
<pages>457--479</pages>
<contexts>
<context citStr="Erkan and Radev, 2004" endWordPosition="673" position="4581" startWordPosition="670">f the 48th Annual Meeting of the Association for Computational Linguistics, pages 79–87, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics without leveraging the dependence relationships among the sentences or the global structure of the document (Shen et al., 2007). Another line of thought attempts to conduct document summarization using unsupervised machine-learning approaches, getting around the need for manually labeled training data. Most previous studies conducted along this line have their roots in the concept of sentence centrality (Gong and Liu, 2001; Erkan and Radev, 2004; Radev et al., 2004; Mihalcea and Tarau, 2005). Put simply, sentences more similar to others are deemed more salient to the main theme of the document; such sentences thus will be selected as part of the summary. Even though the performance of unsupervised summarizers is usually worse than that of supervised summarizers, their domain-independent and easy-to-implement properties still make them attractive. Building on these observations, we expect that researches conducted along the above-mentioned two directions could complement each other, and it might be possible to inherit their individual</context>
<context citStr="Erkan and Radev, 2004" endWordPosition="1433" position="9535" startWordPosition="1430">e of a document and the document itself in vector space (Gong and Liu, 2001), and computes the relevance score between each sentence and the document (e.g., the cosine measure of the simi80 larity between two vectors). Then, the sentences with the highest relevance scores are included in the summary. A natural extension is to represent each document or each sentence vector in a latent semantic space (Gong and Liu, 2001), instead of simply using the literal term information as that done by VSM. On the other hand, the graph-based methods, such as TextRank (Mihalcea and Tarau, 2005) and LexRank (Erkan and Radev, 2004), conceptualize the document to be summarized as a network of sentences, where each node represents a sentence and the associated weight of each link represents the lexical or topical similarity relationship between a pair of nodes. Document summarization thus relies on the global structural information conveyed by such conceptualized network, rather than merely considering the local features of each node (sentence). However, due to the lack of documentsummary reference pairs, the performance of the unsupervised summarizers is usually worse than that of the supervised summarizers. Moreover, mo</context>
</contexts>
<marker>Erkan, Radev, 2004</marker>
<rawString>Güneş Erkan and Dragomir R. Radev. 2004. LexRank: graph-based lexical centrality as salience in text summarization. Journal or Artificial Intelligence Research, 22: 457 - 479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohamed Abdel Fattah</author>
<author>Fuji Ren</author>
</authors>
<title>PNN and GMM based models for automatic text summarization.</title>
<date>2009</date>
<journal>Computer Speech and Language,</journal>
<volume>23</volume>
<pages>126--144</pages>
<contexts>
<context citStr="Fattah and Ren, 2009" endWordPosition="1159" position="7776" startWordPosition="1156">the positive class, Si will be selected as part of the summary; otherwise, it will be excluded (Kupiec et al., 1999). Specifically, the problem can be formulated as follows: Construct a sentence ranking model that assigns a classification score (or a posterior probability) of being in the summary class to each sentence of a spoken document to be summarized; important sentences are subsequently ranked and selected according to these scores. To this end, several popular machine-learning methods could be utilized, like Bayesian classifier (BC) (Kupiec et al., 1999), Gaussian mixture model (GMM) (Fattah and Ren, 2009) , hidden Markov model (HMM) (Conroy and O'leary, 2001), support vector machine (SVM) (Kolcz et al., 2001), maximum entropy (ME) (Ferrier, 2001), conditional random field (CRF) (Galley, 2006; Shen et al., 2007), to name a few. Although such supervised summarizers are effective, most of them (except CRF) usually implicitly assume that sentences are independent of each other (the so-called “bag-of-sentences” assumption) and classify each sentence individually without leveraging the relationship among the sentences (Shen et al., 2007). Another major shortcoming of these summarizers is that a set </context>
</contexts>
<marker>Fattah, Ren, 2009</marker>
<rawString>Mohamed Abdel Fattah and Fuji Ren. 2009. GA, MR, FFNN, PNN and GMM based models for automatic text summarization. Computer Speech and Language, 23, (1): 126 - 144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Louisa Ferrier</author>
</authors>
<title>A maximum entropy approach to text summarization.</title>
<date>2001</date>
<institution>School of Artificial Intelligence, University of Edinburgh,</institution>
<contexts>
<context citStr="Ferrier, 2001" endWordPosition="1181" position="7920" startWordPosition="1180">formulated as follows: Construct a sentence ranking model that assigns a classification score (or a posterior probability) of being in the summary class to each sentence of a spoken document to be summarized; important sentences are subsequently ranked and selected according to these scores. To this end, several popular machine-learning methods could be utilized, like Bayesian classifier (BC) (Kupiec et al., 1999), Gaussian mixture model (GMM) (Fattah and Ren, 2009) , hidden Markov model (HMM) (Conroy and O'leary, 2001), support vector machine (SVM) (Kolcz et al., 2001), maximum entropy (ME) (Ferrier, 2001), conditional random field (CRF) (Galley, 2006; Shen et al., 2007), to name a few. Although such supervised summarizers are effective, most of them (except CRF) usually implicitly assume that sentences are independent of each other (the so-called “bag-of-sentences” assumption) and classify each sentence individually without leveraging the relationship among the sentences (Shen et al., 2007). Another major shortcoming of these summarizers is that a set of handcrafted document-reference summary exemplars are required for training the summarizers; however, such summarizers tend to limit their gen</context>
</contexts>
<marker>Ferrier, 2001</marker>
<rawString>Louisa Ferrier A maximum entropy approach to text summarization. School of Artificial Intelligence, University of Edinburgh, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sadaoki Furui</author>
<author>Tomonori Kikuchi</author>
<author>Yousuke Shinnaka</author>
<author>Chiori Hori</author>
</authors>
<title>Speech-to-text and speechto-speech summarization of spontaneous speech.</title>
<date>2004</date>
<journal>IEEE Transactions on Speech and Audio Processing,</journal>
<volume>12</volume>
<pages>401--408</pages>
<contexts>
<context citStr="Furui et al., 2004" endWordPosition="196" position="1339" startWordPosition="193">ent, respectively. Experiments on speech summarization show that the methods deduced from our framework are very competitive with existing summarization approaches. 1 Introduction Automated summarization systems which enable user to quickly digest the important information conveyed by either a single or a cluster of documents are indispensible for managing the rapidly growing amount of textual information and multimedia content (Mani and Maybury, 1999). On the other hand, due to the maturity of text summarization, the research paradigm has been extended to speech summarization over the years (Furui et al., 2004; McKeown et al., 2005). Speech summarization is expected to distill important information and remove redundant and incorrect information caused by recognition errors from spoken documents, enabling user to efficiently review spoken documents and understand the associated topics quickly. It would also be useful for improving the efficiency of a number of potential applications like retrieval and mining of large volumes of spoken documents. A summary can be either abstractive or extractive. In abstractive summarization, a fluent and concise abstract that reflects the key concepts of a document </context>
<context citStr="Furui et al., 2004" endWordPosition="935" position="6363" startWordPosition="932">he remainder of this paper is structured as follows. We start by reviewing related work on extractive summarization. In Section 3 we formulate the extractive summarization task as a risk minimization problem, followed by a detailed elucidation of the proposed methods in Section 4. Then, the experimental setup and a series of experiments and associated discussions are presented in Sections 5 and 6, respectively. Finally, Section 7 concludes our presentation and discusses avenues for future work. 2 Background Speech summarization can be conducted using either supervised or unsupervised methods (Furui et al., 2004, McKeown et al., 2005, Lin et al., 2008). In the following, we briefly review a few celebrated methods that have been applied to extractive speech summarization tasks with good success. 2.1 Supervised summarizers Extractive speech summarization can be treated as a two-class (positive/negative) classification problem. A spoken sentence Si is characterized by set of T indicative features Xi  xi 1 , , x iT  , and they may include lexical features (Koumpis and Renals, 2000), structural features (Maskey and Hirschberg, 2003), acoustic features (Inoue et al., 2004), discourse features (Zhang et</context>
</contexts>
<marker>Furui, Kikuchi, Shinnaka, Hori, 2004</marker>
<rawString>Sadaoki Furui, Tomonori Kikuchi, Yousuke Shinnaka and Chiori Hori. 2004. Speech-to-text and speechto-speech summarization of spontaneous speech. IEEE Transactions on Speech and Audio Processing, 12, (4): 401 - 408.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
</authors>
<title>A skip-chain conditional random field for ranking meeting utterances by importance.</title>
<date>2006</date>
<booktitle>In Proc. of Conference on Empirical Methods in Natural Language Processing:</booktitle>
<pages>364--372</pages>
<contexts>
<context citStr="Galley, 2006" endWordPosition="1187" position="7966" startWordPosition="1186">ing model that assigns a classification score (or a posterior probability) of being in the summary class to each sentence of a spoken document to be summarized; important sentences are subsequently ranked and selected according to these scores. To this end, several popular machine-learning methods could be utilized, like Bayesian classifier (BC) (Kupiec et al., 1999), Gaussian mixture model (GMM) (Fattah and Ren, 2009) , hidden Markov model (HMM) (Conroy and O'leary, 2001), support vector machine (SVM) (Kolcz et al., 2001), maximum entropy (ME) (Ferrier, 2001), conditional random field (CRF) (Galley, 2006; Shen et al., 2007), to name a few. Although such supervised summarizers are effective, most of them (except CRF) usually implicitly assume that sentences are independent of each other (the so-called “bag-of-sentences” assumption) and classify each sentence individually without leveraging the relationship among the sentences (Shen et al., 2007). Another major shortcoming of these summarizers is that a set of handcrafted document-reference summary exemplars are required for training the summarizers; however, such summarizers tend to limit their generalization capability and might not be readil</context>
</contexts>
<marker>Galley, 2006</marker>
<rawString>Michel Galley. 2006. A skip-chain conditional random field for ranking meeting utterances by importance. In Proc. of Conference on Empirical Methods in Natural Language Processing: 364 -372.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vaibhava Goel</author>
<author>William Byrne</author>
</authors>
<title>Minimum Bayes-risk automatic speech recognition.</title>
<date>2000</date>
<journal>Computer Speech and Language,</journal>
<volume>14</volume>
<pages>115--135</pages>
<contexts>
<context citStr="Goel and Byrne, 2000" endWordPosition="1841" position="11967" startWordPosition="1838"> expected risk (or conditional risk) associated with taking decision ai is given by Rai|O OLai, OpO|OdO, (1) where p O |O is the posterior probability of the state of nature being  given the observation O. Bayes decision theory states that the optimum decision can be made by contemplating each action ai , and then choosing the action for which the expected risk is minimum: a* arg min R  a i |O .  ai The notion of minimizing the Bayes risk has gained much attention and been applied with success to many natural language processing (NLP) tasks, such as automatic speech recognition (Goel and Byrne, 2000), statistical machine translation (Kumar and Byrne, 2004) and statistical information retrieval (Zhai and Lafferty, 2006). Following the same spirit, we formulate the extractive summarization task as a Bayes risk minimization problem. Without loss of generality, let us denote   Π as one of possible selection strategies (or state of nature) which comprises a set of indicators used to address the importance of each sentence Si in a document D to be summarized. A feasible selection strategy can be fairly arbitrary according to the underlying principle. For example, it could be a set of binary i</context>
</contexts>
<marker>Goel, Byrne, 2000</marker>
<rawString>Vaibhava Goel and William Byrne. 2000. Minimum Bayes-risk automatic speech recognition. Computer Speech and Language, 14, (2): 115 -135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yihong Gong</author>
<author>Xin Liu</author>
</authors>
<title>Generic text summarization using relevance measure and latent semantic analysis.</title>
<date>2001</date>
<booktitle>In Proc. of Annual International ACM SIGIR Conference on Research and Development in Information Retrieval: 19 -</booktitle>
<pages>25</pages>
<contexts>
<context citStr="Gong and Liu, 2001" endWordPosition="669" position="4558" startWordPosition="666">er, 79 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 79–87, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics without leveraging the dependence relationships among the sentences or the global structure of the document (Shen et al., 2007). Another line of thought attempts to conduct document summarization using unsupervised machine-learning approaches, getting around the need for manually labeled training data. Most previous studies conducted along this line have their roots in the concept of sentence centrality (Gong and Liu, 2001; Erkan and Radev, 2004; Radev et al., 2004; Mihalcea and Tarau, 2005). Put simply, sentences more similar to others are deemed more salient to the main theme of the document; such sentences thus will be selected as part of the summary. Even though the performance of unsupervised summarizers is usually worse than that of supervised summarizers, their domain-independent and easy-to-implement properties still make them attractive. Building on these observations, we expect that researches conducted along the above-mentioned two directions could complement each other, and it might be possible to i</context>
<context citStr="Gong and Liu, 2001" endWordPosition="1343" position="8989" startWordPosition="1340">a set of handcrafted document-reference summary exemplars are required for training the summarizers; however, such summarizers tend to limit their generalization capability and might not be readily applicable for new tasks or domains. 2.2 Unsupervised summarizers The related work conducted along this direction usually relies on some heuristic rules or statistical evidences between each sentence and the document, avoiding the need of manually labeled training data. For example, the vector space model (VSM) approach represents each sentence of a document and the document itself in vector space (Gong and Liu, 2001), and computes the relevance score between each sentence and the document (e.g., the cosine measure of the simi80 larity between two vectors). Then, the sentences with the highest relevance scores are included in the summary. A natural extension is to represent each document or each sentence vector in a latent semantic space (Gong and Liu, 2001), instead of simply using the literal term information as that done by VSM. On the other hand, the graph-based methods, such as TextRank (Mihalcea and Tarau, 2005) and LexRank (Erkan and Radev, 2004), conceptualize the document to be summarized as a net</context>
<context citStr="Gong and Liu, 2001" endWordPosition="3254" position="19706" startWordPosition="3251">classifiers (or summarizers), like BC or SVM, can be leveraged for this purpose. 4.3 Loss function The loss function introduced in the proposed summarization framework is to measure the relationship between any pair of sentences. Intuitively, when a given sentence is more dissimilar from most of the other sentences, it may incur higher loss as it is taken as the representative sentence (or summary sentence) to represent the main theme embedded in the other ones. Consequently, the loss function can be built on the notion of the similarity measure. In this research, we adopt the cosine measure (Gong and Liu, 2001) to fulfill this goal. We first represent each sentence Si in vector form where each dimension specifies the weighted statistic zt,i , e.g., the product of the term frequency (TF) and inverse document frequency (IDF) scores, associated with an index term wt in sentence Si . Then, the cosine similarity between any given two sentences Si , Sj is The loss function is thus defined by LSi, Sj1 SimSi, S j. (11) Once the sentence generative model PD |Sj  ~ , the sentence prior model PSj  and the loss function LSi, Sj have been properly estimated, the summary sentences can be selected it</context>
<context citStr="Gong and Liu, 2001" endWordPosition="4467" position="26809" startWordPosition="4464">e, including the structural features, the lexical features, the acoustic features and the relevance feature. For each kind of acoustic features, the minimum, maximum, mean, difference value and mean difference value of a spoken sentence are extracted. The difference value is defined as the difference between the minimum and maximum values of the spoken sentence, while the mean difference value is defined as the mean difference between a sentence and its previous sentence. Finally, the relevance feature (VSM score) is use to measure the degree of relevance for a sentence to the whole document (Gong and Liu, 2001). These features are outlined in Table 2, where each of them was further normalized to zero mean and unit variance. 6 Experimental results and discussions 6.1 Baseline experiments In the first set of experiments, we evaluate the baseline performance of the LM and BC summarizers (cf. Sections 4.1 and 4.2), respectively. The corresponding results are detailed in Table 3, 84 Text Document (TD) Spoken Document (SD) ROGUE-1 ROUGE-2 ROUGE-L ROGUE-1 ROUGE-2 ROUGE-L BC 0.445 0.346 0.404 0.369 0.241 0.321 (0.390 - 0.504) (0.201 - 0.415) (0.348 - 0.468) (0.316 - 0.426) (0.183 - 0.302) (0.268 - 0.378) LM</context>
</contexts>
<marker>Gong, Liu, 2001</marker>
<rawString>Yihong Gong and Xin Liu. 2001. Generic text summarization using relevance measure and latent semantic analysis. In Proc. of Annual International ACM SIGIR Conference on Research and Development in Information Retrieval: 19 - 25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akira Inoue</author>
<author>Takayoshi Mikami</author>
<author>Yoichi Yamashita</author>
</authors>
<title>Improvement of speech summarization using prosodic information,</title>
<date>2004</date>
<booktitle>In Proc. of Speech Prosody: 599 -</booktitle>
<pages>602</pages>
<contexts>
<context citStr="Inoue et al., 2004" endWordPosition="1024" position="6933" startWordPosition="1021">vised or unsupervised methods (Furui et al., 2004, McKeown et al., 2005, Lin et al., 2008). In the following, we briefly review a few celebrated methods that have been applied to extractive speech summarization tasks with good success. 2.1 Supervised summarizers Extractive speech summarization can be treated as a two-class (positive/negative) classification problem. A spoken sentence Si is characterized by set of T indicative features Xi  xi 1 , , x iT  , and they may include lexical features (Koumpis and Renals, 2000), structural features (Maskey and Hirschberg, 2003), acoustic features (Inoue et al., 2004), discourse features (Zhang et al., 2007) and relevance features (Lin et al., 2009). Then, the corresponding feature vector Xi of Si is taken as the input to the classifier. If the output (classification) score belongs to the positive class, Si will be selected as part of the summary; otherwise, it will be excluded (Kupiec et al., 1999). Specifically, the problem can be formulated as follows: Construct a sentence ranking model that assigns a classification score (or a posterior probability) of being in the summary class to each sentence of a spoken document to be summarized; important sentence</context>
</contexts>
<marker>Inoue, Mikami, Yamashita, 2004</marker>
<rawString>Akira Inoue, Takayoshi Mikami and Yoichi Yamashita. 2004. Improvement of speech summarization using prosodic information, In Proc. of Speech Prosody: 599 - 602.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shankar Kumar</author>
<author>William Byrne</author>
</authors>
<title>Minimum Bayes-risk decoding for statistical machine translation.</title>
<date>2004</date>
<booktitle>In Proc. of Human Language Technology conference / North American chapter of the Association for Computational Linguistics annual meeting:</booktitle>
<pages>169--176</pages>
<contexts>
<context citStr="Kumar and Byrne, 2004" endWordPosition="1848" position="12024" startWordPosition="1845">ing decision ai is given by Rai|O OLai, OpO|OdO, (1) where p O |O is the posterior probability of the state of nature being  given the observation O. Bayes decision theory states that the optimum decision can be made by contemplating each action ai , and then choosing the action for which the expected risk is minimum: a* arg min R  a i |O .  ai The notion of minimizing the Bayes risk has gained much attention and been applied with success to many natural language processing (NLP) tasks, such as automatic speech recognition (Goel and Byrne, 2000), statistical machine translation (Kumar and Byrne, 2004) and statistical information retrieval (Zhai and Lafferty, 2006). Following the same spirit, we formulate the extractive summarization task as a Bayes risk minimization problem. Without loss of generality, let us denote   Π as one of possible selection strategies (or state of nature) which comprises a set of indicators used to address the importance of each sentence Si in a document D to be summarized. A feasible selection strategy can be fairly arbitrary according to the underlying principle. For example, it could be a set of binary indicators denoting whether a sentence should be selected </context>
</contexts>
<marker>Kumar, Byrne, 2004</marker>
<rawString>Shankar Kumar and William Byrne. 2004. Minimum Bayes-risk decoding for statistical machine translation. In Proc. of Human Language Technology conference / North American chapter of the Association for Computational Linguistics annual meeting: 169 - 176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aleksander Kolcz</author>
<author>Vidya Prabakarmurthi</author>
<author>Jugal Kalita</author>
</authors>
<title>Summarization as feature selection for text categorization.</title>
<date>2001</date>
<booktitle>In Proc. of Conference on Information and Knowledge Management:</booktitle>
<pages>365--370</pages>
<contexts>
<context citStr="Kolcz et al., 2001" endWordPosition="1176" position="7882" startWordPosition="1173">., 1999). Specifically, the problem can be formulated as follows: Construct a sentence ranking model that assigns a classification score (or a posterior probability) of being in the summary class to each sentence of a spoken document to be summarized; important sentences are subsequently ranked and selected according to these scores. To this end, several popular machine-learning methods could be utilized, like Bayesian classifier (BC) (Kupiec et al., 1999), Gaussian mixture model (GMM) (Fattah and Ren, 2009) , hidden Markov model (HMM) (Conroy and O'leary, 2001), support vector machine (SVM) (Kolcz et al., 2001), maximum entropy (ME) (Ferrier, 2001), conditional random field (CRF) (Galley, 2006; Shen et al., 2007), to name a few. Although such supervised summarizers are effective, most of them (except CRF) usually implicitly assume that sentences are independent of each other (the so-called “bag-of-sentences” assumption) and classify each sentence individually without leveraging the relationship among the sentences (Shen et al., 2007). Another major shortcoming of these summarizers is that a set of handcrafted document-reference summary exemplars are required for training the summarizers; however, su</context>
</contexts>
<marker>Kolcz, Prabakarmurthi, Kalita, 2001</marker>
<rawString>Aleksander Kolcz, Vidya Prabakarmurthi and Jugal Kalita. 2001. Summarization as feature selection for text categorization. In Proc. of Conference on Information and Knowledge Management: 365 -370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julian Kupiec</author>
<author>Jan Pedersen</author>
<author>Francine Chen</author>
</authors>
<title>A trainable document summarizer.</title>
<date>1999</date>
<booktitle>In Proc. of Annual International ACM SIGIR Conference on Research and Development in Information Retrieval: 68 -</booktitle>
<pages>73</pages>
<contexts>
<context citStr="Kupiec et al., 1999" endWordPosition="466" position="3191" startWordPosition="463">ingledocument or multi-document summarization, and so forth. The readers may refer to (Mani and Maybury, 1999) for a comprehensive overview of automatic text summarization. In this paper, we focus exclusively on generic, singledocument extractive summarization which forms the building block for many other summarization tasks. Aside from traditional ad-hoc extractive summarization methods (Mani and Maybury, 1999), machine-learning approaches with either supervised or unsupervised learning strategies have gained much attention and been applied with empirical success to many summarization tasks (Kupiec et al., 1999; Lin et al., 2009). For supervised learning strategies, the summarization task is usually cast as a two-class (summary and nonsummary) sentence-classification problem: A sentence with a set of indicative features is input to the classifier (or summarizer) and a decision is then returned from it on the basis of these features. In general, they usually require a training set, comprised of several documents and their corresponding handcrafted summaries (or labeled data), to train the classifiers. However, manual labeling is expensive in terms of time and personnel. The other potential problem is</context>
<context citStr="Kupiec et al., 1999" endWordPosition="1082" position="7271" startWordPosition="1079">gative) classification problem. A spoken sentence Si is characterized by set of T indicative features Xi  xi 1 , , x iT  , and they may include lexical features (Koumpis and Renals, 2000), structural features (Maskey and Hirschberg, 2003), acoustic features (Inoue et al., 2004), discourse features (Zhang et al., 2007) and relevance features (Lin et al., 2009). Then, the corresponding feature vector Xi of Si is taken as the input to the classifier. If the output (classification) score belongs to the positive class, Si will be selected as part of the summary; otherwise, it will be excluded (Kupiec et al., 1999). Specifically, the problem can be formulated as follows: Construct a sentence ranking model that assigns a classification score (or a posterior probability) of being in the summary class to each sentence of a spoken document to be summarized; important sentences are subsequently ranked and selected according to these scores. To this end, several popular machine-learning methods could be utilized, like Bayesian classifier (BC) (Kupiec et al., 1999), Gaussian mixture model (GMM) (Fattah and Ren, 2009) , hidden Markov model (HMM) (Conroy and O'leary, 2001), support vector machine (SVM) (Kolcz et</context>
<context citStr="Kupiec et al., 1999" endWordPosition="3037" position="18496" startWordPosition="3034">ation or the inherent prosodic properties of a spoken sentence. A straightforward way is to assume that the sentence prior probability PSj  is in proportion to the posterior probability of a sentence Sj beS D i arg min LSi,Sj+j |5, ~ ~ S D j  S D i (5) S PS j  S&amp;quot;  argmin  LS„ Sj ~ D . ~P (8) D SiD Sj � Sm kSm ) ~ S D m eD Si |b where D (9) will contribute more in the calculation of PD if it occurs more frequently in D 82 ing included in the summary class when observing a set of indicative features Xj of Sj derived from such factors or other sentence importance measures (Kupiec et al., 1999). These features can be integrated in a systematic way into the proposed framework by taking the advantage of the learning capability of the supervised machine-learning methods. Specifically, the prior probability P Sj  can be approximated by: PSj P j|SSS+S X  |SP S, j (10) where PXj |S and PXj |S  are the likelihoods that a sentence Sj with features Xj are generated by the summary class S and the nonsummary class S , respectively; the prior probability PS and P  S  are set to be equal in this research. To estimate PX . |S and PXj |S  , several popular supervised classifie</context>
</contexts>
<marker>Kupiec, Pedersen, Chen, 1999</marker>
<rawString>Julian Kupiec, Jan Pedersen and Francine Chen. 1999. A trainable document summarizer. In Proc. of Annual International ACM SIGIR Conference on Research and Development in Information Retrieval: 68 - 73.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Konstantinos Koumpis</author>
<author>Steve Renals</author>
</authors>
<title>Transcription And Summarization Of Voicemail Speech. In</title>
<date>2000</date>
<booktitle>Proc. of International Conference on Spoken Language Processing: 688 -</booktitle>
<pages>691</pages>
<contexts>
<context citStr="Koumpis and Renals, 2000" endWordPosition="1012" position="6842" startWordPosition="1009">es avenues for future work. 2 Background Speech summarization can be conducted using either supervised or unsupervised methods (Furui et al., 2004, McKeown et al., 2005, Lin et al., 2008). In the following, we briefly review a few celebrated methods that have been applied to extractive speech summarization tasks with good success. 2.1 Supervised summarizers Extractive speech summarization can be treated as a two-class (positive/negative) classification problem. A spoken sentence Si is characterized by set of T indicative features Xi  xi 1 , , x iT  , and they may include lexical features (Koumpis and Renals, 2000), structural features (Maskey and Hirschberg, 2003), acoustic features (Inoue et al., 2004), discourse features (Zhang et al., 2007) and relevance features (Lin et al., 2009). Then, the corresponding feature vector Xi of Si is taken as the input to the classifier. If the output (classification) score belongs to the positive class, Si will be selected as part of the summary; otherwise, it will be excluded (Kupiec et al., 1999). Specifically, the problem can be formulated as follows: Construct a sentence ranking model that assigns a classification score (or a posterior probability) of being in t</context>
</contexts>
<marker>Koumpis, Renals, 2000</marker>
<rawString>Konstantinos Koumpis and Steve Renals. 2000. Transcription And Summarization Of Voicemail Speech. In Proc. of International Conference on Spoken Language Processing: 688 - 691.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chin-Yew Lin</author>
</authors>
<title>ROUGE: a Package for Automatic Evaluation of Summaries.</title>
<date>2004</date>
<booktitle>In Proc. of Workshop on Text Summarization Branches Out.</booktitle>
<contexts>
<context citStr="Lin, 2004" endWordPosition="4107" position="24563" startWordPosition="4106"> compared to other speech materials like conversations, the positional information would play an important (dominant) role in extractive summarization of broadcast news stories; we, hence, chose 20 documents for which the generation of reference summaries is less correlated with the positional information (or the position of sentences) as the held-out test set to evaluate the general performance of the proposed summarization framework, and 100 documents as the development set. 5.2 Performance evaluation For the assessment of summarization performance, we adopted the widely used ROUGE measure (Lin, 2004) because of its higher correlation with human judgments. It evaluates the quality of the summarization by counting the number of overlapping units, such as N-grams, longest common subsequences or skip-bigram, between the automatic summary and a set of reference summaries. Three variants of the ROGUE measure were used to quantify the utility of the proposed method. They are, respectively, the ROUGE-1 (unigram) measure, the ROUGE-2 (bigram) measure and the ROUGE-L (longest common subsequence) measure (Lin, 2004). The summarization ratio, defined as the ratio of the number of words in the automat</context>
</contexts>
<marker>Lin, 2004</marker>
<rawString>Chin-Yew Lin. 2004. ROUGE: a Package for Automatic Evaluation of Summaries. In Proc. of Workshop on Text Summarization Branches Out.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shih-Hsiang Lin</author>
<author>Berlin Chen</author>
<author>Hsin-Min Wang</author>
</authors>
<title>A comparative study of probabilistic ranking models for Chinese spoken document summarization.</title>
<date>2009</date>
<journal>ACM Transactions on Asian Language Information Processing,</journal>
<volume>8</volume>
<pages>3--1</pages>
<contexts>
<context citStr="Lin et al., 2009" endWordPosition="470" position="3210" startWordPosition="467">i-document summarization, and so forth. The readers may refer to (Mani and Maybury, 1999) for a comprehensive overview of automatic text summarization. In this paper, we focus exclusively on generic, singledocument extractive summarization which forms the building block for many other summarization tasks. Aside from traditional ad-hoc extractive summarization methods (Mani and Maybury, 1999), machine-learning approaches with either supervised or unsupervised learning strategies have gained much attention and been applied with empirical success to many summarization tasks (Kupiec et al., 1999; Lin et al., 2009). For supervised learning strategies, the summarization task is usually cast as a two-class (summary and nonsummary) sentence-classification problem: A sentence with a set of indicative features is input to the classifier (or summarizer) and a decision is then returned from it on the basis of these features. In general, they usually require a training set, comprised of several documents and their corresponding handcrafted summaries (or labeled data), to train the classifiers. However, manual labeling is expensive in terms of time and personnel. The other potential problem is the socalled “bag-</context>
<context citStr="Lin et al., 2009" endWordPosition="1037" position="7016" startWordPosition="1034">2008). In the following, we briefly review a few celebrated methods that have been applied to extractive speech summarization tasks with good success. 2.1 Supervised summarizers Extractive speech summarization can be treated as a two-class (positive/negative) classification problem. A spoken sentence Si is characterized by set of T indicative features Xi  xi 1 , , x iT  , and they may include lexical features (Koumpis and Renals, 2000), structural features (Maskey and Hirschberg, 2003), acoustic features (Inoue et al., 2004), discourse features (Zhang et al., 2007) and relevance features (Lin et al., 2009). Then, the corresponding feature vector Xi of Si is taken as the input to the classifier. If the output (classification) score belongs to the positive class, Si will be selected as part of the summary; otherwise, it will be excluded (Kupiec et al., 1999). Specifically, the problem can be formulated as follows: Construct a sentence ranking model that assigns a classification score (or a posterior probability) of being in the summary class to each sentence of a spoken document to be summarized; important sentences are subsequently ranked and selected according to these scores. To this end, seve</context>
<context citStr="Lin et al., 2009" endWordPosition="3620" position="21690" startWordPosition="3617">e and redundancy. 4.4 Relation to other summarization models In this subsection, we briefly illustrate the relationship between our proposed summarization framework and a few existing summarization approaches. We start by considering a special case where a 0-1 loss function is used in (8), namely, the loss function will take value 0 if the two sentences are identical, and 1 otherwise. Then, (8) can be alternatively represented by P D S P S     ~ |j j PD |Sm)Sm  S D m  ~ PP |SmPSm  S D m  which actually provides a natural integration of the supervised and unsupervised summarizers (Lin et al., 2009), as mentioned previously. If we further assume the prior probability PSj  is uniformly distributed, the important (or summary) sentence selection problem has now been reduced to the problem of measuring the document-likelihood PD |Sj  ~ , or the relevance between the document and the sentence. Alone a similar vein, the important sentences of a document can be selected (or ranked) solely based on the prior probability PSj  with the assumption of an equal document-likelihood P  D |Sj ~ . 5 Experimental setup 5.1 Data The summarization dataset used in this research is a widely used broad</context>
</contexts>
<marker>Lin, Chen, Wang, 2009</marker>
<rawString>Shih-Hsiang Lin, Berlin Chen and Hsin-Min Wang. 2009. A comparative study of probabilistic ranking models for Chinese spoken document summarization. ACM Transactions on Asian Language Information Processing, 8, (1): 3:1 -3:23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shih-Hsiang Lin</author>
<author>Yueng-Tien Lo</author>
<author>Yao-Ming Yeh</author>
<author>Berlin Chen</author>
</authors>
<title>Hybrids of supervised and unsupervised models for extractive speech summarization.</title>
<date>2009</date>
<booktitle>In Proc. of Annual Conference of the International Speech Communication Association:</booktitle>
<pages>1507--1510</pages>
<contexts>
<context citStr="Lin et al., 2009" endWordPosition="470" position="3210" startWordPosition="467">i-document summarization, and so forth. The readers may refer to (Mani and Maybury, 1999) for a comprehensive overview of automatic text summarization. In this paper, we focus exclusively on generic, singledocument extractive summarization which forms the building block for many other summarization tasks. Aside from traditional ad-hoc extractive summarization methods (Mani and Maybury, 1999), machine-learning approaches with either supervised or unsupervised learning strategies have gained much attention and been applied with empirical success to many summarization tasks (Kupiec et al., 1999; Lin et al., 2009). For supervised learning strategies, the summarization task is usually cast as a two-class (summary and nonsummary) sentence-classification problem: A sentence with a set of indicative features is input to the classifier (or summarizer) and a decision is then returned from it on the basis of these features. In general, they usually require a training set, comprised of several documents and their corresponding handcrafted summaries (or labeled data), to train the classifiers. However, manual labeling is expensive in terms of time and personnel. The other potential problem is the socalled “bag-</context>
<context citStr="Lin et al., 2009" endWordPosition="1037" position="7016" startWordPosition="1034">2008). In the following, we briefly review a few celebrated methods that have been applied to extractive speech summarization tasks with good success. 2.1 Supervised summarizers Extractive speech summarization can be treated as a two-class (positive/negative) classification problem. A spoken sentence Si is characterized by set of T indicative features Xi  xi 1 , , x iT  , and they may include lexical features (Koumpis and Renals, 2000), structural features (Maskey and Hirschberg, 2003), acoustic features (Inoue et al., 2004), discourse features (Zhang et al., 2007) and relevance features (Lin et al., 2009). Then, the corresponding feature vector Xi of Si is taken as the input to the classifier. If the output (classification) score belongs to the positive class, Si will be selected as part of the summary; otherwise, it will be excluded (Kupiec et al., 1999). Specifically, the problem can be formulated as follows: Construct a sentence ranking model that assigns a classification score (or a posterior probability) of being in the summary class to each sentence of a spoken document to be summarized; important sentences are subsequently ranked and selected according to these scores. To this end, seve</context>
<context citStr="Lin et al., 2009" endWordPosition="3620" position="21690" startWordPosition="3617">e and redundancy. 4.4 Relation to other summarization models In this subsection, we briefly illustrate the relationship between our proposed summarization framework and a few existing summarization approaches. We start by considering a special case where a 0-1 loss function is used in (8), namely, the loss function will take value 0 if the two sentences are identical, and 1 otherwise. Then, (8) can be alternatively represented by P D S P S     ~ |j j PD |Sm)Sm  S D m  ~ PP |SmPSm  S D m  which actually provides a natural integration of the supervised and unsupervised summarizers (Lin et al., 2009), as mentioned previously. If we further assume the prior probability PSj  is uniformly distributed, the important (or summary) sentence selection problem has now been reduced to the problem of measuring the document-likelihood PD |Sj  ~ , or the relevance between the document and the sentence. Alone a similar vein, the important sentences of a document can be selected (or ranked) solely based on the prior probability PSj  with the assumption of an equal document-likelihood P  D |Sj ~ . 5 Experimental setup 5.1 Data The summarization dataset used in this research is a widely used broad</context>
</contexts>
<marker>Lin, Lo, Yeh, Chen, 2009</marker>
<rawString>Shih-Hsiang Lin, Yueng-Tien Lo, Yao-Ming Yeh and Berlin Chen. 2009. Hybrids of supervised and unsupervised models for extractive speech summarization. In Proc. of Annual Conference of the International Speech Communication Association: 1507 - 1510.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjeet Mani</author>
<author>T Mark</author>
</authors>
<title>Maybury Advances in automatic text summarization.</title>
<date>1999</date>
<publisher>MIT Press,</publisher>
<location>Cambridge,</location>
<marker>Mani, Mark, 1999</marker>
<rawString>Inderjeet Mani and Mark T. Maybury Advances in automatic text summarization. MIT Press, Cambridge, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer R Maskey</author>
<author>Julia Hirschberg</author>
</authors>
<title>Automatic Summarization of Broadcast News using Structural Features.</title>
<date>2003</date>
<booktitle>In Proc. of the European Conf. Speech Communication and Technology:</booktitle>
<pages>1173--1176</pages>
<contexts>
<context citStr="Maskey and Hirschberg, 2003" endWordPosition="1018" position="6893" startWordPosition="1015">summarization can be conducted using either supervised or unsupervised methods (Furui et al., 2004, McKeown et al., 2005, Lin et al., 2008). In the following, we briefly review a few celebrated methods that have been applied to extractive speech summarization tasks with good success. 2.1 Supervised summarizers Extractive speech summarization can be treated as a two-class (positive/negative) classification problem. A spoken sentence Si is characterized by set of T indicative features Xi  xi 1 , , x iT  , and they may include lexical features (Koumpis and Renals, 2000), structural features (Maskey and Hirschberg, 2003), acoustic features (Inoue et al., 2004), discourse features (Zhang et al., 2007) and relevance features (Lin et al., 2009). Then, the corresponding feature vector Xi of Si is taken as the input to the classifier. If the output (classification) score belongs to the positive class, Si will be selected as part of the summary; otherwise, it will be excluded (Kupiec et al., 1999). Specifically, the problem can be formulated as follows: Construct a sentence ranking model that assigns a classification score (or a posterior probability) of being in the summary class to each sentence of a spoken docum</context>
</contexts>
<marker>Maskey, Hirschberg, 2003</marker>
<rawString>Sameer R. Maskey and Julia Hirschberg. 2003. Automatic Summarization of Broadcast News using Structural Features. In Proc. of the European Conf. Speech Communication and Technology: 1173 - 1176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen McKeown</author>
<author>Julia Hirschberg</author>
<author>Michel Galley</author>
<author>Sameer Maskey</author>
</authors>
<title>From text to speech summarization.</title>
<date>2005</date>
<booktitle>In Proc. of IEEE International Conference on Acoustics, Speech, and Signal Processing: 997 -</booktitle>
<pages>1000</pages>
<contexts>
<context citStr="McKeown et al., 2005" endWordPosition="200" position="1362" startWordPosition="197">xperiments on speech summarization show that the methods deduced from our framework are very competitive with existing summarization approaches. 1 Introduction Automated summarization systems which enable user to quickly digest the important information conveyed by either a single or a cluster of documents are indispensible for managing the rapidly growing amount of textual information and multimedia content (Mani and Maybury, 1999). On the other hand, due to the maturity of text summarization, the research paradigm has been extended to speech summarization over the years (Furui et al., 2004; McKeown et al., 2005). Speech summarization is expected to distill important information and remove redundant and incorrect information caused by recognition errors from spoken documents, enabling user to efficiently review spoken documents and understand the associated topics quickly. It would also be useful for improving the efficiency of a number of potential applications like retrieval and mining of large volumes of spoken documents. A summary can be either abstractive or extractive. In abstractive summarization, a fluent and concise abstract that reflects the key concepts of a document is generated, whereas i</context>
<context citStr="McKeown et al., 2005" endWordPosition="939" position="6385" startWordPosition="936"> paper is structured as follows. We start by reviewing related work on extractive summarization. In Section 3 we formulate the extractive summarization task as a risk minimization problem, followed by a detailed elucidation of the proposed methods in Section 4. Then, the experimental setup and a series of experiments and associated discussions are presented in Sections 5 and 6, respectively. Finally, Section 7 concludes our presentation and discusses avenues for future work. 2 Background Speech summarization can be conducted using either supervised or unsupervised methods (Furui et al., 2004, McKeown et al., 2005, Lin et al., 2008). In the following, we briefly review a few celebrated methods that have been applied to extractive speech summarization tasks with good success. 2.1 Supervised summarizers Extractive speech summarization can be treated as a two-class (positive/negative) classification problem. A spoken sentence Si is characterized by set of T indicative features Xi  xi 1 , , x iT  , and they may include lexical features (Koumpis and Renals, 2000), structural features (Maskey and Hirschberg, 2003), acoustic features (Inoue et al., 2004), discourse features (Zhang et al., 2007) and releva</context>
</contexts>
<marker>McKeown, Hirschberg, Galley, Maskey, 2005</marker>
<rawString>Kathleen McKeown, Julia Hirschberg, Michel Galley and Sameer Maskey. 2005. From text to speech summarization. In Proc. of IEEE International Conference on Acoustics, Speech, and Signal Processing: 997 - 1000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Paul Tarau</author>
</authors>
<title>TextRank: bringing order into texts.</title>
<date>2005</date>
<booktitle>In Proc. of Conference on Empirical Methods in Natural Language Processing:</booktitle>
<pages>404--411</pages>
<contexts>
<context citStr="Mihalcea and Tarau, 2005" endWordPosition="681" position="4628" startWordPosition="678">n for Computational Linguistics, pages 79–87, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics without leveraging the dependence relationships among the sentences or the global structure of the document (Shen et al., 2007). Another line of thought attempts to conduct document summarization using unsupervised machine-learning approaches, getting around the need for manually labeled training data. Most previous studies conducted along this line have their roots in the concept of sentence centrality (Gong and Liu, 2001; Erkan and Radev, 2004; Radev et al., 2004; Mihalcea and Tarau, 2005). Put simply, sentences more similar to others are deemed more salient to the main theme of the document; such sentences thus will be selected as part of the summary. Even though the performance of unsupervised summarizers is usually worse than that of supervised summarizers, their domain-independent and easy-to-implement properties still make them attractive. Building on these observations, we expect that researches conducted along the above-mentioned two directions could complement each other, and it might be possible to inherit their individual merits to overcome their inherent limitations.</context>
<context citStr="Mihalcea and Tarau, 2005" endWordPosition="1427" position="9499" startWordPosition="1424"> (VSM) approach represents each sentence of a document and the document itself in vector space (Gong and Liu, 2001), and computes the relevance score between each sentence and the document (e.g., the cosine measure of the simi80 larity between two vectors). Then, the sentences with the highest relevance scores are included in the summary. A natural extension is to represent each document or each sentence vector in a latent semantic space (Gong and Liu, 2001), instead of simply using the literal term information as that done by VSM. On the other hand, the graph-based methods, such as TextRank (Mihalcea and Tarau, 2005) and LexRank (Erkan and Radev, 2004), conceptualize the document to be summarized as a network of sentences, where each node represents a sentence and the associated weight of each link represents the lexical or topical similarity relationship between a pair of nodes. Document summarization thus relies on the global structural information conveyed by such conceptualized network, rather than merely considering the local features of each node (sentence). However, due to the lack of documentsummary reference pairs, the performance of the unsupervised summarizers is usually worse than that of the </context>
</contexts>
<marker>Mihalcea, Tarau, 2005</marker>
<rawString>Rada Mihalcea and Paul Tarau. 2005. TextRank: bringing order into texts. In Proc. of Conference on Empirical Methods in Natural Language Processing: 404 - 411.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragomir R Radev</author>
<author>Hongyan Jing</author>
<author>Małgorzata Stys</author>
<author>Daniel Tam</author>
</authors>
<title>Centroid-based summarization of multiple documents.</title>
<date>2004</date>
<journal>Information Processing and Management,</journal>
<volume>40</volume>
<pages>919--938</pages>
<contexts>
<context citStr="Radev et al., 2004" endWordPosition="677" position="4601" startWordPosition="674">ng of the Association for Computational Linguistics, pages 79–87, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics without leveraging the dependence relationships among the sentences or the global structure of the document (Shen et al., 2007). Another line of thought attempts to conduct document summarization using unsupervised machine-learning approaches, getting around the need for manually labeled training data. Most previous studies conducted along this line have their roots in the concept of sentence centrality (Gong and Liu, 2001; Erkan and Radev, 2004; Radev et al., 2004; Mihalcea and Tarau, 2005). Put simply, sentences more similar to others are deemed more salient to the main theme of the document; such sentences thus will be selected as part of the summary. Even though the performance of unsupervised summarizers is usually worse than that of supervised summarizers, their domain-independent and easy-to-implement properties still make them attractive. Building on these observations, we expect that researches conducted along the above-mentioned two directions could complement each other, and it might be possible to inherit their individual merits to overcome </context>
</contexts>
<marker>Radev, Jing, Stys, Tam, 2004</marker>
<rawString>Dragomir R. Radev, Hongyan Jing, Małgorzata Stys and Daniel Tam. 2004. Centroid-based summarization of multiple documents. Information Processing and Management, 40: 919 - 938.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dou Shen</author>
<author>Jian-Tao Sun</author>
<author>Hua Li</author>
<author>Qiang Yang</author>
<author>Zheng Chen</author>
</authors>
<title>Document summarization using conditional random fields.</title>
<date>2007</date>
<booktitle>In Proc. of International Joint Conference on Artificial Intelligence:</booktitle>
<pages>2862--2867</pages>
<contexts>
<context citStr="Shen et al., 2007" endWordPosition="627" position="4259" startWordPosition="624">ries (or labeled data), to train the classifiers. However, manual labeling is expensive in terms of time and personnel. The other potential problem is the socalled “bag-of-sentences” assumption implicitly made by most of these summarizers. That is, sentences are classified independently of each other, 79 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 79–87, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics without leveraging the dependence relationships among the sentences or the global structure of the document (Shen et al., 2007). Another line of thought attempts to conduct document summarization using unsupervised machine-learning approaches, getting around the need for manually labeled training data. Most previous studies conducted along this line have their roots in the concept of sentence centrality (Gong and Liu, 2001; Erkan and Radev, 2004; Radev et al., 2004; Mihalcea and Tarau, 2005). Put simply, sentences more similar to others are deemed more salient to the main theme of the document; such sentences thus will be selected as part of the summary. Even though the performance of unsupervised summarizers is usual</context>
<context citStr="Shen et al., 2007" endWordPosition="1191" position="7986" startWordPosition="1188"> assigns a classification score (or a posterior probability) of being in the summary class to each sentence of a spoken document to be summarized; important sentences are subsequently ranked and selected according to these scores. To this end, several popular machine-learning methods could be utilized, like Bayesian classifier (BC) (Kupiec et al., 1999), Gaussian mixture model (GMM) (Fattah and Ren, 2009) , hidden Markov model (HMM) (Conroy and O'leary, 2001), support vector machine (SVM) (Kolcz et al., 2001), maximum entropy (ME) (Ferrier, 2001), conditional random field (CRF) (Galley, 2006; Shen et al., 2007), to name a few. Although such supervised summarizers are effective, most of them (except CRF) usually implicitly assume that sentences are independent of each other (the so-called “bag-of-sentences” assumption) and classify each sentence individually without leveraging the relationship among the sentences (Shen et al., 2007). Another major shortcoming of these summarizers is that a set of handcrafted document-reference summary exemplars are required for training the summarizers; however, such summarizers tend to limit their generalization capability and might not be readily applicable for new</context>
</contexts>
<marker>Shen, Sun, Li, Yang, Chen, 2007</marker>
<rawString>Dou Shen, Jian-Tao Sun, Hua Li, Qiang Yang and Zheng Chen. 2007. Document summarization using conditional random fields. In Proc. of International Joint Conference on Artificial Intelligence: 2862 - 2867.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hsin-Min Wang</author>
<author>Berlin Chen</author>
<author>Jen-Wei Kuo</author>
<author>ShihSian Cheng</author>
</authors>
<title>MATBN: A Mandarin Chinese broadcast news corpus.</title>
<date>2005</date>
<journal>International Journal of Computational Linguistics and Chinese Language Processing,</journal>
<volume>10</volume>
<pages>219--236</pages>
<contexts>
<context citStr="Wang et al., 2005" endWordPosition="3748" position="22451" startWordPosition="3745">ction problem has now been reduced to the problem of measuring the document-likelihood PD |Sj  ~ , or the relevance between the document and the sentence. Alone a similar vein, the important sentences of a document can be selected (or ranked) solely based on the prior probability PSj  with the assumption of an equal document-likelihood P  D |Sj ~ . 5 Experimental setup 5.1 Data The summarization dataset used in this research is a widely used broadcast news corpus collected by the Academia Sinica and the Public Television Service Foundation of Taiwan between November 2001 and April 2003 (Wang et al., 2005). Each story contains the speech of one studio anchor, as well as several field reporters and interviewees. A subset of 205 broadcast news doc  T t t i t j  1 , z z , Sim S S  ,   i j . (10) T  T 2  t1zt,j 2 t1 zt,i (12) S *  ~  min arg ~ S D i Sj D,Sj Si  arg max ~ S D i �D |Si kSi  (13) 83 Kappa ROGUE-1 ROUGE-2 ROUGE-L 0.400 0.600 0.532 0.527 Table 1: The agreement among the subjects for important sentence ranking for the evaluation set. Structural 1.Duration of the current sentence features 2.Position of the current sentence 3.Length of the current sentence Lexical 1.Numb</context>
</contexts>
<marker>Wang, Chen, Kuo, Cheng, 2005</marker>
<rawString>Hsin-Min Wang, Berlin Chen, Jen-Wei Kuo and ShihSian Cheng. 2005. MATBN: A Mandarin Chinese broadcast news corpus. International Journal of Computational Linguistics and Chinese Language Processing, 10, (2): 219 - 236.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ChengXiang Zhai</author>
<author>John Lafferty</author>
</authors>
<title>A risk minimization framework for information retrieval.</title>
<date>2006</date>
<journal>Information Processing &amp; Management,</journal>
<volume>42</volume>
<pages>31--55</pages>
<contexts>
<context citStr="Zhai and Lafferty, 2006" endWordPosition="1857" position="12088" startWordPosition="1854">here p O |O is the posterior probability of the state of nature being  given the observation O. Bayes decision theory states that the optimum decision can be made by contemplating each action ai , and then choosing the action for which the expected risk is minimum: a* arg min R  a i |O .  ai The notion of minimizing the Bayes risk has gained much attention and been applied with success to many natural language processing (NLP) tasks, such as automatic speech recognition (Goel and Byrne, 2000), statistical machine translation (Kumar and Byrne, 2004) and statistical information retrieval (Zhai and Lafferty, 2006). Following the same spirit, we formulate the extractive summarization task as a Bayes risk minimization problem. Without loss of generality, let us denote   Π as one of possible selection strategies (or state of nature) which comprises a set of indicators used to address the importance of each sentence Si in a document D to be summarized. A feasible selection strategy can be fairly arbitrary according to the underlying principle. For example, it could be a set of binary indicators denoting whether a sentence should be selected as part of summary or not. On the contrary, it may also be a ran</context>
</contexts>
<marker>Zhai, Lafferty, 2006</marker>
<rawString>ChengXiang Zhai and John Lafferty. 2006. A risk minimization framework for information retrieval. Information Processing &amp; Management, 42, (1): 31 - 55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ChengXiang Zhai</author>
</authors>
<title>Statistical language models for information retrieval.</title>
<date>2008</date>
<publisher>Morgan &amp; Claypool Publishers,</publisher>
<contexts>
<context citStr="Zhai, 2008" endWordPosition="2797" position="17197" startWordPosition="2796">fwords” assumption) for generating the document (Chen et al., 2009): PO Sj  ~ Pw Sj Yw`, w D  where cw ~ D , is the number of times that index term (or word) w occurs in D ~ , reflecting that w Sj . Note that the sentence model Pw Sj is simply estimated on the basis of the frequency of index term w occurring in the sentence Sj with the maximum likelihood (ML) criterion. In a sense, (9) belongs to a kind of literal term matching strategy (Chen, 2009) and may suffer the problem of unreliable model estimation owing particularly to only a few sampled index terms present in the sentence (Zhai, 2008). To mitigate this potential defect, a unigram probability estimated from a general collection, which models the general distribution of words in the target language, is often used to smooth the sentence model. Interested readers may refer to (Zhai, 2008; Chen et al., 2009) for a thorough discussion on various ways to construct the sentence generative model. 4.2 Sentence prior model The sentence prior probability PSj  can be regarded as the likelihood of a sentence being important without seeing the whole document. It could be assumed uniformly distributed over sentences or estimated from a </context>
</contexts>
<marker>Zhai, 2008</marker>
<rawString>ChengXiang Zhai. Statistical language models for information retrieval. Morgan &amp; Claypool Publishers, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Justin Jian Zhang</author>
<author>Ho Yin Chan</author>
<author>Pascale Fung</author>
</authors>
<title>Improving Lecture Speech Summarization Using Rhetorical Information.</title>
<date>2007</date>
<booktitle>In Proc. of Workshop of Automatic Speech Recognition Understanding: 195 -</booktitle>
<pages>200</pages>
<contexts>
<context citStr="Zhang et al., 2007" endWordPosition="1030" position="6974" startWordPosition="1027">l., 2004, McKeown et al., 2005, Lin et al., 2008). In the following, we briefly review a few celebrated methods that have been applied to extractive speech summarization tasks with good success. 2.1 Supervised summarizers Extractive speech summarization can be treated as a two-class (positive/negative) classification problem. A spoken sentence Si is characterized by set of T indicative features Xi  xi 1 , , x iT  , and they may include lexical features (Koumpis and Renals, 2000), structural features (Maskey and Hirschberg, 2003), acoustic features (Inoue et al., 2004), discourse features (Zhang et al., 2007) and relevance features (Lin et al., 2009). Then, the corresponding feature vector Xi of Si is taken as the input to the classifier. If the output (classification) score belongs to the positive class, Si will be selected as part of the summary; otherwise, it will be excluded (Kupiec et al., 1999). Specifically, the problem can be formulated as follows: Construct a sentence ranking model that assigns a classification score (or a posterior probability) of being in the summary class to each sentence of a spoken document to be summarized; important sentences are subsequently ranked and selected ac</context>
</contexts>
<marker>Zhang, Chan, Fung, 2007</marker>
<rawString>Justin Jian Zhang, Ho Yin Chan and Pascale Fung. 2007. Improving Lecture Speech Summarization Using Rhetorical Information. In Proc. of Workshop of Automatic Speech Recognition Understanding: 195 - 200.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>